{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Vector for Korean LLM\n",
    "\n",
    "- The paper on chat-vectors (https://arxiv.org/abs/2310.04799v2) only disclosed the idea and did not release any specific code.\n",
    "- Currently, Junbeom(beomi/Llama-3-Open-Ko-8B-Instruct-preview) is deploying an instruction model that applies the chat-vector concept to a Korean model that has undergone Continual Pre-Training (CP) based on this idea.\n",
    "- The idea itself is quite simple, but its implications are worth considering in various ways.\n",
    "- However, it seems that the authors wrote this paper not so much from a robust theoretical foundation, but rather from a brilliant idea that they decided to experiment with, and upon experimenting, it actually worked.\n",
    "- Implementation was based on the code from StableFluffy (https://github.com/StableFluffy/EasyLLMFeaturePorter).\n",
    "- Due to limited memory conditions, there is a process of loading and then deleting the model.\n",
    "- Since loading the model in single precision (FP32) would not allow two models within 64GB, it is necessary to load in mixed precision (FP16 or bfp16).\n",
    "\n",
    "### Environment\n",
    "- The computer used as a code server has limited resources.\n",
    "- It uses an Intel 1260p CPU in an Intel NUC 12th generation.\n",
    "- 64GB RAM, 20GB swap memory (as loading more than two models at once is not possible with 64GB, ample swap memory is essential).\n",
    "- RTX 3090 24GB eGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Vector for Korean LLM\n",
    "\n",
    "- chat-vector 논문(https://arxiv.org/abs/2310.04799v2)은 아이디어만 공개하고 구체적인 코드는 공개하지 않았다. \n",
    "- 현재 준범님이 아이디어를 통해 한글로 CP(Continual Pre-Training)된 모델에 chat-vector를 적용해서 instruction 모델을 배포하고 있다. \n",
    "- 아이디어 자체는 매우 간단하지만, 내포하고 있는 의미는 여러가지로 생각 해 볼 수 있을 듯 하다. \n",
    "- 다만 저자들도 매우 단단한 이론적 배경위에서 이 논문을 작성했다기 보단, 번뜩이는 아이디어를 가지고 실험해보고, 실험해보니 실제로 작동해서 이 논문을 작성한게 아닐까 한다. \n",
    "- StableFluffy님의 코드(https://github.com/StableFluffy/EasyLLMFeaturePorter)를 기준으로 구현해보았다.\n",
    "- 제한적인 메모리 상황 때문에 모델을 로드했다가 삭제하는 과정이 있다. \n",
    "- 단정밀도(FP32)로 모델을 로드하면 64GB안에 두개 모델을 도르 할 수 없기 때문에, 반정밀도(FP16 or bfp16)으로 로드해야 한다. \n",
    "\n",
    "### Environment\n",
    "- 코드서버로 사용하고 있는 컴퓨터의 환경이 제한적이다. \n",
    "- intel 1260p CPU를 사용하는 intel nuc 12th\n",
    "- 64GB RAM, 20GB swap memory(64GB 많으로 두대 이상의 모델을 한번에 로드 해 연산을 할 수 없기 때문에, 넉넉한 swap 메모리는 필수이다.)\n",
    "- rtx 3090 24GB eGPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function\n",
    "\n",
    "def calculate_model_diffs(model_a, model_b):\n",
    "    model_a_dict = model_a.state_dict()\n",
    "    model_b_dict = model_b.state_dict()\n",
    "    print(\"model_a: \", len(model_a_dict))\n",
    "    print(\"model_a: \", len(model_b_dict))\n",
    "    model_diffs = {}\n",
    "    for key in model_a_dict.keys():\n",
    "        if key in model_b_dict:\n",
    "            model_diffs[key] = model_a_dict[key] - model_b_dict[key]\n",
    "            print(f\"Diff calculated for {key}\")\n",
    "    print(len(model_diffs))\n",
    "    return model_diffs\n",
    "\n",
    "\n",
    "def apply_model_diffs(target_model, model_diffs):\n",
    "    target_state_dict = target_model.state_dict()\n",
    "    for key in model_diffs.keys():\n",
    "        print(key)\n",
    "        print(model_diffs[key])\n",
    "        target_state_dict[key] += model_diffs[key]\n",
    "        print(f\"Diff applied for {key}\")\n",
    "    target_model.load_state_dict(target_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "chat_model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" \n",
    "base_model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "target_model_name = \"beomi/Llama-3-Open-Ko-8B\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_model_dir=\"/mnt/t7/.cache/huggingface/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e86869b373448f8236f5f65f6397f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc0b50af98a40e3beed3a2d0b931c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name, torch_dtype=torch.bfloat16,  cache_dir = cache_model_dir)\n",
    "chat_model = AutoModelForCausalLM.from_pretrained(chat_model_name, torch_dtype=torch.bfloat16,  cache_dir = cache_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating model diffs...\n",
      "model_a:  291\n",
      "model_a:  291\n",
      "Diff calculated for model.embed_tokens.weight\n",
      "Diff calculated for model.layers.0.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.0.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.0.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.0.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.0.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.0.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.0.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.0.input_layernorm.weight\n",
      "Diff calculated for model.layers.0.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.1.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.1.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.1.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.1.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.1.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.1.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.1.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.1.input_layernorm.weight\n",
      "Diff calculated for model.layers.1.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.2.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.2.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.2.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.2.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.2.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.2.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.2.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.2.input_layernorm.weight\n",
      "Diff calculated for model.layers.2.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.3.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.3.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.3.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.3.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.3.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.3.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.3.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.3.input_layernorm.weight\n",
      "Diff calculated for model.layers.3.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.4.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.4.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.4.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.4.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.4.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.4.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.4.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.4.input_layernorm.weight\n",
      "Diff calculated for model.layers.4.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.5.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.5.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.5.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.5.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.5.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.5.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.5.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.5.input_layernorm.weight\n",
      "Diff calculated for model.layers.5.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.6.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.6.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.6.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.6.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.6.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.6.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.6.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.6.input_layernorm.weight\n",
      "Diff calculated for model.layers.6.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.7.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.7.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.7.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.7.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.7.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.7.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.7.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.7.input_layernorm.weight\n",
      "Diff calculated for model.layers.7.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.8.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.8.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.8.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.8.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.8.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.8.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.8.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.8.input_layernorm.weight\n",
      "Diff calculated for model.layers.8.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.9.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.9.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.9.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.9.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.9.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.9.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.9.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.9.input_layernorm.weight\n",
      "Diff calculated for model.layers.9.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.10.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.10.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.10.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.10.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.10.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.10.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.10.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.10.input_layernorm.weight\n",
      "Diff calculated for model.layers.10.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.11.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.11.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.11.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.11.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.11.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.11.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.11.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.11.input_layernorm.weight\n",
      "Diff calculated for model.layers.11.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.12.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.12.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.12.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.12.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.12.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.12.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.12.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.12.input_layernorm.weight\n",
      "Diff calculated for model.layers.12.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.13.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.13.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.13.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.13.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.13.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.13.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.13.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.13.input_layernorm.weight\n",
      "Diff calculated for model.layers.13.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.14.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.14.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.14.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.14.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.14.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.14.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.14.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.14.input_layernorm.weight\n",
      "Diff calculated for model.layers.14.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.15.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.15.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.15.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.15.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.15.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.15.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.15.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.15.input_layernorm.weight\n",
      "Diff calculated for model.layers.15.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.16.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.16.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.16.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.16.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.16.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.16.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.16.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.16.input_layernorm.weight\n",
      "Diff calculated for model.layers.16.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.17.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.17.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.17.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.17.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.17.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.17.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.17.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.17.input_layernorm.weight\n",
      "Diff calculated for model.layers.17.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.18.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.18.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.18.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.18.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.18.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.18.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.18.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.18.input_layernorm.weight\n",
      "Diff calculated for model.layers.18.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.19.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.19.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.19.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.19.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.19.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.19.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.19.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.19.input_layernorm.weight\n",
      "Diff calculated for model.layers.19.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.20.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.20.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.20.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.20.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.20.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.20.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.20.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.20.input_layernorm.weight\n",
      "Diff calculated for model.layers.20.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.21.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.21.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.21.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.21.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.21.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.21.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.21.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.21.input_layernorm.weight\n",
      "Diff calculated for model.layers.21.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.22.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.22.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.22.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.22.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.22.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.22.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.22.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.22.input_layernorm.weight\n",
      "Diff calculated for model.layers.22.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.23.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.23.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.23.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.23.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.23.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.23.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.23.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.23.input_layernorm.weight\n",
      "Diff calculated for model.layers.23.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.24.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.24.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.24.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.24.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.24.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.24.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.24.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.24.input_layernorm.weight\n",
      "Diff calculated for model.layers.24.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.25.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.25.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.25.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.25.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.25.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.25.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.25.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.25.input_layernorm.weight\n",
      "Diff calculated for model.layers.25.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.26.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.26.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.26.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.26.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.26.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.26.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.26.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.26.input_layernorm.weight\n",
      "Diff calculated for model.layers.26.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.27.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.27.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.27.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.27.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.27.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.27.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.27.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.27.input_layernorm.weight\n",
      "Diff calculated for model.layers.27.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.28.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.28.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.28.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.28.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.28.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.28.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.28.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.28.input_layernorm.weight\n",
      "Diff calculated for model.layers.28.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.29.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.29.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.29.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.29.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.29.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.29.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.29.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.29.input_layernorm.weight\n",
      "Diff calculated for model.layers.29.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.30.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.30.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.30.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.30.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.30.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.30.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.30.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.30.input_layernorm.weight\n",
      "Diff calculated for model.layers.30.post_attention_layernorm.weight\n",
      "Diff calculated for model.layers.31.self_attn.q_proj.weight\n",
      "Diff calculated for model.layers.31.self_attn.k_proj.weight\n",
      "Diff calculated for model.layers.31.self_attn.v_proj.weight\n",
      "Diff calculated for model.layers.31.self_attn.o_proj.weight\n",
      "Diff calculated for model.layers.31.mlp.gate_proj.weight\n",
      "Diff calculated for model.layers.31.mlp.up_proj.weight\n",
      "Diff calculated for model.layers.31.mlp.down_proj.weight\n",
      "Diff calculated for model.layers.31.input_layernorm.weight\n",
      "Diff calculated for model.layers.31.post_attention_layernorm.weight\n",
      "Diff calculated for model.norm.weight\n",
      "Diff calculated for lm_head.weight\n",
      "291\n",
      "Model diffs calculated.\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating model diffs...\")\n",
    "model_diffs = calculate_model_diffs(chat_model, base_model)\n",
    "print(\"Model diffs calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chat_model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694ef5230bfc469c86387974ea73100a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_model = AutoModelForCausalLM.from_pretrained(target_model_name, torch_dtype=torch.bfloat16,  cache_dir = cache_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying model diffs...\n",
      "model.embed_tokens.weight\n",
      "tensor([[-7.6294e-05,  2.7466e-04,  8.2397e-04,  ..., -2.1362e-04,\n",
      "          4.7302e-04, -8.5831e-06],\n",
      "        [ 5.1880e-04, -3.8910e-04, -7.6294e-06,  ...,  5.1880e-04,\n",
      "          3.8147e-05,  4.9591e-04],\n",
      "        [ 2.1362e-03, -4.8828e-04, -6.9046e-04,  ...,  1.8311e-04,\n",
      "          3.9673e-04, -5.9509e-04],\n",
      "        ...,\n",
      "        [-1.0340e-25, -1.2925e-26, -1.0340e-25,  ...,  0.0000e+00,\n",
      "          1.2925e-26,  1.0340e-25],\n",
      "        [-1.0340e-25,  0.0000e+00,  1.0340e-25,  ..., -1.0340e-25,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 4.1359e-25,  0.0000e+00, -2.5849e-26,  ..., -2.5849e-26,\n",
      "          0.0000e+00,  1.2925e-26]], dtype=torch.bfloat16)\n",
      "Diff applied for model.embed_tokens.weight\n",
      "model.layers.0.self_attn.q_proj.weight\n",
      "tensor([[-9.1553e-05,  2.4414e-04, -1.5259e-05,  ...,  6.4087e-04,\n",
      "          0.0000e+00,  2.4414e-04],\n",
      "        [-6.1035e-05,  4.8828e-04,  4.1199e-04,  ...,  6.7139e-04,\n",
      "          0.0000e+00, -2.4414e-04],\n",
      "        [ 0.0000e+00,  7.3242e-04,  1.8311e-04,  ...,  1.2207e-04,\n",
      "         -4.8828e-04, -7.9346e-04],\n",
      "        ...,\n",
      "        [ 2.7466e-04,  7.3242e-04, -9.7656e-04,  ..., -2.1362e-04,\n",
      "          1.5259e-04, -4.7302e-04],\n",
      "        [ 4.2725e-04,  3.6621e-04, -2.4414e-04,  ..., -4.2725e-04,\n",
      "          2.2888e-04, -2.5940e-04],\n",
      "        [ 3.9673e-04,  2.4414e-04, -2.4414e-04,  ..., -3.6621e-04,\n",
      "          2.3651e-04, -5.3406e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.self_attn.q_proj.weight\n",
      "model.layers.0.self_attn.k_proj.weight\n",
      "tensor([[ 9.7656e-04,  0.0000e+00, -4.8828e-04,  ...,  4.8828e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4414e-04,  4.8828e-04, -1.2207e-04,  ...,  4.8828e-04,\n",
      "          2.1362e-04,  0.0000e+00],\n",
      "        [-1.2207e-04,  2.4414e-04,  2.4414e-04,  ...,  2.1362e-04,\n",
      "          2.4414e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 6.1035e-05,  1.2207e-04,  1.2207e-04,  ...,  0.0000e+00,\n",
      "          7.0190e-04,  1.5259e-05],\n",
      "        [ 9.1553e-04,  9.7656e-04, -2.3193e-03,  ..., -1.0986e-03,\n",
      "          4.8065e-04, -4.2725e-04],\n",
      "        [ 1.1292e-03,  8.5449e-04, -2.5635e-03,  ..., -9.1553e-04,\n",
      "          2.3651e-04, -4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.self_attn.k_proj.weight\n",
      "model.layers.0.self_attn.v_proj.weight\n",
      "tensor([[ 1.2207e-04, -4.2725e-04,  1.0872e-04,  ..., -3.6621e-04,\n",
      "          9.4604e-04,  4.5776e-05],\n",
      "        [ 2.2602e-04,  1.3733e-04,  5.0545e-05,  ..., -5.9509e-04,\n",
      "          3.6621e-04,  3.2043e-04],\n",
      "        [-2.4414e-04, -3.8147e-06, -1.2207e-04,  ..., -9.1553e-05,\n",
      "          7.3242e-04, -7.9346e-04],\n",
      "        ...,\n",
      "        [-1.2207e-04,  1.5640e-04, -9.1553e-05,  ..., -1.5259e-04,\n",
      "          6.1035e-05,  6.1035e-05],\n",
      "        [-6.1035e-05, -8.3923e-05,  1.9836e-04,  ..., -9.1553e-05,\n",
      "          1.8311e-04,  5.3406e-05],\n",
      "        [ 4.5776e-05,  9.1553e-05, -2.3651e-04,  ..., -2.5940e-04,\n",
      "          3.0518e-05, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.self_attn.v_proj.weight\n",
      "model.layers.0.self_attn.o_proj.weight\n",
      "tensor([[-4.9591e-04, -6.9427e-04, -4.8828e-04,  ...,  6.1035e-05,\n",
      "          1.8311e-04,  2.2125e-04],\n",
      "        [ 3.8147e-04,  1.2207e-04, -1.2207e-04,  ...,  2.4414e-04,\n",
      "         -2.4414e-04, -3.0518e-04],\n",
      "        [-2.0599e-04, -4.1962e-04,  4.5776e-04,  ...,  6.1035e-04,\n",
      "          1.3351e-04,  4.1962e-05],\n",
      "        ...,\n",
      "        [ 4.2725e-04, -3.3569e-04,  7.3242e-04,  ..., -1.2207e-04,\n",
      "          1.2207e-04, -3.6621e-04],\n",
      "        [ 3.0518e-04, -1.5259e-04,  3.0518e-05,  ..., -2.0599e-04,\n",
      "         -1.2207e-04,  2.5940e-04],\n",
      "        [ 2.7466e-04,  9.6130e-04,  3.9673e-04,  ..., -6.7139e-04,\n",
      "         -1.6785e-04, -2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.self_attn.o_proj.weight\n",
      "model.layers.0.mlp.gate_proj.weight\n",
      "tensor([[-2.4414e-04,  2.7466e-04,  2.4414e-04,  ...,  3.0518e-04,\n",
      "         -2.4414e-04, -4.2725e-04],\n",
      "        [ 3.9673e-04,  0.0000e+00, -1.9836e-04,  ...,  3.0518e-04,\n",
      "          9.4604e-04, -6.0272e-04],\n",
      "        [ 2.4414e-04,  2.1744e-04,  3.0518e-04,  ..., -1.0681e-04,\n",
      "          3.0518e-05, -3.0518e-04],\n",
      "        ...,\n",
      "        [-3.0518e-04,  1.2207e-04,  1.1597e-03,  ..., -1.8311e-04,\n",
      "         -3.6621e-04,  6.1035e-04],\n",
      "        [-3.0518e-05,  1.9073e-05, -2.7466e-04,  ..., -1.2207e-04,\n",
      "          5.4932e-04,  3.0518e-05],\n",
      "        [-3.0518e-05,  6.1035e-04,  1.2207e-04,  ...,  7.3242e-04,\n",
      "          3.6621e-04, -2.7466e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.mlp.gate_proj.weight\n",
      "model.layers.0.mlp.up_proj.weight\n",
      "tensor([[ 0.0000e+00,  1.2207e-04,  3.6621e-04,  ...,  2.1362e-04,\n",
      "         -7.3242e-04, -2.1362e-04],\n",
      "        [-3.6621e-04, -4.8828e-04, -2.8992e-04,  ...,  6.1035e-05,\n",
      "         -3.3569e-04, -3.0518e-04],\n",
      "        [ 4.1199e-04,  0.0000e+00, -6.1035e-05,  ..., -1.5259e-04,\n",
      "          1.6785e-04, -1.2207e-04],\n",
      "        ...,\n",
      "        [-2.4033e-04,  4.8828e-04,  9.1553e-05,  ..., -2.4414e-04,\n",
      "          6.7139e-04,  3.0518e-04],\n",
      "        [ 4.8828e-04,  0.0000e+00,  9.1553e-05,  ..., -2.2888e-04,\n",
      "          7.0190e-04, -1.8311e-04],\n",
      "        [-5.7983e-04, -4.2725e-04, -7.6294e-05,  ...,  6.1035e-05,\n",
      "         -6.1035e-04, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.mlp.up_proj.weight\n",
      "model.layers.0.mlp.down_proj.weight\n",
      "tensor([[ 1.2207e-04,  1.2207e-04,  3.6621e-04,  ..., -2.1362e-04,\n",
      "         -9.1553e-05,  1.2207e-04],\n",
      "        [ 1.2207e-04, -1.1597e-03, -3.9673e-04,  ..., -2.5940e-04,\n",
      "          4.8828e-04, -6.8665e-05],\n",
      "        [ 6.1035e-05, -3.0518e-05,  1.8311e-04,  ...,  7.0190e-04,\n",
      "          3.0518e-05, -9.7656e-04],\n",
      "        ...,\n",
      "        [ 3.6621e-04, -2.4414e-04,  2.4414e-04,  ...,  1.2207e-04,\n",
      "          3.6621e-04,  0.0000e+00],\n",
      "        [-5.4932e-04, -5.7983e-04,  6.1035e-05,  ...,  6.1035e-04,\n",
      "         -1.8311e-04, -3.0518e-04],\n",
      "        [ 6.2561e-04,  1.5259e-04,  2.4414e-04,  ...,  1.2207e-04,\n",
      "         -6.1035e-05,  5.4932e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.mlp.down_proj.weight\n",
      "model.layers.0.input_layernorm.weight\n",
      "tensor([-0.0002, -0.0010, -0.0020,  ..., -0.0005, -0.0002, -0.0002],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.input_layernorm.weight\n",
      "model.layers.0.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000, -0.0020,  ...,  0.0000, -0.0010, -0.0010],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.0.post_attention_layernorm.weight\n",
      "model.layers.1.self_attn.q_proj.weight\n",
      "tensor([[-2.4414e-04, -1.0986e-03, -8.5449e-04,  ...,  8.5449e-04,\n",
      "          3.0518e-05,  9.7656e-04],\n",
      "        [ 3.9673e-04, -1.5068e-04, -3.6621e-04,  ...,  2.4414e-04,\n",
      "          5.0354e-04,  7.3242e-04],\n",
      "        [-3.0518e-05, -4.8828e-04, -4.8828e-04,  ...,  7.9346e-04,\n",
      "          7.0190e-04,  1.0681e-03],\n",
      "        ...,\n",
      "        [-4.8828e-04,  4.8828e-04,  5.3406e-05,  ..., -4.2725e-04,\n",
      "         -2.4414e-04,  4.8828e-04],\n",
      "        [-8.5449e-04,  1.2207e-04,  9.7656e-04,  ..., -2.4414e-04,\n",
      "         -2.4414e-04, -2.4414e-04],\n",
      "        [-3.6621e-04,  1.2207e-04, -6.1035e-05,  ..., -2.4414e-04,\n",
      "         -4.2725e-04,  6.1035e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.self_attn.q_proj.weight\n",
      "model.layers.1.self_attn.k_proj.weight\n",
      "tensor([[ 0.0002, -0.0005,  0.0003,  ...,  0.0005,  0.0007, -0.0001],\n",
      "        [-0.0001, -0.0002,  0.0001,  ...,  0.0000, -0.0002, -0.0004],\n",
      "        [-0.0005, -0.0004, -0.0003,  ...,  0.0002,  0.0001, -0.0005],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0002, -0.0001,  ...,  0.0005, -0.0001,  0.0005],\n",
      "        [ 0.0000,  0.0001,  0.0004,  ...,  0.0000, -0.0005,  0.0000],\n",
      "        [ 0.0002,  0.0002, -0.0001,  ..., -0.0003,  0.0005, -0.0003]],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.self_attn.k_proj.weight\n",
      "model.layers.1.self_attn.v_proj.weight\n",
      "tensor([[-3.6621e-04,  5.7220e-04, -6.1035e-05,  ..., -5.0354e-04,\n",
      "          1.4877e-04, -3.6621e-04],\n",
      "        [-1.5259e-04, -9.1553e-05, -3.0518e-04,  ..., -2.2888e-04,\n",
      "          0.0000e+00, -3.6621e-04],\n",
      "        [ 9.1553e-04,  6.1035e-05, -3.3569e-04,  ..., -3.0518e-04,\n",
      "          1.2207e-03,  4.7302e-04],\n",
      "        ...,\n",
      "        [ 2.7466e-04,  4.5776e-05, -5.3406e-04,  ...,  8.0109e-05,\n",
      "          3.9673e-04, -9.7656e-04],\n",
      "        [-1.8311e-04,  1.8311e-04,  6.1035e-04,  ..., -1.2207e-04,\n",
      "          2.4414e-04,  6.1035e-05],\n",
      "        [-2.4414e-04,  2.4414e-04,  4.5776e-04,  ...,  4.2725e-04,\n",
      "          1.8311e-04, -4.1199e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.self_attn.v_proj.weight\n",
      "model.layers.1.self_attn.o_proj.weight\n",
      "tensor([[-9.1553e-04,  6.1035e-05,  6.1035e-05,  ...,  9.4604e-04,\n",
      "         -3.6621e-04, -1.8311e-04],\n",
      "        [-5.7983e-04,  9.1553e-04, -3.3569e-04,  ...,  3.9673e-04,\n",
      "         -2.4414e-04, -1.2207e-04],\n",
      "        [ 3.0518e-05,  9.1553e-04,  4.8828e-04,  ..., -2.1362e-04,\n",
      "         -1.2207e-04, -4.8828e-04],\n",
      "        ...,\n",
      "        [ 7.3242e-04,  4.8828e-04, -1.5259e-04,  ..., -5.4932e-04,\n",
      "         -1.2207e-04, -1.2207e-04],\n",
      "        [-4.8828e-04,  3.0518e-04, -2.4414e-04,  ...,  6.1035e-05,\n",
      "          3.6621e-04,  5.4932e-04],\n",
      "        [-1.8311e-04, -1.2207e-04,  2.7466e-04,  ..., -3.0518e-04,\n",
      "          1.2207e-04,  2.8992e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.self_attn.o_proj.weight\n",
      "model.layers.1.mlp.gate_proj.weight\n",
      "tensor([[ 0.0000e+00, -2.4414e-04,  1.0681e-04,  ..., -9.1553e-05,\n",
      "         -3.0518e-04, -3.6621e-04],\n",
      "        [-3.6621e-04, -2.4414e-04, -2.4414e-04,  ..., -3.0518e-04,\n",
      "          4.2725e-04, -3.6621e-04],\n",
      "        [-7.6294e-04, -8.5449e-04,  1.5259e-05,  ..., -6.1035e-04,\n",
      "         -1.8311e-04,  2.4414e-04],\n",
      "        ...,\n",
      "        [-1.8311e-04,  2.4414e-04, -1.2207e-04,  ...,  2.8229e-04,\n",
      "         -2.1362e-04, -3.6621e-04],\n",
      "        [ 4.2725e-04,  1.2207e-04, -2.4414e-04,  ..., -3.0518e-04,\n",
      "          4.1199e-04,  1.0376e-03],\n",
      "        [ 6.1035e-05,  3.6621e-04, -3.6621e-04,  ...,  1.8311e-04,\n",
      "          3.6621e-04,  4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.mlp.gate_proj.weight\n",
      "model.layers.1.mlp.up_proj.weight\n",
      "tensor([[-3.1281e-04, -1.2207e-04, -3.6621e-04,  ..., -1.3733e-04,\n",
      "          1.5259e-04,  1.4496e-04],\n",
      "        [ 2.4414e-04, -4.7302e-04,  1.2817e-03,  ...,  0.0000e+00,\n",
      "          4.1962e-04, -4.2725e-04],\n",
      "        [ 5.4932e-04,  3.9673e-04, -9.1553e-05,  ...,  9.4604e-04,\n",
      "         -6.7139e-04,  6.1035e-04],\n",
      "        ...,\n",
      "        [-4.8828e-04, -5.4932e-04, -5.0354e-04,  ..., -2.7847e-04,\n",
      "          1.0681e-04,  0.0000e+00],\n",
      "        [ 4.6539e-04,  9.1553e-04,  1.5259e-04,  ..., -3.9673e-04,\n",
      "          2.4414e-04,  2.0409e-04],\n",
      "        [-4.2725e-04, -1.2207e-04, -1.8311e-04,  ...,  0.0000e+00,\n",
      "          4.8828e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.mlp.up_proj.weight\n",
      "model.layers.1.mlp.down_proj.weight\n",
      "tensor([[ 4.5776e-05,  6.1035e-05,  3.0518e-04,  ..., -3.6621e-04,\n",
      "          2.1362e-04,  6.4087e-04],\n",
      "        [ 3.0518e-04, -1.0986e-03,  3.0518e-05,  ..., -7.3242e-04,\n",
      "         -4.8828e-04, -2.1362e-04],\n",
      "        [ 6.5613e-04, -1.8311e-04,  4.2725e-04,  ...,  0.0000e+00,\n",
      "         -5.4932e-04, -1.3123e-03],\n",
      "        ...,\n",
      "        [-1.8311e-04,  6.7139e-04,  3.4714e-04,  ...,  3.6621e-04,\n",
      "         -6.1035e-05, -4.8828e-04],\n",
      "        [-3.0518e-05,  1.3123e-03, -1.0223e-03,  ...,  1.2207e-04,\n",
      "         -6.8665e-05, -6.1035e-05],\n",
      "        [-4.8828e-04, -1.2207e-04,  5.4932e-04,  ..., -3.3569e-04,\n",
      "         -3.0518e-04, -6.2466e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.mlp.down_proj.weight\n",
      "model.layers.1.input_layernorm.weight\n",
      "tensor([-0.0005, -0.0010, -0.0010,  ...,  0.0000,  0.0000, -0.0005],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.input_layernorm.weight\n",
      "model.layers.1.post_attention_layernorm.weight\n",
      "tensor([-0.0010,  0.0000, -0.0010,  ...,  0.0000,  0.0000, -0.0010],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.1.post_attention_layernorm.weight\n",
      "model.layers.2.self_attn.q_proj.weight\n",
      "tensor([[ 2.4414e-04,  3.6621e-04,  6.8665e-04,  ..., -2.4414e-04,\n",
      "         -1.2207e-04, -3.6621e-04],\n",
      "        [-4.8828e-04,  7.3242e-04,  8.5449e-04,  ..., -6.1035e-05,\n",
      "          2.2888e-04, -6.7139e-04],\n",
      "        [-2.7466e-04,  5.7983e-04,  5.1117e-04,  ..., -3.6621e-04,\n",
      "          4.8828e-04, -2.1362e-04],\n",
      "        ...,\n",
      "        [-3.9673e-04, -5.4932e-04, -5.4932e-04,  ..., -3.0518e-05,\n",
      "          3.0518e-04,  5.0354e-04],\n",
      "        [ 9.1553e-05,  0.0000e+00, -4.2725e-04,  ..., -4.4632e-04,\n",
      "          4.8828e-04,  1.2207e-04],\n",
      "        [-8.5449e-04,  2.4414e-04, -4.2915e-05,  ...,  6.7139e-04,\n",
      "         -7.3242e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.self_attn.q_proj.weight\n",
      "model.layers.2.self_attn.k_proj.weight\n",
      "tensor([[ 2.1362e-04, -6.1035e-05,  1.2207e-04,  ...,  0.0000e+00,\n",
      "          6.1035e-04,  3.6621e-04],\n",
      "        [-3.0518e-05,  0.0000e+00, -1.2207e-04,  ..., -1.2207e-04,\n",
      "         -6.1035e-05,  0.0000e+00],\n",
      "        [-1.8311e-04, -4.8828e-04,  3.3569e-04,  ..., -2.4414e-04,\n",
      "          3.0518e-05, -5.1880e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  5.1880e-04,  6.1035e-04,  ..., -2.4414e-04,\n",
      "          2.4414e-04,  4.8828e-04],\n",
      "        [ 1.2207e-03,  3.0518e-05,  3.6621e-04,  ..., -1.2207e-04,\n",
      "          2.4414e-04, -4.8828e-04],\n",
      "        [ 3.3569e-04,  3.0518e-04, -9.7656e-04,  ..., -9.7656e-04,\n",
      "          2.7466e-04,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.self_attn.k_proj.weight\n",
      "model.layers.2.self_attn.v_proj.weight\n",
      "tensor([[-8.7738e-05,  7.9346e-04, -6.1035e-05,  ...,  0.0000e+00,\n",
      "         -2.4414e-04, -2.4414e-04],\n",
      "        [ 1.0376e-03,  4.8828e-04,  6.1035e-04,  ...,  6.1035e-05,\n",
      "          4.9591e-04,  6.8665e-05],\n",
      "        [ 1.4114e-04,  7.4768e-04,  6.1035e-05,  ...,  5.1880e-04,\n",
      "          3.0518e-05,  3.3569e-04],\n",
      "        ...,\n",
      "        [-3.8528e-04,  2.4414e-04,  1.5259e-05,  ..., -6.1035e-05,\n",
      "         -1.8311e-04, -3.0518e-04],\n",
      "        [ 3.0518e-04,  4.2725e-04,  6.1035e-04,  ..., -4.2725e-04,\n",
      "          1.3733e-04,  3.0518e-05],\n",
      "        [ 1.1902e-03, -1.2207e-04,  0.0000e+00,  ..., -1.5259e-05,\n",
      "         -2.4414e-04, -5.7983e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.self_attn.v_proj.weight\n",
      "model.layers.2.self_attn.o_proj.weight\n",
      "tensor([[ 6.1035e-04, -3.0518e-04,  4.8828e-04,  ...,  1.8311e-04,\n",
      "          5.4932e-04, -3.3569e-04],\n",
      "        [-1.8311e-04, -3.2425e-04,  1.5259e-05,  ...,  4.2725e-04,\n",
      "         -1.9836e-04,  0.0000e+00],\n",
      "        [ 1.8311e-04, -8.5449e-04, -6.7139e-04,  ...,  5.1880e-04,\n",
      "          6.1035e-04,  2.4414e-04],\n",
      "        ...,\n",
      "        [ 3.6621e-04,  1.2207e-04,  3.6621e-04,  ...,  9.7656e-04,\n",
      "         -3.0518e-04,  2.7466e-04],\n",
      "        [-7.3242e-04,  1.2207e-04, -6.1035e-04,  ...,  1.2207e-04,\n",
      "          1.1902e-03, -1.0223e-03],\n",
      "        [ 0.0000e+00,  3.6621e-04, -2.1362e-04,  ...,  2.1362e-04,\n",
      "         -6.1035e-04, -6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.self_attn.o_proj.weight\n",
      "model.layers.2.mlp.gate_proj.weight\n",
      "tensor([[-2.7466e-04,  4.2725e-04,  6.1035e-05,  ...,  3.5095e-04,\n",
      "         -4.8828e-04, -3.6621e-04],\n",
      "        [ 8.6212e-04, -4.2725e-04,  3.6621e-04,  ..., -3.8147e-04,\n",
      "         -2.0504e-04, -4.8828e-04],\n",
      "        [ 4.8828e-04, -5.7220e-05,  7.3242e-04,  ...,  3.9673e-04,\n",
      "         -6.7139e-04, -8.6212e-04],\n",
      "        ...,\n",
      "        [-1.2207e-04, -6.1035e-04,  5.7602e-04,  ..., -1.6785e-04,\n",
      "         -6.3324e-04, -1.2207e-04],\n",
      "        [ 2.4414e-04, -5.1880e-04,  9.9182e-05,  ...,  2.2888e-05,\n",
      "         -1.1444e-04,  3.0518e-04],\n",
      "        [ 7.9346e-04, -1.0681e-04,  0.0000e+00,  ...,  6.1035e-05,\n",
      "         -4.8828e-04,  8.3923e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.mlp.gate_proj.weight\n",
      "model.layers.2.mlp.up_proj.weight\n",
      "tensor([[ 0.0000e+00, -2.7466e-04,  3.0518e-04,  ...,  6.1035e-05,\n",
      "          9.1553e-05,  5.3406e-04],\n",
      "        [ 2.4414e-04,  0.0000e+00,  7.1335e-04,  ...,  1.5259e-04,\n",
      "          4.8828e-04, -4.2725e-04],\n",
      "        [-3.0518e-04,  2.4414e-04,  2.4414e-04,  ..., -4.8828e-04,\n",
      "         -8.5449e-04,  3.6621e-04],\n",
      "        ...,\n",
      "        [ 8.0872e-04, -1.5259e-04,  4.8828e-04,  ...,  2.4414e-04,\n",
      "          4.2725e-04,  3.0518e-04],\n",
      "        [-4.2725e-04, -4.8828e-04, -3.0518e-04,  ..., -3.6621e-04,\n",
      "         -1.2207e-04,  1.0300e-04],\n",
      "        [-2.6703e-05, -2.1362e-04,  6.7139e-04,  ..., -1.3733e-04,\n",
      "          2.4414e-04, -6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.mlp.up_proj.weight\n",
      "model.layers.2.mlp.down_proj.weight\n",
      "tensor([[ 2.4414e-04, -6.1035e-05,  3.2043e-04,  ...,  2.4414e-04,\n",
      "         -9.1553e-05,  6.7139e-04],\n",
      "        [ 1.2207e-04,  4.2725e-04, -9.1553e-05,  ...,  8.5449e-04,\n",
      "         -1.5259e-04,  2.4414e-04],\n",
      "        [ 4.6158e-04,  7.4768e-04, -8.5449e-04,  ...,  7.3242e-04,\n",
      "         -2.1362e-04,  1.2207e-04],\n",
      "        ...,\n",
      "        [-6.7139e-04,  2.4414e-04,  3.0518e-04,  ..., -3.0518e-04,\n",
      "         -6.1035e-05,  4.5776e-04],\n",
      "        [-4.2725e-04,  1.5259e-04,  1.2207e-04,  ...,  3.6621e-04,\n",
      "          1.2970e-04, -3.6621e-04],\n",
      "        [-2.4414e-04, -3.6621e-04,  1.2207e-04,  ...,  0.0000e+00,\n",
      "          9.9182e-05, -6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.mlp.down_proj.weight\n",
      "model.layers.2.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0039, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.input_layernorm.weight\n",
      "model.layers.2.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0010,  0.0000,  ..., -0.0010, -0.0010, -0.0010],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.2.post_attention_layernorm.weight\n",
      "model.layers.3.self_attn.q_proj.weight\n",
      "tensor([[ 5.4932e-04,  6.1035e-05,  2.2125e-04,  ...,  1.2207e-04,\n",
      "          7.6294e-05, -7.6294e-04],\n",
      "        [ 6.7139e-04, -9.1553e-04,  4.8828e-04,  ...,  3.3379e-04,\n",
      "          1.0376e-03,  4.2725e-04],\n",
      "        [ 4.8828e-04,  4.8828e-04, -1.2207e-04,  ...,  0.0000e+00,\n",
      "         -3.0518e-05,  9.1553e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  2.4414e-04, -6.7902e-04,  ...,  0.0000e+00,\n",
      "         -1.3428e-03,  6.1035e-05],\n",
      "        [-2.4414e-04, -1.2207e-04,  2.7466e-04,  ..., -1.2207e-04,\n",
      "          1.5259e-04, -7.6294e-05],\n",
      "        [ 4.2725e-04,  6.1035e-04,  0.0000e+00,  ...,  3.0518e-04,\n",
      "         -2.4414e-04,  4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.self_attn.q_proj.weight\n",
      "model.layers.3.self_attn.k_proj.weight\n",
      "tensor([[-6.7139e-04,  3.6621e-04,  6.1035e-05,  ...,  3.6621e-04,\n",
      "          7.3242e-04,  0.0000e+00],\n",
      "        [-3.0518e-04, -1.4648e-03, -4.1962e-04,  ..., -3.0518e-04,\n",
      "         -6.4087e-04, -6.1035e-05],\n",
      "        [-7.7057e-04, -1.9073e-04,  1.9836e-04,  ..., -1.8311e-04,\n",
      "          1.2207e-04, -2.4414e-04],\n",
      "        ...,\n",
      "        [ 7.3242e-04,  9.3079e-04,  4.8828e-04,  ...,  0.0000e+00,\n",
      "         -9.7656e-04,  0.0000e+00],\n",
      "        [-1.3733e-04, -6.1035e-05,  3.0518e-04,  ..., -3.6621e-04,\n",
      "         -2.4414e-04, -2.4414e-04],\n",
      "        [-2.4414e-04, -4.8828e-04, -4.7302e-04,  ..., -1.2207e-04,\n",
      "         -1.0986e-03,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.self_attn.k_proj.weight\n",
      "model.layers.3.self_attn.v_proj.weight\n",
      "tensor([[-2.7466e-04,  5.4932e-04, -1.0681e-04,  ..., -4.8828e-04,\n",
      "          6.1035e-05, -6.4850e-05],\n",
      "        [-6.1035e-04,  3.0518e-05,  5.3406e-04,  ...,  2.4414e-04,\n",
      "          2.4414e-04,  2.7466e-04],\n",
      "        [ 1.2207e-04,  4.8828e-04,  4.6539e-04,  ..., -1.5259e-04,\n",
      "         -4.9591e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [-1.2207e-04,  1.6785e-04, -6.7139e-04,  ...,  4.8447e-04,\n",
      "         -1.1444e-04,  9.1553e-05],\n",
      "        [-2.4414e-04,  1.8311e-04, -3.8147e-05,  ..., -2.1362e-04,\n",
      "         -5.7983e-04, -2.5940e-04],\n",
      "        [ 1.2207e-04,  1.6880e-04, -3.9673e-04,  ...,  1.0529e-03,\n",
      "          1.8311e-04,  4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.self_attn.v_proj.weight\n",
      "model.layers.3.self_attn.o_proj.weight\n",
      "tensor([[ 3.0518e-04, -8.3923e-04, -2.4414e-04,  ...,  8.0109e-04,\n",
      "         -1.2207e-04,  6.1035e-04],\n",
      "        [ 3.2043e-04, -6.1035e-04, -1.3733e-04,  ...,  9.9182e-04,\n",
      "          1.0376e-03,  4.2725e-04],\n",
      "        [ 3.6621e-04,  6.1035e-05,  4.2725e-04,  ...,  5.0354e-04,\n",
      "          5.4932e-04, -3.0518e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04,  2.4414e-04, -3.6621e-04,  ..., -2.4414e-04,\n",
      "         -1.2207e-04,  0.0000e+00],\n",
      "        [-1.5259e-04,  6.1035e-04,  1.0376e-03,  ...,  3.0518e-05,\n",
      "          7.1716e-04,  2.4414e-04],\n",
      "        [ 6.4087e-04, -3.6621e-04,  1.8311e-04,  ...,  6.1035e-04,\n",
      "         -3.5095e-04,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.self_attn.o_proj.weight\n",
      "model.layers.3.mlp.gate_proj.weight\n",
      "tensor([[-5.4932e-04,  1.2207e-04, -6.1035e-05,  ...,  1.8311e-04,\n",
      "         -6.1035e-05,  4.8828e-04],\n",
      "        [ 3.3569e-04,  1.5259e-04, -7.9346e-04,  ...,  1.5259e-04,\n",
      "          6.1035e-04,  4.8828e-04],\n",
      "        [ 4.8828e-04,  0.0000e+00, -6.1035e-05,  ...,  9.4604e-04,\n",
      "          0.0000e+00,  2.4414e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-05, -3.6621e-04, -6.1035e-04,  ..., -3.0518e-05,\n",
      "         -1.2207e-04,  3.3951e-04],\n",
      "        [ 6.8665e-04,  1.0376e-03,  6.1035e-04,  ...,  2.7466e-04,\n",
      "         -3.6621e-04,  5.1880e-04],\n",
      "        [-1.8311e-04,  5.4932e-04,  5.7983e-04,  ..., -1.6403e-04,\n",
      "          1.8311e-04, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.mlp.gate_proj.weight\n",
      "model.layers.3.mlp.up_proj.weight\n",
      "tensor([[-4.5776e-04, -1.8311e-04, -2.4414e-04,  ..., -1.2207e-04,\n",
      "         -1.1902e-03,  3.0518e-04],\n",
      "        [ 0.0000e+00,  1.8311e-04, -3.0518e-04,  ...,  3.3569e-04,\n",
      "         -6.7139e-04,  6.1035e-05],\n",
      "        [-6.7139e-04, -4.2725e-04, -1.5259e-04,  ...,  1.2207e-04,\n",
      "         -4.8828e-04,  9.6893e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -6.7139e-04, -2.0599e-04,  ..., -1.2054e-03,\n",
      "          4.2725e-04,  1.8311e-04],\n",
      "        [ 3.6621e-04,  2.8992e-04, -1.2207e-04,  ...,  0.0000e+00,\n",
      "         -1.2207e-04, -6.2943e-04],\n",
      "        [ 5.4932e-04, -1.8311e-04, -6.7139e-04,  ..., -2.1362e-04,\n",
      "         -9.1553e-04,  2.0599e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.mlp.up_proj.weight\n",
      "model.layers.3.mlp.down_proj.weight\n",
      "tensor([[-2.1362e-04, -2.4796e-05, -6.1035e-05,  ...,  4.8828e-04,\n",
      "          1.3733e-04, -7.6294e-05],\n",
      "        [ 5.7983e-04,  7.6294e-06,  1.8311e-04,  ..., -3.6621e-04,\n",
      "          1.0300e-04, -3.6621e-04],\n",
      "        [ 9.7656e-04, -4.6158e-04, -6.4087e-04,  ...,  3.6621e-04,\n",
      "         -3.0518e-05,  6.1035e-05],\n",
      "        ...,\n",
      "        [ 2.7466e-04,  1.8692e-04, -3.3569e-04,  ...,  0.0000e+00,\n",
      "         -9.1553e-04,  1.2207e-04],\n",
      "        [ 7.9346e-04, -4.8828e-04,  7.9346e-04,  ...,  3.5858e-04,\n",
      "          5.4932e-04, -6.1035e-04],\n",
      "        [ 1.2207e-04,  6.1035e-05,  7.6294e-04,  ...,  2.4414e-04,\n",
      "         -4.8828e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.mlp.down_proj.weight\n",
      "model.layers.3.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.input_layernorm.weight\n",
      "model.layers.3.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0010, -0.0020,  ..., -0.0010,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.3.post_attention_layernorm.weight\n",
      "model.layers.4.self_attn.q_proj.weight\n",
      "tensor([[-6.1035e-04, -8.5449e-04, -2.7466e-04,  ..., -8.8501e-04,\n",
      "          8.5449e-04,  1.2207e-04],\n",
      "        [-2.4414e-04, -1.0681e-03, -3.0518e-05,  ...,  0.0000e+00,\n",
      "         -4.2725e-04,  4.5776e-04],\n",
      "        [ 4.2725e-04, -6.1035e-05, -4.8828e-04,  ...,  9.7656e-04,\n",
      "         -4.8828e-04,  1.2207e-04],\n",
      "        ...,\n",
      "        [-3.6621e-04, -8.5449e-04,  1.8311e-04,  ...,  2.4414e-04,\n",
      "          2.4414e-04,  6.1035e-05],\n",
      "        [ 1.8311e-04,  5.7220e-06,  2.4414e-04,  ..., -2.4414e-04,\n",
      "          7.3242e-04, -1.9073e-06],\n",
      "        [ 1.2207e-04,  4.8828e-04, -2.1362e-04,  ...,  2.4414e-04,\n",
      "          3.6621e-04, -7.3242e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.self_attn.q_proj.weight\n",
      "model.layers.4.self_attn.k_proj.weight\n",
      "tensor([[ 0.0000e+00,  4.8828e-04,  1.2207e-04,  ..., -7.7820e-04,\n",
      "          0.0000e+00, -1.2207e-04],\n",
      "        [ 1.2207e-04,  2.8992e-04,  7.3242e-04,  ..., -8.2397e-04,\n",
      "          9.7656e-04, -2.4414e-04],\n",
      "        [ 4.8828e-04,  4.8828e-04, -9.1553e-05,  ..., -3.0518e-04,\n",
      "          1.2207e-04, -7.3242e-04],\n",
      "        ...,\n",
      "        [-4.8828e-04,  1.6785e-04,  6.1035e-05,  ...,  0.0000e+00,\n",
      "          2.4414e-04, -1.2207e-04],\n",
      "        [-7.3242e-04, -1.8311e-04,  3.6621e-04,  ...,  0.0000e+00,\n",
      "         -4.8828e-04,  6.1035e-05],\n",
      "        [-6.1035e-04,  7.3242e-04, -1.0681e-04,  ...,  6.7139e-04,\n",
      "         -6.1035e-05,  8.5449e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.self_attn.k_proj.weight\n",
      "model.layers.4.self_attn.v_proj.weight\n",
      "tensor([[ 4.8828e-04,  3.6621e-04,  5.7983e-04,  ..., -4.2725e-04,\n",
      "          2.1362e-04,  4.2725e-04],\n",
      "        [ 1.2207e-04,  8.5449e-04,  3.6621e-04,  ...,  1.6785e-04,\n",
      "          1.2207e-04,  8.3923e-05],\n",
      "        [-2.8992e-04, -2.4414e-04, -1.2207e-04,  ...,  3.0518e-05,\n",
      "          7.3242e-04,  5.4932e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  1.2207e-04,  6.1035e-05,  ..., -3.0518e-04,\n",
      "          8.3923e-04,  3.5095e-04],\n",
      "        [ 6.1035e-05,  2.1362e-04,  5.0354e-04,  ..., -9.9182e-05,\n",
      "         -1.2207e-04,  0.0000e+00],\n",
      "        [ 1.8311e-04,  2.2888e-04, -5.4932e-04,  ...,  1.5259e-04,\n",
      "         -9.1553e-05, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.self_attn.v_proj.weight\n",
      "model.layers.4.self_attn.o_proj.weight\n",
      "tensor([[ 0.0007,  0.0003,  0.0003,  ..., -0.0002, -0.0007, -0.0002],\n",
      "        [ 0.0006, -0.0002,  0.0007,  ...,  0.0004, -0.0002,  0.0002],\n",
      "        [ 0.0005,  0.0002, -0.0004,  ...,  0.0010, -0.0002, -0.0004],\n",
      "        ...,\n",
      "        [ 0.0006, -0.0002, -0.0002,  ..., -0.0003,  0.0006,  0.0005],\n",
      "        [-0.0007, -0.0002,  0.0003,  ...,  0.0002, -0.0002,  0.0000],\n",
      "        [-0.0005,  0.0013, -0.0006,  ..., -0.0003, -0.0009,  0.0004]],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.self_attn.o_proj.weight\n",
      "model.layers.4.mlp.gate_proj.weight\n",
      "tensor([[-1.8311e-04,  3.0518e-04,  3.0518e-04,  ...,  1.2207e-04,\n",
      "         -6.1035e-05,  0.0000e+00],\n",
      "        [-4.2725e-04,  6.1035e-05,  2.4414e-04,  ..., -1.2207e-04,\n",
      "         -2.4414e-04,  3.3569e-04],\n",
      "        [ 0.0000e+00,  2.5940e-04, -9.7656e-04,  ..., -5.4932e-04,\n",
      "         -3.0518e-04,  7.4005e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04,  1.0223e-03, -9.1553e-05,  ...,  1.2207e-04,\n",
      "          3.0518e-05,  2.5177e-04],\n",
      "        [-3.2806e-04, -4.2725e-04, -7.3242e-04,  ...,  1.8311e-04,\n",
      "          8.5449e-04,  4.9210e-04],\n",
      "        [-7.3242e-04, -6.1035e-05, -7.9346e-04,  ..., -3.9673e-04,\n",
      "          0.0000e+00, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.mlp.gate_proj.weight\n",
      "model.layers.4.mlp.up_proj.weight\n",
      "tensor([[-5.0354e-04,  6.1035e-05, -1.2817e-03,  ...,  1.8311e-04,\n",
      "         -1.0071e-03,  5.6458e-04],\n",
      "        [ 2.7466e-04,  0.0000e+00,  0.0000e+00,  ...,  1.6785e-04,\n",
      "          1.0986e-03,  1.9073e-04],\n",
      "        [-2.4414e-04, -1.8311e-04,  6.4087e-04,  ..., -4.8828e-04,\n",
      "          5.7983e-04,  1.8311e-04],\n",
      "        ...,\n",
      "        [-1.6403e-03, -5.4932e-04,  3.5858e-04,  ..., -1.8311e-04,\n",
      "         -5.1880e-04,  5.1880e-04],\n",
      "        [ 3.0518e-05, -6.1035e-05, -2.4414e-04,  ..., -6.7139e-04,\n",
      "          6.1035e-05, -2.8992e-04],\n",
      "        [-9.1553e-05,  3.5095e-04,  1.5259e-04,  ...,  2.4414e-04,\n",
      "          4.8828e-04,  4.2725e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.mlp.up_proj.weight\n",
      "model.layers.4.mlp.down_proj.weight\n",
      "tensor([[-4.8828e-04, -3.6621e-04,  2.4414e-04,  ...,  0.0000e+00,\n",
      "          3.7384e-04, -1.8311e-04],\n",
      "        [ 0.0000e+00,  4.8828e-04, -4.2725e-04,  ...,  1.8311e-04,\n",
      "          2.4414e-04, -2.4414e-04],\n",
      "        [ 8.2397e-04,  3.6621e-04, -4.8828e-04,  ...,  3.0518e-04,\n",
      "          9.1553e-05, -4.8828e-04],\n",
      "        ...,\n",
      "        [-1.8311e-04,  5.6458e-04, -3.6621e-04,  ..., -9.1553e-04,\n",
      "         -9.1553e-04,  0.0000e+00],\n",
      "        [-4.8828e-04,  3.0518e-04, -5.4932e-04,  ..., -6.1035e-05,\n",
      "          1.1444e-05,  2.4414e-04],\n",
      "        [-2.4414e-04,  6.7139e-04,  4.8828e-04,  ..., -1.9073e-04,\n",
      "          4.2725e-04,  8.5449e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.mlp.down_proj.weight\n",
      "model.layers.4.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020,  0.0000,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.input_layernorm.weight\n",
      "model.layers.4.post_attention_layernorm.weight\n",
      "tensor([-0.0020,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.4.post_attention_layernorm.weight\n",
      "model.layers.5.self_attn.q_proj.weight\n",
      "tensor([[-5.7983e-04, -4.5776e-04, -8.4686e-04,  ...,  8.5449e-04,\n",
      "         -1.0376e-03, -4.5776e-04],\n",
      "        [ 1.2207e-04, -3.2806e-04, -1.2207e-04,  ...,  1.2207e-04,\n",
      "         -2.4414e-04, -6.7139e-04],\n",
      "        [-6.1035e-05,  6.4087e-04, -6.1035e-04,  ...,  9.1553e-05,\n",
      "         -7.9346e-04, -1.6785e-04],\n",
      "        ...,\n",
      "        [-6.1035e-04,  6.7139e-04, -3.6621e-04,  ...,  1.8311e-04,\n",
      "         -7.3242e-04,  6.1035e-05],\n",
      "        [ 2.1362e-04, -1.2207e-04,  7.3242e-04,  ..., -5.3406e-04,\n",
      "         -2.4414e-04,  4.8828e-04],\n",
      "        [ 3.6621e-04, -2.1362e-04, -7.3242e-04,  ...,  2.8992e-04,\n",
      "         -4.2725e-04, -6.4087e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.self_attn.q_proj.weight\n",
      "model.layers.5.self_attn.k_proj.weight\n",
      "tensor([[ 6.1035e-05,  0.0000e+00,  2.4414e-04,  ..., -2.1362e-04,\n",
      "          0.0000e+00, -1.5259e-04],\n",
      "        [-1.2207e-04,  0.0000e+00,  4.2725e-04,  ...,  2.4414e-04,\n",
      "          9.7656e-04,  8.6212e-04],\n",
      "        [ 7.6294e-05, -2.4414e-04, -7.3242e-04,  ...,  4.5776e-04,\n",
      "          4.8828e-04,  7.9346e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04,  0.0000e+00,  7.3242e-04,  ...,  0.0000e+00,\n",
      "          4.8828e-04, -4.8828e-04],\n",
      "        [ 4.8828e-04,  8.8882e-04, -4.8828e-04,  ...,  1.1444e-03,\n",
      "          7.0190e-04, -3.6621e-04],\n",
      "        [ 0.0000e+00,  3.1662e-04,  3.0518e-04,  ..., -7.3242e-04,\n",
      "         -6.7139e-04,  6.1035e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.self_attn.k_proj.weight\n",
      "model.layers.5.self_attn.v_proj.weight\n",
      "tensor([[-2.7466e-04,  1.5259e-04,  9.0027e-04,  ..., -2.9755e-04,\n",
      "          5.4932e-04, -1.3733e-04],\n",
      "        [-6.7139e-04, -6.1035e-05,  1.8311e-04,  ...,  0.0000e+00,\n",
      "         -9.1553e-05, -2.7466e-04],\n",
      "        [ 6.5994e-04,  7.9346e-04,  1.9836e-04,  ...,  6.1035e-04,\n",
      "          1.2207e-04,  2.2888e-04],\n",
      "        ...,\n",
      "        [ 1.9836e-04,  4.6158e-04,  3.0518e-04,  ..., -3.1662e-04,\n",
      "          3.5095e-04, -1.0681e-04],\n",
      "        [ 1.4496e-04,  6.7139e-04,  2.4414e-04,  ..., -3.2043e-04,\n",
      "          1.2207e-04, -3.0518e-04],\n",
      "        [ 4.7302e-04,  9.0790e-04, -7.0190e-04,  ..., -6.1035e-05,\n",
      "         -2.4414e-04, -1.8311e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.self_attn.v_proj.weight\n",
      "model.layers.5.self_attn.o_proj.weight\n",
      "tensor([[ 3.6621e-04,  4.8828e-04,  0.0000e+00,  ...,  3.6621e-04,\n",
      "          7.6294e-04,  4.5776e-04],\n",
      "        [ 3.6621e-04, -5.4932e-04, -1.2207e-04,  ...,  3.4332e-05,\n",
      "          2.7466e-04, -2.4414e-04],\n",
      "        [-1.2207e-04,  3.0518e-04, -1.2207e-04,  ..., -2.2125e-04,\n",
      "          6.7139e-04, -9.1553e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -2.4605e-04, -7.6294e-05,  ...,  6.1035e-05,\n",
      "         -4.6539e-04, -8.2397e-04],\n",
      "        [-3.3569e-04, -4.3678e-04,  1.6022e-04,  ...,  5.7983e-04,\n",
      "          1.2207e-04, -2.9755e-04],\n",
      "        [-3.3569e-04, -6.1035e-05, -4.9591e-05,  ..., -1.0986e-03,\n",
      "          2.4414e-04,  9.1553e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.self_attn.o_proj.weight\n",
      "model.layers.5.mlp.gate_proj.weight\n",
      "tensor([[-4.8828e-04, -5.4932e-04, -1.0986e-03,  ..., -1.2207e-04,\n",
      "          8.5449e-04, -7.0190e-04],\n",
      "        [ 2.1362e-04,  4.2725e-04, -2.4414e-04,  ..., -6.1035e-04,\n",
      "          4.8828e-04,  6.1035e-05],\n",
      "        [ 3.6621e-04, -3.6621e-04, -9.3079e-04,  ...,  5.1498e-04,\n",
      "          5.1880e-04, -1.2207e-04],\n",
      "        ...,\n",
      "        [-1.2207e-04, -2.4414e-04, -2.4414e-04,  ...,  4.7302e-04,\n",
      "          0.0000e+00, -4.8828e-04],\n",
      "        [ 1.7166e-03,  1.6479e-03,  1.2207e-04,  ...,  5.3406e-05,\n",
      "         -1.2207e-04,  2.4414e-04],\n",
      "        [-1.2207e-03,  3.6621e-04, -6.1035e-04,  ..., -3.6621e-04,\n",
      "         -4.8828e-04,  3.9673e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.mlp.gate_proj.weight\n",
      "model.layers.5.mlp.up_proj.weight\n",
      "tensor([[-6.6376e-04,  4.2725e-04, -3.6621e-04,  ..., -6.1035e-04,\n",
      "          3.0518e-05, -3.6621e-04],\n",
      "        [-3.8862e-05, -2.8992e-04, -1.2207e-04,  ..., -2.4414e-04,\n",
      "          7.3242e-04,  3.9673e-04],\n",
      "        [ 2.4414e-04, -1.8311e-04,  6.2561e-04,  ..., -9.7656e-04,\n",
      "         -8.5449e-04,  7.9346e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  3.6621e-04, -1.8311e-04,  ...,  3.3569e-04,\n",
      "         -4.8828e-04, -1.2207e-04],\n",
      "        [ 7.9346e-04,  5.4932e-04, -3.2043e-04,  ...,  7.3624e-04,\n",
      "         -9.1553e-04,  4.8828e-04],\n",
      "        [-2.7847e-04,  3.6621e-04,  1.5259e-04,  ...,  9.1553e-05,\n",
      "          0.0000e+00,  3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.mlp.up_proj.weight\n",
      "model.layers.5.mlp.down_proj.weight\n",
      "tensor([[ 2.1362e-04,  1.4496e-04, -1.6785e-04,  ...,  0.0000e+00,\n",
      "         -1.2207e-04, -5.1880e-04],\n",
      "        [ 3.0518e-05,  7.0190e-04, -9.9182e-05,  ...,  9.1553e-05,\n",
      "         -9.1553e-05, -6.1035e-04],\n",
      "        [-1.2207e-04,  3.3569e-04,  8.2397e-04,  ..., -6.1035e-05,\n",
      "          3.6621e-04, -1.6785e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-05, -3.2043e-04,  1.3733e-04,  ..., -2.4414e-04,\n",
      "          3.0518e-04,  5.4932e-04],\n",
      "        [-2.7466e-04, -3.0518e-05, -3.0518e-04,  ..., -3.6621e-04,\n",
      "         -5.1880e-04, -7.3242e-04],\n",
      "        [-3.0518e-05, -6.1035e-04,  9.1553e-05,  ..., -3.0518e-04,\n",
      "         -1.8787e-04,  1.8311e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.mlp.down_proj.weight\n",
      "model.layers.5.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0039, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.input_layernorm.weight\n",
      "model.layers.5.post_attention_layernorm.weight\n",
      "tensor([-0.0020,  0.0000,  0.0000,  ...,  0.0000, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.5.post_attention_layernorm.weight\n",
      "model.layers.6.self_attn.q_proj.weight\n",
      "tensor([[-5.4932e-04,  1.2207e-04,  1.5259e-04,  ..., -1.0300e-04,\n",
      "         -5.7602e-04,  3.8147e-04],\n",
      "        [ 8.5449e-04,  7.6294e-05, -2.4414e-04,  ..., -2.4414e-04,\n",
      "          4.1199e-04, -2.7466e-04],\n",
      "        [ 3.6621e-04,  3.0518e-04,  3.3569e-04,  ...,  3.6621e-04,\n",
      "         -3.6621e-04,  4.2725e-04],\n",
      "        ...,\n",
      "        [-4.2725e-04,  4.2725e-04,  3.6621e-04,  ..., -1.5259e-05,\n",
      "         -9.7656e-04, -7.3242e-04],\n",
      "        [ 2.4414e-04, -2.4414e-04,  4.5776e-04,  ..., -7.4768e-04,\n",
      "          2.4414e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00, -2.4414e-04, -7.3242e-04,  ...,  9.1553e-05,\n",
      "         -1.2207e-04, -7.3242e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.self_attn.q_proj.weight\n",
      "model.layers.6.self_attn.k_proj.weight\n",
      "tensor([[ 2.5940e-04,  4.8828e-04, -2.4414e-04,  ...,  3.0518e-04,\n",
      "         -5.4932e-04, -3.0518e-04],\n",
      "        [-2.4414e-04,  1.5259e-04, -1.5259e-04,  ..., -3.0518e-04,\n",
      "          5.7983e-04,  2.4414e-04],\n",
      "        [ 1.2207e-04, -1.2207e-03,  4.8828e-04,  ..., -9.1553e-05,\n",
      "          4.8828e-04,  7.9346e-04],\n",
      "        ...,\n",
      "        [-9.7656e-04, -7.3242e-04,  4.8828e-04,  ..., -1.2207e-04,\n",
      "          0.0000e+00,  6.1035e-04],\n",
      "        [-2.4414e-04, -4.8828e-04, -6.1035e-05,  ..., -1.3428e-03,\n",
      "         -4.0436e-04,  3.0518e-04],\n",
      "        [ 0.0000e+00, -4.8828e-04,  4.8828e-04,  ..., -6.1035e-05,\n",
      "          2.4414e-04,  4.2725e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.self_attn.k_proj.weight\n",
      "model.layers.6.self_attn.v_proj.weight\n",
      "tensor([[ 0.0000e+00, -5.9509e-04,  4.2725e-04,  ..., -1.2207e-04,\n",
      "          2.4414e-04, -1.8311e-04],\n",
      "        [-2.1362e-04, -1.8311e-04,  1.6785e-04,  ..., -3.0518e-04,\n",
      "          0.0000e+00, -7.9346e-04],\n",
      "        [ 2.8229e-04, -5.4932e-04, -1.2207e-04,  ...,  1.8311e-04,\n",
      "          2.1362e-04, -6.0272e-04],\n",
      "        ...,\n",
      "        [-2.8229e-04,  1.5259e-05,  4.1962e-04,  ..., -3.0518e-04,\n",
      "         -1.9836e-04, -7.6294e-04],\n",
      "        [-3.3569e-04, -1.8311e-04,  5.0354e-04,  ...,  6.1035e-04,\n",
      "          4.2725e-04, -4.2152e-04],\n",
      "        [ 4.8828e-04,  0.0000e+00,  3.9673e-04,  ...,  2.5940e-04,\n",
      "          2.1362e-04,  1.1444e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.self_attn.v_proj.weight\n",
      "model.layers.6.self_attn.o_proj.weight\n",
      "tensor([[-1.8311e-04,  2.4414e-04, -7.6294e-05,  ..., -2.2125e-04,\n",
      "         -4.2725e-04,  1.5259e-04],\n",
      "        [ 4.5776e-04,  3.0518e-05,  1.8311e-04,  ..., -1.8311e-04,\n",
      "         -3.8147e-05, -2.4414e-04],\n",
      "        [ 3.0518e-04,  4.2725e-04,  1.2207e-04,  ...,  4.4250e-04,\n",
      "          8.2397e-04,  3.6621e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-04, -1.5259e-04, -7.9346e-04,  ..., -4.8828e-04,\n",
      "         -1.4496e-04,  3.6621e-04],\n",
      "        [ 2.4414e-04, -1.8311e-04, -1.8501e-04,  ...,  5.9891e-04,\n",
      "          2.7084e-04,  9.4604e-04],\n",
      "        [ 2.4414e-04, -1.2207e-03, -3.4904e-04,  ...,  1.3733e-04,\n",
      "          1.2207e-04, -2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.self_attn.o_proj.weight\n",
      "model.layers.6.mlp.gate_proj.weight\n",
      "tensor([[ 8.2397e-04,  1.8311e-04, -9.9182e-04,  ...,  6.1035e-05,\n",
      "         -1.6403e-04,  1.2207e-04],\n",
      "        [-4.2725e-04,  1.0376e-03,  2.4414e-04,  ...,  4.8828e-04,\n",
      "          0.0000e+00,  7.3242e-04],\n",
      "        [-9.0027e-04, -3.6621e-04,  1.8692e-04,  ..., -6.1035e-05,\n",
      "         -9.1553e-05, -1.8311e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  5.4932e-04,  1.2207e-04,  ...,  8.5449e-04,\n",
      "         -6.1035e-05,  2.4414e-04],\n",
      "        [ 7.6294e-05, -1.2207e-04,  9.7656e-04,  ..., -9.1553e-05,\n",
      "         -4.9210e-04,  5.7983e-04],\n",
      "        [-3.0518e-04, -2.4414e-04, -2.4414e-04,  ...,  7.9346e-04,\n",
      "          4.2725e-04, -1.0071e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.mlp.gate_proj.weight\n",
      "model.layers.6.mlp.up_proj.weight\n",
      "tensor([[-6.7139e-04,  8.5449e-04,  2.4414e-04,  ...,  7.1716e-04,\n",
      "          2.4414e-04, -6.7139e-04],\n",
      "        [ 6.1035e-04, -6.8665e-04,  4.2725e-04,  ..., -2.4414e-04,\n",
      "          4.4250e-04,  3.0518e-04],\n",
      "        [-3.0518e-04,  1.0529e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          1.5259e-05, -3.9673e-04],\n",
      "        ...,\n",
      "        [ 1.7929e-04,  1.9073e-04, -6.1035e-04,  ...,  2.1362e-04,\n",
      "         -6.1035e-05, -2.1362e-04],\n",
      "        [ 1.0681e-04, -1.8311e-04,  7.9346e-04,  ...,  0.0000e+00,\n",
      "         -1.8311e-04, -4.8828e-04],\n",
      "        [ 3.6621e-04, -4.8828e-04, -2.0981e-04,  ...,  6.1035e-04,\n",
      "         -5.4932e-04, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.mlp.up_proj.weight\n",
      "model.layers.6.mlp.down_proj.weight\n",
      "tensor([[-4.8828e-04,  3.1662e-04,  3.0518e-05,  ...,  3.0518e-04,\n",
      "          3.6621e-04, -4.8828e-04],\n",
      "        [-7.3242e-04, -6.1035e-05, -1.5259e-04,  ...,  4.2725e-04,\n",
      "         -9.1553e-04, -1.0376e-03],\n",
      "        [-6.1035e-05, -2.1362e-04,  6.1035e-04,  ..., -5.1880e-04,\n",
      "         -7.7248e-05, -3.0518e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04,  6.5613e-04,  2.4414e-04,  ...,  6.1035e-05,\n",
      "          3.6621e-04, -2.4414e-04],\n",
      "        [ 6.1035e-04, -7.3242e-04,  0.0000e+00,  ...,  2.1362e-04,\n",
      "         -3.6621e-04,  4.2725e-04],\n",
      "        [-9.9182e-05,  4.8828e-04,  4.2725e-04,  ..., -7.9346e-04,\n",
      "          4.8828e-04, -9.1553e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.mlp.down_proj.weight\n",
      "model.layers.6.input_layernorm.weight\n",
      "tensor([-0.0020,  0.0000, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.input_layernorm.weight\n",
      "model.layers.6.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.6.post_attention_layernorm.weight\n",
      "model.layers.7.self_attn.q_proj.weight\n",
      "tensor([[-2.1362e-04,  1.8311e-04,  5.3406e-04,  ...,  2.4414e-04,\n",
      "         -3.0518e-05,  4.2725e-04],\n",
      "        [-3.0518e-04, -2.7466e-04,  3.6621e-04,  ...,  3.6621e-04,\n",
      "          1.8311e-04,  2.4414e-04],\n",
      "        [-1.8311e-04,  0.0000e+00,  8.8882e-04,  ...,  4.8828e-04,\n",
      "          9.1553e-05,  3.9673e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04,  2.4414e-04, -1.2207e-04,  ...,  0.0000e+00,\n",
      "         -7.6294e-05,  7.3242e-04],\n",
      "        [-1.2207e-04,  0.0000e+00, -2.4414e-04,  ...,  4.2725e-04,\n",
      "         -6.1035e-05,  7.9346e-04],\n",
      "        [-6.0272e-04, -6.1035e-04,  1.0986e-03,  ...,  3.0518e-05,\n",
      "          8.6975e-04, -2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.self_attn.q_proj.weight\n",
      "model.layers.7.self_attn.k_proj.weight\n",
      "tensor([[ 6.1035e-04,  0.0000e+00,  0.0000e+00,  ..., -3.0518e-04,\n",
      "          4.2725e-04, -6.1035e-05],\n",
      "        [ 1.2589e-04, -3.0518e-05, -3.6621e-04,  ..., -2.4414e-04,\n",
      "          2.4414e-04, -4.8828e-04],\n",
      "        [-7.3242e-04,  1.4038e-03, -5.4932e-04,  ..., -3.6621e-04,\n",
      "         -6.1035e-05, -1.2207e-04],\n",
      "        ...,\n",
      "        [ 2.4414e-04, -1.0223e-03,  1.4267e-03,  ...,  7.9346e-04,\n",
      "         -2.4414e-04, -2.4414e-04],\n",
      "        [-3.6621e-04, -2.4414e-04,  2.4414e-04,  ...,  1.0986e-03,\n",
      "         -2.4414e-04, -1.8311e-04],\n",
      "        [ 5.4932e-04,  4.8828e-04,  3.6621e-04,  ...,  6.1035e-05,\n",
      "         -8.3923e-05,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.self_attn.k_proj.weight\n",
      "model.layers.7.self_attn.v_proj.weight\n",
      "tensor([[-4.8828e-04,  4.4441e-04, -2.1362e-04,  ...,  3.0518e-04,\n",
      "          8.6212e-04,  3.0518e-05],\n",
      "        [ 3.0518e-04,  5.1880e-04, -3.6621e-04,  ..., -4.2725e-04,\n",
      "          1.5259e-04, -3.6621e-04],\n",
      "        [ 7.6294e-05,  1.8311e-04,  0.0000e+00,  ..., -4.6921e-04,\n",
      "          2.7466e-04, -4.8828e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04,  6.1035e-05,  6.6376e-04,  ...,  3.0136e-04,\n",
      "          8.5449e-04,  0.0000e+00],\n",
      "        [-2.2125e-04, -9.1553e-05, -3.0518e-04,  ...,  9.1553e-04,\n",
      "         -9.0027e-04, -2.4414e-04],\n",
      "        [ 1.2207e-04,  5.1880e-04, -6.1035e-05,  ...,  4.5776e-04,\n",
      "         -3.0518e-04,  4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.self_attn.v_proj.weight\n",
      "model.layers.7.self_attn.o_proj.weight\n",
      "tensor([[ 1.8311e-04,  3.6621e-04, -7.3242e-04,  ...,  3.9673e-04,\n",
      "          4.5776e-04, -6.1035e-05],\n",
      "        [ 3.3569e-04, -3.0518e-04,  7.3242e-04,  ...,  3.0518e-05,\n",
      "          5.6458e-04, -3.3569e-04],\n",
      "        [-6.1035e-04, -2.8992e-04, -6.7139e-04,  ..., -4.5776e-05,\n",
      "          1.9836e-04,  4.8828e-04],\n",
      "        ...,\n",
      "        [-7.6294e-04,  1.9073e-04,  5.1880e-04,  ...,  4.8828e-04,\n",
      "         -7.9346e-04, -2.8992e-04],\n",
      "        [-1.2207e-04, -2.2125e-04, -1.8311e-04,  ...,  1.8311e-04,\n",
      "         -2.7466e-04,  3.3569e-04],\n",
      "        [ 2.4414e-04,  1.2207e-04, -7.3242e-04,  ..., -3.9673e-04,\n",
      "         -1.3733e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.self_attn.o_proj.weight\n",
      "model.layers.7.mlp.gate_proj.weight\n",
      "tensor([[ 2.4414e-04, -6.6757e-04, -1.0376e-03,  ..., -2.4414e-04,\n",
      "         -5.4932e-04, -4.2725e-04],\n",
      "        [ 2.7466e-04,  1.2207e-04, -1.0986e-03,  ...,  1.2207e-04,\n",
      "          1.8311e-04,  6.1035e-04],\n",
      "        [-2.8133e-05,  8.8501e-04, -5.7220e-05,  ..., -1.8311e-04,\n",
      "         -3.3569e-04, -4.6921e-04],\n",
      "        ...,\n",
      "        [-1.0376e-03, -3.6621e-04, -6.4087e-04,  ...,  4.8828e-04,\n",
      "         -3.0518e-04,  3.8147e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  4.8828e-04,  ..., -5.1880e-04,\n",
      "          0.0000e+00,  3.0518e-05],\n",
      "        [-4.7302e-04,  2.4414e-04,  3.6621e-04,  ..., -1.8311e-04,\n",
      "          7.0190e-04, -6.7520e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.mlp.gate_proj.weight\n",
      "model.layers.7.mlp.up_proj.weight\n",
      "tensor([[ 8.4686e-04,  5.0354e-04, -8.5449e-04,  ..., -5.6458e-04,\n",
      "         -1.4038e-03,  2.1362e-04],\n",
      "        [ 6.1035e-05,  1.1597e-03, -7.3242e-04,  ..., -9.3842e-04,\n",
      "         -1.5259e-05, -2.4414e-04],\n",
      "        [ 6.1035e-04, -9.1553e-04,  1.4114e-04,  ...,  3.6621e-04,\n",
      "          6.1035e-05, -8.2397e-04],\n",
      "        ...,\n",
      "        [-8.5449e-04, -8.8501e-04,  0.0000e+00,  ...,  1.2207e-04,\n",
      "          5.9509e-04, -1.1292e-03],\n",
      "        [ 1.9836e-04,  1.2207e-04, -1.5259e-04,  ...,  6.0272e-04,\n",
      "         -4.8828e-04,  6.1035e-05],\n",
      "        [-1.8311e-04, -4.8828e-04,  4.8828e-04,  ...,  9.1553e-04,\n",
      "          5.4932e-04, -1.2207e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.mlp.up_proj.weight\n",
      "model.layers.7.mlp.down_proj.weight\n",
      "tensor([[ 9.1553e-05, -4.8828e-04, -4.2725e-04,  ...,  6.1035e-05,\n",
      "          0.0000e+00,  3.0518e-05],\n",
      "        [-1.8311e-04,  1.5259e-04,  9.1553e-05,  ...,  4.2725e-04,\n",
      "         -1.2207e-04, -3.0518e-04],\n",
      "        [-3.0518e-04, -1.2512e-03,  2.5940e-04,  ...,  1.0681e-04,\n",
      "          3.6621e-04, -2.4414e-04],\n",
      "        ...,\n",
      "        [ 4.2725e-04, -1.8311e-04, -6.8665e-05,  ..., -8.6975e-04,\n",
      "          6.5613e-04,  3.0518e-04],\n",
      "        [ 1.2207e-04,  6.1035e-04,  1.5259e-04,  ..., -1.2207e-04,\n",
      "         -6.4468e-04,  2.4414e-04],\n",
      "        [ 6.1035e-04, -2.4414e-04,  4.1962e-05,  ..., -3.0518e-04,\n",
      "          6.7139e-04, -5.3406e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.mlp.down_proj.weight\n",
      "model.layers.7.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.input_layernorm.weight\n",
      "model.layers.7.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0020,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.7.post_attention_layernorm.weight\n",
      "model.layers.8.self_attn.q_proj.weight\n",
      "tensor([[ 5.4932e-04, -3.6621e-04,  3.0518e-05,  ...,  1.7548e-04,\n",
      "         -2.1362e-04,  2.4414e-04],\n",
      "        [-1.2207e-04,  1.2207e-04, -1.3046e-03,  ...,  0.0000e+00,\n",
      "          2.4414e-04, -6.1035e-05],\n",
      "        [ 1.4114e-04,  1.2817e-03, -4.1962e-04,  ...,  3.0518e-04,\n",
      "          8.5449e-04, -1.2207e-04],\n",
      "        ...,\n",
      "        [ 5.4932e-04,  0.0000e+00, -4.8828e-04,  ...,  6.1035e-05,\n",
      "          1.8311e-04,  0.0000e+00],\n",
      "        [ 1.2207e-04, -7.9346e-04,  0.0000e+00,  ...,  7.3242e-04,\n",
      "          9.1553e-04, -2.1362e-04],\n",
      "        [ 4.8828e-04,  0.0000e+00,  5.4932e-04,  ...,  2.4414e-04,\n",
      "          2.4414e-04, -1.4038e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.self_attn.q_proj.weight\n",
      "model.layers.8.self_attn.k_proj.weight\n",
      "tensor([[ 3.6621e-04,  2.1362e-04, -6.1035e-04,  ..., -3.6621e-04,\n",
      "          4.7302e-04,  5.6458e-04],\n",
      "        [ 6.1035e-05, -2.4414e-04, -3.6621e-04,  ..., -1.1902e-03,\n",
      "          0.0000e+00,  9.4604e-04],\n",
      "        [-3.0518e-05,  1.8311e-04, -1.8311e-04,  ..., -3.6621e-04,\n",
      "         -6.1035e-04, -1.3733e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04, -2.4414e-04, -4.2725e-04,  ..., -8.5449e-04,\n",
      "         -9.7656e-04, -4.8828e-04],\n",
      "        [ 0.0000e+00, -2.4414e-04, -3.6621e-04,  ...,  0.0000e+00,\n",
      "         -4.8828e-04, -7.3242e-04],\n",
      "        [ 2.4414e-04,  2.4414e-04,  2.4414e-04,  ..., -7.4768e-04,\n",
      "          9.7656e-04, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.self_attn.k_proj.weight\n",
      "model.layers.8.self_attn.v_proj.weight\n",
      "tensor([[ 1.0681e-04,  3.6621e-04,  9.1553e-05,  ..., -1.5259e-04,\n",
      "          3.0518e-04,  7.1716e-04],\n",
      "        [-6.1035e-04,  6.1035e-04, -1.2207e-04,  ..., -3.0518e-04,\n",
      "          7.0190e-04,  3.0518e-04],\n",
      "        [ 4.2725e-04,  2.4414e-04, -2.4414e-04,  ...,  0.0000e+00,\n",
      "         -6.1035e-05,  3.7384e-04],\n",
      "        ...,\n",
      "        [-7.6294e-05, -1.6117e-04,  6.1035e-05,  ...,  3.3569e-04,\n",
      "          2.4414e-04,  3.9673e-04],\n",
      "        [ 4.5776e-04,  3.2043e-04, -1.6785e-04,  ...,  3.8147e-04,\n",
      "         -7.6675e-04,  3.6621e-04],\n",
      "        [-6.1035e-05, -5.4932e-04,  3.5095e-04,  ...,  1.4496e-04,\n",
      "          1.2207e-04,  3.3569e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.self_attn.v_proj.weight\n",
      "model.layers.8.self_attn.o_proj.weight\n",
      "tensor([[-6.1035e-04, -3.0518e-04,  4.2725e-04,  ..., -6.7139e-04,\n",
      "         -1.2207e-04,  0.0000e+00],\n",
      "        [ 4.8828e-04, -1.8311e-04,  7.3242e-04,  ...,  2.4414e-04,\n",
      "         -3.0518e-05,  3.9673e-04],\n",
      "        [-4.5776e-05,  1.8311e-04, -9.1553e-05,  ...,  5.5695e-04,\n",
      "          2.1362e-04, -9.1553e-05],\n",
      "        ...,\n",
      "        [ 6.1035e-05,  4.7302e-04,  5.7983e-04,  ..., -5.5695e-04,\n",
      "          0.0000e+00,  1.0681e-04],\n",
      "        [ 6.1035e-04, -1.8311e-04, -1.2207e-04,  ...,  5.1880e-04,\n",
      "         -2.2888e-04, -6.1035e-05],\n",
      "        [ 4.8828e-04,  1.8311e-04,  4.5776e-04,  ..., -5.1880e-04,\n",
      "         -1.2207e-04, -4.5776e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.self_attn.o_proj.weight\n",
      "model.layers.8.mlp.gate_proj.weight\n",
      "tensor([[-2.4414e-04,  1.2207e-04,  3.0518e-04,  ...,  6.1035e-05,\n",
      "         -4.5776e-04,  2.7466e-04],\n",
      "        [ 2.4414e-04,  3.1281e-04,  0.0000e+00,  ..., -4.2725e-04,\n",
      "         -1.8311e-04,  0.0000e+00],\n",
      "        [-5.1880e-04, -2.3651e-04, -1.0681e-04,  ..., -8.3923e-04,\n",
      "          2.4414e-04,  3.6621e-04],\n",
      "        ...,\n",
      "        [ 4.2725e-04, -4.8828e-04,  1.2207e-04,  ..., -6.1035e-04,\n",
      "         -8.5449e-04,  9.9945e-04],\n",
      "        [-8.5449e-04, -7.3242e-04, -1.2207e-04,  ..., -4.8828e-04,\n",
      "         -4.8828e-04,  1.8311e-04],\n",
      "        [-4.4250e-04, -8.3923e-04, -6.1035e-05,  ..., -4.5776e-04,\n",
      "          4.7302e-04,  4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.mlp.gate_proj.weight\n",
      "model.layers.8.mlp.up_proj.weight\n",
      "tensor([[ 9.1553e-04, -2.1362e-04, -3.9673e-04,  ..., -9.1553e-04,\n",
      "          1.0986e-03,  4.2725e-04],\n",
      "        [ 2.2888e-04, -5.4932e-04,  2.4414e-04,  ...,  4.8828e-04,\n",
      "          1.8311e-04, -2.4414e-04],\n",
      "        [ 1.2207e-04, -4.8828e-04,  9.1553e-05,  ..., -3.0518e-04,\n",
      "          7.6294e-06,  8.5449e-04],\n",
      "        ...,\n",
      "        [ 7.3242e-04,  4.2725e-04,  1.2207e-04,  ...,  4.7302e-04,\n",
      "          1.2207e-04,  7.9346e-04],\n",
      "        [-1.0071e-03,  1.8311e-04, -1.4038e-03,  ..., -4.8828e-04,\n",
      "         -6.8665e-05, -9.1553e-05],\n",
      "        [ 6.1035e-05, -3.0518e-04, -4.8828e-04,  ...,  7.4768e-04,\n",
      "          0.0000e+00,  5.1880e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.mlp.up_proj.weight\n",
      "model.layers.8.mlp.down_proj.weight\n",
      "tensor([[ 1.8501e-04, -9.1553e-05,  5.7983e-04,  ..., -4.9591e-04,\n",
      "         -2.4414e-04,  7.9346e-04],\n",
      "        [-3.6621e-04, -3.6621e-04,  4.5776e-04,  ...,  1.6785e-04,\n",
      "         -3.0518e-05,  1.0071e-03],\n",
      "        [-4.8828e-04, -3.6621e-04,  0.0000e+00,  ..., -4.5776e-04,\n",
      "          3.6621e-04, -7.3242e-04],\n",
      "        ...,\n",
      "        [ 7.6294e-04,  3.6621e-04, -8.5449e-04,  ..., -1.5259e-04,\n",
      "         -4.8828e-04, -5.7983e-04],\n",
      "        [-1.2207e-04, -2.4414e-04, -3.0518e-04,  ...,  0.0000e+00,\n",
      "          5.6458e-04,  3.6621e-04],\n",
      "        [-2.4033e-04,  1.2207e-04,  3.0518e-04,  ...,  1.5259e-05,\n",
      "         -6.1035e-05,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.mlp.down_proj.weight\n",
      "model.layers.8.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.input_layernorm.weight\n",
      "model.layers.8.post_attention_layernorm.weight\n",
      "tensor([-0.0020,  0.0000,  0.0000,  ...,  0.0000, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.8.post_attention_layernorm.weight\n",
      "model.layers.9.self_attn.q_proj.weight\n",
      "tensor([[ 3.0518e-05,  0.0000e+00,  1.1396e-04,  ..., -1.5259e-05,\n",
      "          0.0000e+00,  2.4414e-04],\n",
      "        [ 9.4604e-04, -8.5449e-04, -3.3569e-04,  ..., -1.2207e-03,\n",
      "         -3.0518e-04,  2.4414e-04],\n",
      "        [-3.6621e-04,  0.0000e+00, -5.4932e-04,  ...,  7.3242e-04,\n",
      "          4.8828e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [-7.3242e-04, -6.7139e-04,  1.8311e-04,  ...,  6.1035e-04,\n",
      "         -1.2207e-04, -7.3242e-04],\n",
      "        [ 1.2207e-03, -4.8828e-04, -1.2207e-04,  ...,  7.2479e-04,\n",
      "          4.1199e-04, -8.2397e-04],\n",
      "        [-4.8828e-04,  6.1035e-04, -9.1553e-05,  ...,  3.6049e-04,\n",
      "          1.2207e-04,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.self_attn.q_proj.weight\n",
      "model.layers.9.self_attn.k_proj.weight\n",
      "tensor([[-8.2397e-04, -3.6621e-04,  3.0518e-04,  ..., -7.3242e-04,\n",
      "          3.6621e-04, -1.2207e-04],\n",
      "        [-4.8828e-04,  9.1553e-04,  7.6294e-05,  ..., -6.7139e-04,\n",
      "         -1.2207e-04, -3.0518e-04],\n",
      "        [ 0.0000e+00,  1.0681e-03, -6.1035e-04,  ..., -1.2207e-04,\n",
      "         -4.3869e-04, -3.0518e-04],\n",
      "        ...,\n",
      "        [ 1.7090e-03,  5.1880e-04, -6.1035e-04,  ...,  1.2207e-04,\n",
      "         -4.2725e-04, -2.1362e-04],\n",
      "        [-3.0518e-04,  2.4414e-04,  0.0000e+00,  ..., -6.1035e-04,\n",
      "          0.0000e+00, -7.4768e-04],\n",
      "        [ 1.2207e-04,  5.1880e-04,  8.5449e-04,  ...,  4.8828e-04,\n",
      "         -7.3242e-04, -2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.self_attn.k_proj.weight\n",
      "model.layers.9.self_attn.v_proj.weight\n",
      "tensor([[-8.5449e-04, -8.2397e-04,  1.5259e-04,  ..., -1.8311e-04,\n",
      "          4.6730e-04, -9.7656e-04],\n",
      "        [ 1.2207e-04,  8.2397e-04, -6.7139e-04,  ...,  3.4332e-04,\n",
      "          1.8311e-04,  8.3923e-04],\n",
      "        [ 3.5858e-04, -6.1035e-05, -2.2888e-04,  ...,  5.5695e-04,\n",
      "          5.1880e-04,  1.0071e-03],\n",
      "        ...,\n",
      "        [ 1.8311e-04,  2.7466e-04, -6.7139e-04,  ..., -4.8065e-04,\n",
      "          2.2888e-04,  1.2207e-04],\n",
      "        [ 3.0518e-04,  3.4332e-04, -2.5177e-04,  ...,  6.5613e-04,\n",
      "          4.9973e-04, -3.0518e-05],\n",
      "        [-7.7820e-04, -2.4414e-04,  1.2207e-04,  ...,  1.8311e-04,\n",
      "          2.8992e-04,  6.7139e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.self_attn.v_proj.weight\n",
      "model.layers.9.self_attn.o_proj.weight\n",
      "tensor([[-4.4250e-04, -2.4414e-04,  3.6621e-04,  ...,  1.8311e-04,\n",
      "          1.6785e-04, -6.1035e-05],\n",
      "        [ 7.3242e-04, -4.2725e-04, -2.7466e-04,  ..., -3.0518e-04,\n",
      "          6.1035e-04, -7.3242e-04],\n",
      "        [ 3.6621e-04,  0.0000e+00,  1.9836e-04,  ..., -4.5776e-04,\n",
      "          4.1199e-04,  9.1553e-05],\n",
      "        ...,\n",
      "        [-2.1362e-04,  3.0518e-05, -1.2207e-04,  ..., -3.9673e-04,\n",
      "          2.3270e-04, -3.0518e-05],\n",
      "        [-4.1199e-04,  0.0000e+00, -2.4414e-04,  ..., -3.0518e-05,\n",
      "         -2.7466e-04,  2.5940e-04],\n",
      "        [-2.6321e-04,  6.1035e-05, -3.3569e-04,  ...,  1.5259e-04,\n",
      "         -1.2207e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.self_attn.o_proj.weight\n",
      "model.layers.9.mlp.gate_proj.weight\n",
      "tensor([[ 9.9182e-05,  2.4414e-04, -6.1035e-04,  ...,  8.0872e-04,\n",
      "          3.0518e-04, -6.2943e-04],\n",
      "        [-4.6539e-04,  1.2207e-04, -1.5259e-05,  ...,  3.6621e-04,\n",
      "          1.0681e-04, -5.4932e-04],\n",
      "        [ 9.7656e-04, -9.1553e-04,  1.8311e-04,  ..., -3.6621e-04,\n",
      "          2.4414e-04,  6.1035e-04],\n",
      "        ...,\n",
      "        [-4.5776e-05, -3.0518e-04, -7.3242e-04,  ...,  7.0190e-04,\n",
      "          5.4932e-04, -2.4414e-04],\n",
      "        [ 9.1553e-05,  5.4932e-04,  1.4648e-03,  ...,  0.0000e+00,\n",
      "         -2.4414e-04,  0.0000e+00],\n",
      "        [ 3.0518e-04, -4.8828e-04, -2.4414e-04,  ..., -5.1880e-04,\n",
      "         -9.1553e-04, -1.4782e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.mlp.gate_proj.weight\n",
      "model.layers.9.mlp.up_proj.weight\n",
      "tensor([[-4.8828e-04, -2.4414e-04,  0.0000e+00,  ...,  2.4414e-04,\n",
      "         -8.7738e-04,  1.2207e-04],\n",
      "        [ 9.1553e-05, -4.8828e-04, -3.8147e-04,  ...,  4.2725e-04,\n",
      "          3.5095e-04,  2.1362e-04],\n",
      "        [ 1.6022e-04, -3.0518e-04,  3.0518e-04,  ...,  1.0376e-03,\n",
      "         -2.1362e-04,  1.5259e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04, -1.6022e-04,  8.8501e-04,  ..., -4.2725e-04,\n",
      "          9.9182e-05, -1.2207e-04],\n",
      "        [-9.7656e-04,  1.7548e-04,  4.5776e-05,  ..., -5.7983e-04,\n",
      "          6.7139e-04, -3.0518e-04],\n",
      "        [-4.8828e-04,  6.4087e-04,  0.0000e+00,  ..., -7.3242e-04,\n",
      "          8.5449e-04,  5.7983e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.mlp.up_proj.weight\n",
      "model.layers.9.mlp.down_proj.weight\n",
      "tensor([[-2.4414e-04, -4.8828e-04, -6.8665e-05,  ..., -4.1962e-04,\n",
      "         -6.1035e-05,  5.4932e-04],\n",
      "        [ 9.1553e-04, -7.6294e-04, -3.3569e-04,  ...,  1.5259e-05,\n",
      "          2.4414e-04, -1.2207e-03],\n",
      "        [ 1.2207e-04, -6.1035e-05,  2.1362e-04,  ..., -6.0272e-04,\n",
      "          6.1035e-05,  6.8665e-04],\n",
      "        ...,\n",
      "        [ 6.7139e-04, -5.1880e-04, -6.7139e-04,  ...,  1.8311e-04,\n",
      "          2.4414e-04, -5.1880e-04],\n",
      "        [ 6.1035e-04,  3.0518e-04,  0.0000e+00,  ..., -1.8311e-04,\n",
      "          2.4414e-04, -6.2561e-04],\n",
      "        [-7.5150e-04, -1.2207e-04, -8.3923e-04,  ...,  6.1035e-04,\n",
      "          0.0000e+00, -2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.mlp.down_proj.weight\n",
      "model.layers.9.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.input_layernorm.weight\n",
      "model.layers.9.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0020, -0.0020,  ..., -0.0020,  0.0000, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.9.post_attention_layernorm.weight\n",
      "model.layers.10.self_attn.q_proj.weight\n",
      "tensor([[-3.6621e-04,  4.2725e-04,  6.1035e-04,  ..., -4.1962e-05,\n",
      "          3.6621e-04, -5.3406e-04],\n",
      "        [ 7.3242e-04, -2.4414e-04, -2.4414e-04,  ...,  1.2207e-04,\n",
      "         -1.0986e-03,  0.0000e+00],\n",
      "        [-3.0518e-04,  2.4414e-04,  7.3242e-04,  ...,  2.0218e-04,\n",
      "         -1.2207e-04, -8.8501e-04],\n",
      "        ...,\n",
      "        [-4.8828e-04, -3.6621e-04, -3.0518e-04,  ..., -4.8828e-04,\n",
      "         -3.9673e-04,  1.2207e-04],\n",
      "        [ 9.7656e-04,  6.1035e-04,  2.4414e-04,  ...,  2.4414e-04,\n",
      "         -2.4414e-04, -9.7656e-04],\n",
      "        [-4.8828e-04,  4.8828e-04, -4.8828e-04,  ...,  0.0000e+00,\n",
      "          3.6621e-04, -6.4087e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.self_attn.q_proj.weight\n",
      "model.layers.10.self_attn.k_proj.weight\n",
      "tensor([[ 1.0681e-04, -2.7466e-04,  1.2207e-04,  ...,  6.1035e-05,\n",
      "          3.0518e-05, -9.9182e-05],\n",
      "        [ 4.8828e-04, -6.7139e-04, -3.6621e-04,  ...,  6.1035e-05,\n",
      "          3.0518e-04, -1.8311e-04],\n",
      "        [ 4.1962e-04,  2.4414e-04,  1.4038e-03,  ...,  4.8828e-04,\n",
      "          1.2207e-04, -4.8828e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04,  7.3242e-04, -1.8311e-04,  ...,  1.2207e-04,\n",
      "          0.0000e+00,  1.2207e-04],\n",
      "        [ 7.3242e-04,  4.8828e-04, -2.4414e-04,  ...,  4.8828e-04,\n",
      "          2.4414e-04,  0.0000e+00],\n",
      "        [ 1.2207e-04, -4.8828e-04,  2.4414e-04,  ..., -7.3242e-04,\n",
      "         -1.2207e-04, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.self_attn.k_proj.weight\n",
      "model.layers.10.self_attn.v_proj.weight\n",
      "tensor([[ 6.1035e-05, -1.9836e-04,  5.9509e-04,  ..., -3.0518e-04,\n",
      "         -8.5449e-04,  2.4414e-04],\n",
      "        [ 1.8311e-04, -2.7466e-04,  3.3569e-04,  ..., -4.1199e-04,\n",
      "          0.0000e+00,  6.1035e-05],\n",
      "        [ 9.3460e-04,  6.7139e-04,  1.8692e-04,  ...,  0.0000e+00,\n",
      "          3.0518e-05, -9.1553e-05],\n",
      "        ...,\n",
      "        [-6.1035e-04,  1.5259e-05,  1.7929e-04,  ..., -1.5259e-05,\n",
      "         -2.7466e-04,  1.2207e-04],\n",
      "        [-1.2207e-04, -6.1035e-04, -2.7466e-04,  ..., -5.4932e-04,\n",
      "         -1.6022e-04,  1.2207e-04],\n",
      "        [-9.6130e-04, -6.1035e-04,  1.8311e-04,  ..., -7.6294e-05,\n",
      "          5.7983e-04, -1.5259e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.self_attn.v_proj.weight\n",
      "model.layers.10.self_attn.o_proj.weight\n",
      "tensor([[ 4.2725e-04, -9.1553e-05, -4.4250e-04,  ..., -7.3242e-04,\n",
      "          1.6403e-04,  4.2725e-04],\n",
      "        [ 3.0518e-04, -1.5259e-05,  5.1117e-04,  ..., -9.1553e-05,\n",
      "          7.6294e-05,  1.8311e-04],\n",
      "        [-9.7656e-04, -1.6022e-04,  9.1553e-05,  ..., -3.6621e-04,\n",
      "          8.8501e-04,  2.8992e-04],\n",
      "        ...,\n",
      "        [-1.2207e-04, -1.2207e-04, -6.1035e-05,  ...,  3.0518e-04,\n",
      "          1.2207e-04,  5.4932e-04],\n",
      "        [-6.2561e-04,  9.1553e-05, -6.1035e-05,  ..., -1.2207e-04,\n",
      "         -5.3406e-04, -1.0529e-03],\n",
      "        [-4.8828e-04,  9.1553e-05,  5.9891e-04,  ...,  1.2207e-04,\n",
      "          3.0518e-05,  9.1553e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.self_attn.o_proj.weight\n",
      "model.layers.10.mlp.gate_proj.weight\n",
      "tensor([[-3.0518e-05, -6.1035e-05,  3.8147e-05,  ..., -1.0376e-03,\n",
      "         -1.8311e-04, -6.1035e-05],\n",
      "        [-2.4414e-04,  4.6921e-04,  2.4414e-04,  ..., -2.4414e-04,\n",
      "          0.0000e+00,  4.2725e-04],\n",
      "        [ 0.0000e+00,  7.0190e-04,  2.4414e-04,  ..., -2.4414e-04,\n",
      "          0.0000e+00,  6.8665e-04],\n",
      "        ...,\n",
      "        [ 3.6621e-04, -6.1035e-04,  3.0518e-04,  ..., -7.9346e-04,\n",
      "          6.7139e-04,  5.0354e-04],\n",
      "        [ 5.4932e-04, -4.8828e-04, -9.7275e-04,  ...,  1.7929e-04,\n",
      "          1.0986e-03, -1.2207e-03],\n",
      "        [-2.1362e-04, -8.5449e-04, -3.0518e-05,  ..., -4.8828e-04,\n",
      "          2.4414e-04,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.mlp.gate_proj.weight\n",
      "model.layers.10.mlp.up_proj.weight\n",
      "tensor([[ 1.2207e-04,  3.6621e-04, -5.3787e-04,  ...,  6.1035e-05,\n",
      "         -2.5940e-04,  3.0518e-04],\n",
      "        [-4.5776e-04,  2.1362e-04,  1.8311e-04,  ...,  1.9836e-04,\n",
      "         -1.2207e-04, -9.7656e-04],\n",
      "        [-2.4414e-04,  3.6621e-04, -7.9346e-04,  ...,  6.1035e-05,\n",
      "         -4.8828e-04,  1.3351e-04],\n",
      "        ...,\n",
      "        [-7.7820e-04, -1.2207e-03,  7.3242e-04,  ..., -2.4414e-04,\n",
      "         -7.0190e-04, -3.6621e-04],\n",
      "        [-9.6512e-04, -1.0986e-03,  9.1553e-04,  ...,  3.0518e-04,\n",
      "         -1.1597e-03,  0.0000e+00],\n",
      "        [ 3.0518e-04, -6.5613e-04,  4.4632e-04,  ..., -7.6294e-04,\n",
      "         -4.8828e-04, -4.1199e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.mlp.up_proj.weight\n",
      "model.layers.10.mlp.down_proj.weight\n",
      "tensor([[-6.7139e-04,  5.4932e-04,  9.1553e-04,  ...,  1.2207e-04,\n",
      "         -1.5259e-04, -1.2207e-04],\n",
      "        [ 3.3569e-04,  1.2207e-04,  2.1362e-04,  ...,  1.2207e-04,\n",
      "          2.4414e-04,  1.2207e-04],\n",
      "        [-5.4932e-04,  1.2207e-04, -2.7466e-04,  ...,  4.8828e-04,\n",
      "          1.2207e-03, -2.5940e-04],\n",
      "        ...,\n",
      "        [-7.9346e-04,  3.0518e-04,  3.2425e-04,  ...,  3.6621e-04,\n",
      "         -3.0518e-04,  9.1553e-05],\n",
      "        [ 3.6621e-04,  2.2888e-04,  2.4414e-04,  ..., -1.1902e-03,\n",
      "          1.3733e-04, -3.0518e-04],\n",
      "        [-6.7139e-04, -3.6621e-04, -4.4250e-04,  ...,  3.0518e-05,\n",
      "          6.1035e-05, -4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.mlp.down_proj.weight\n",
      "model.layers.10.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.input_layernorm.weight\n",
      "model.layers.10.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.10.post_attention_layernorm.weight\n",
      "model.layers.11.self_attn.q_proj.weight\n",
      "tensor([[ 5.4932e-04,  6.1035e-05, -2.5940e-04,  ...,  2.4414e-04,\n",
      "         -4.8828e-04,  2.4414e-04],\n",
      "        [ 2.3651e-04,  6.1035e-05, -4.2725e-04,  ..., -1.8311e-04,\n",
      "         -3.0518e-04, -2.2888e-04],\n",
      "        [-1.2207e-04, -8.5449e-04,  3.6621e-04,  ..., -6.1035e-04,\n",
      "         -6.7139e-04, -3.0518e-04],\n",
      "        ...,\n",
      "        [-7.3242e-04,  4.5776e-04, -3.8147e-04,  ..., -3.6621e-04,\n",
      "          3.6621e-04,  7.3242e-04],\n",
      "        [-7.9346e-04, -3.0518e-04,  1.0681e-04,  ..., -4.5776e-04,\n",
      "          1.0967e-04,  0.0000e+00],\n",
      "        [ 5.3406e-04,  2.4414e-04, -1.0376e-03,  ...,  1.8311e-04,\n",
      "         -2.8992e-04, -1.8311e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.self_attn.q_proj.weight\n",
      "model.layers.11.self_attn.k_proj.weight\n",
      "tensor([[ 8.2397e-04,  2.9755e-04, -5.4932e-04,  ..., -6.1035e-05,\n",
      "         -4.5967e-04, -6.1035e-05],\n",
      "        [-2.7466e-04, -9.1553e-05,  2.7466e-04,  ..., -3.0518e-04,\n",
      "          1.2207e-04,  7.9346e-04],\n",
      "        [-7.3242e-04, -1.8311e-04,  7.9346e-04,  ..., -3.0518e-05,\n",
      "         -2.3270e-04, -1.2207e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  6.1035e-04,  2.4414e-04,  ...,  1.2207e-04,\n",
      "         -2.4414e-04,  2.4414e-04],\n",
      "        [ 0.0000e+00, -2.1362e-04, -3.6621e-04,  ...,  7.3242e-04,\n",
      "         -4.2725e-04, -1.8311e-04],\n",
      "        [-9.7656e-04, -3.6621e-04, -3.0518e-04,  ...,  9.7656e-04,\n",
      "         -8.5449e-04,  9.7656e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.self_attn.k_proj.weight\n",
      "model.layers.11.self_attn.v_proj.weight\n",
      "tensor([[ 4.8828e-04, -6.1035e-05, -7.6294e-05,  ...,  1.8311e-04,\n",
      "         -6.1798e-04, -3.0518e-04],\n",
      "        [-9.1553e-05, -2.7466e-04, -1.5259e-04,  ...,  4.2725e-04,\n",
      "          1.2589e-04, -5.6458e-04],\n",
      "        [ 1.5259e-04,  2.4414e-04, -1.9455e-04,  ..., -3.3569e-04,\n",
      "         -3.6049e-04, -5.4932e-04],\n",
      "        ...,\n",
      "        [ 1.3733e-04, -1.8311e-04, -3.0518e-04,  ..., -2.2888e-05,\n",
      "         -3.4332e-04, -1.2207e-04],\n",
      "        [-7.6294e-05,  2.8229e-04, -7.6294e-05,  ...,  8.5449e-04,\n",
      "         -1.2207e-04,  2.4414e-04],\n",
      "        [-3.8147e-05,  0.0000e+00,  4.2725e-04,  ..., -1.0986e-03,\n",
      "          3.9673e-04, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.self_attn.v_proj.weight\n",
      "model.layers.11.self_attn.o_proj.weight\n",
      "tensor([[-4.8828e-04, -6.1035e-05,  1.0681e-04,  ...,  3.6621e-04,\n",
      "         -4.2725e-04, -3.9673e-04],\n",
      "        [-3.6621e-04,  0.0000e+00, -2.4414e-04,  ..., -3.0518e-05,\n",
      "          7.9346e-04, -3.7956e-04],\n",
      "        [-1.1444e-04,  4.2725e-04,  2.4414e-04,  ...,  3.6621e-04,\n",
      "         -5.6458e-04,  6.1035e-04],\n",
      "        ...,\n",
      "        [-5.7983e-04,  3.9673e-04, -6.1035e-05,  ...,  2.4414e-04,\n",
      "         -4.5013e-04, -2.0218e-04],\n",
      "        [-6.1035e-04, -4.5586e-04, -4.8828e-04,  ...,  7.9346e-04,\n",
      "         -9.1553e-05,  4.7493e-04],\n",
      "        [-7.3242e-04, -3.0518e-05, -3.0518e-05,  ..., -4.8828e-04,\n",
      "         -1.2207e-04,  3.5095e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.self_attn.o_proj.weight\n",
      "model.layers.11.mlp.gate_proj.weight\n",
      "tensor([[ 2.0790e-04,  3.0518e-05,  4.4250e-04,  ..., -4.8065e-04,\n",
      "          6.1035e-05, -9.9182e-05],\n",
      "        [-2.9755e-04,  1.0986e-03, -4.8828e-04,  ...,  2.4414e-04,\n",
      "         -4.8828e-04,  2.2507e-04],\n",
      "        [-1.2207e-04,  2.1362e-04, -6.7139e-04,  ...,  4.2725e-04,\n",
      "          9.7656e-04,  3.9673e-04],\n",
      "        ...,\n",
      "        [-1.5259e-04,  1.5259e-04, -9.1553e-04,  ...,  7.6294e-05,\n",
      "         -1.2207e-03,  0.0000e+00],\n",
      "        [ 0.0000e+00, -4.2725e-04,  1.0376e-03,  ...,  7.3242e-04,\n",
      "          8.5449e-04, -5.6458e-04],\n",
      "        [-1.2207e-04,  3.0518e-04, -4.8828e-04,  ..., -1.3885e-03,\n",
      "         -7.3242e-04,  3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.mlp.gate_proj.weight\n",
      "model.layers.11.mlp.up_proj.weight\n",
      "tensor([[-2.3079e-04, -9.1553e-04, -1.7548e-04,  ...,  4.4250e-04,\n",
      "          6.1035e-04,  4.8828e-04],\n",
      "        [ 9.7656e-04, -4.8828e-04,  0.0000e+00,  ...,  2.7466e-04,\n",
      "          6.1035e-05,  0.0000e+00],\n",
      "        [ 7.8201e-04, -6.5613e-04, -3.0518e-04,  ...,  6.7139e-04,\n",
      "          5.7983e-04,  3.2043e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04, -4.8828e-04, -4.1199e-04,  ..., -5.1880e-04,\n",
      "          2.7466e-04,  1.8311e-04],\n",
      "        [ 6.1035e-05, -3.6621e-04, -3.0518e-04,  ...,  2.4414e-04,\n",
      "          6.1035e-04,  5.4932e-04],\n",
      "        [-6.1035e-05,  9.8419e-04,  1.2207e-04,  ...,  1.2207e-04,\n",
      "          9.1553e-05,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.mlp.up_proj.weight\n",
      "model.layers.11.mlp.down_proj.weight\n",
      "tensor([[-9.1553e-05, -1.5259e-04, -1.8311e-04,  ..., -3.6621e-04,\n",
      "          7.6294e-04, -3.0518e-04],\n",
      "        [-4.8828e-04, -3.4142e-04,  4.1199e-04,  ...,  3.9291e-04,\n",
      "         -6.1035e-05, -4.2725e-04],\n",
      "        [-1.1444e-04, -5.4932e-04, -9.3842e-04,  ..., -3.9673e-04,\n",
      "         -3.0518e-04, -7.3242e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -1.0834e-03,  8.5449e-04,  ..., -9.1553e-05,\n",
      "          6.1035e-04,  6.1035e-05],\n",
      "        [ 4.2725e-04,  6.1035e-04,  3.0518e-04,  ..., -9.7656e-04,\n",
      "         -6.1035e-05, -3.6621e-04],\n",
      "        [-1.2207e-04,  2.1362e-04,  1.7166e-04,  ...,  1.2207e-04,\n",
      "         -3.0518e-04, -3.0518e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.mlp.down_proj.weight\n",
      "model.layers.11.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0039, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.input_layernorm.weight\n",
      "model.layers.11.post_attention_layernorm.weight\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.11.post_attention_layernorm.weight\n",
      "model.layers.12.self_attn.q_proj.weight\n",
      "tensor([[-2.2888e-04,  1.8311e-04, -6.7139e-04,  ...,  3.6621e-04,\n",
      "         -1.8311e-04, -6.1035e-04],\n",
      "        [ 4.2725e-04,  1.2817e-03, -1.0986e-03,  ...,  8.8501e-04,\n",
      "         -3.1281e-04,  9.1553e-04],\n",
      "        [ 9.6893e-04,  3.6621e-04,  9.7656e-04,  ...,  1.4343e-03,\n",
      "         -2.4414e-04,  4.8828e-04],\n",
      "        ...,\n",
      "        [ 1.0986e-03, -3.6621e-04, -8.5449e-04,  ...,  5.4932e-04,\n",
      "          9.7656e-04, -2.4414e-04],\n",
      "        [ 2.4414e-04, -3.0518e-05,  3.9673e-04,  ..., -3.2234e-04,\n",
      "          2.4414e-04,  7.3242e-04],\n",
      "        [-2.4414e-04,  2.4414e-04,  6.1035e-05,  ...,  1.5259e-05,\n",
      "         -4.2725e-04,  4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.self_attn.q_proj.weight\n",
      "model.layers.12.self_attn.k_proj.weight\n",
      "tensor([[ 5.2643e-04,  1.0376e-03,  1.2207e-04,  ...,  1.0376e-03,\n",
      "         -9.1553e-05,  6.1035e-04],\n",
      "        [ 3.6621e-04, -4.8828e-04, -2.1362e-04,  ..., -2.4414e-04,\n",
      "          2.4414e-04, -1.1063e-04],\n",
      "        [-9.7656e-04,  2.4414e-04, -7.6294e-05,  ..., -6.1035e-04,\n",
      "          6.7139e-04,  4.4250e-04],\n",
      "        ...,\n",
      "        [ 7.3242e-04,  5.7983e-04,  5.4932e-04,  ...,  2.4414e-04,\n",
      "         -3.6621e-04, -5.4932e-04],\n",
      "        [-7.3242e-04,  3.6621e-04, -2.4414e-04,  ...,  3.6621e-04,\n",
      "         -2.4414e-04, -4.8828e-04],\n",
      "        [-6.2561e-04,  3.6621e-04,  0.0000e+00,  ..., -7.3242e-04,\n",
      "         -6.1035e-05,  7.9346e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.self_attn.k_proj.weight\n",
      "model.layers.12.self_attn.v_proj.weight\n",
      "tensor([[-8.3923e-05, -1.3733e-04, -7.9346e-04,  ...,  1.8311e-04,\n",
      "          6.1035e-05,  1.4877e-04],\n",
      "        [-4.2725e-04, -9.1553e-05,  1.8311e-04,  ...,  3.2043e-04,\n",
      "         -7.6294e-05, -6.8665e-05],\n",
      "        [ 2.7466e-04, -4.5776e-04, -4.1199e-04,  ...,  3.6621e-04,\n",
      "          6.5613e-04, -3.8147e-04],\n",
      "        ...,\n",
      "        [ 2.1744e-04, -2.3270e-04, -1.8311e-04,  ..., -2.4414e-04,\n",
      "          1.2207e-04,  4.1199e-04],\n",
      "        [ 1.8311e-04,  2.5940e-04, -1.2970e-04,  ...,  2.4414e-04,\n",
      "         -3.6621e-04, -3.3569e-04],\n",
      "        [-2.7466e-04,  2.4414e-04, -6.1035e-05,  ..., -6.1035e-04,\n",
      "         -6.5613e-04,  4.5776e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.self_attn.v_proj.weight\n",
      "model.layers.12.self_attn.o_proj.weight\n",
      "tensor([[-1.2207e-04,  2.4414e-04, -9.1553e-05,  ...,  4.4250e-04,\n",
      "          6.1035e-04,  4.5776e-04],\n",
      "        [-7.6294e-05,  5.4169e-04, -1.8311e-04,  ...,  2.5940e-04,\n",
      "         -1.8311e-04,  2.2888e-04],\n",
      "        [ 1.5259e-04, -4.8828e-04, -1.2207e-03,  ...,  6.5613e-04,\n",
      "         -7.0190e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [-1.7738e-04,  4.5776e-04,  3.0518e-05,  ..., -4.2725e-04,\n",
      "         -1.2207e-04, -1.8311e-04],\n",
      "        [-1.2207e-04, -2.4414e-04, -4.5013e-04,  ..., -1.2207e-04,\n",
      "         -3.9673e-04, -4.2725e-04],\n",
      "        [-6.1035e-05, -3.3569e-04,  2.4414e-04,  ...,  1.5259e-04,\n",
      "         -3.6621e-04, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.self_attn.o_proj.weight\n",
      "model.layers.12.mlp.gate_proj.weight\n",
      "tensor([[ 7.3242e-04,  3.2806e-04,  7.7820e-04,  ...,  7.6294e-04,\n",
      "          1.2207e-04,  8.7738e-04],\n",
      "        [ 7.7820e-04, -1.2207e-04, -7.6294e-04,  ..., -6.2561e-04,\n",
      "         -6.8665e-04, -6.1035e-05],\n",
      "        [-4.8828e-04,  3.6621e-04, -6.7139e-04,  ...,  6.1035e-04,\n",
      "         -9.9182e-04,  6.1035e-05],\n",
      "        ...,\n",
      "        [ 1.5259e-03,  4.8828e-04, -1.2207e-04,  ..., -5.4932e-04,\n",
      "          1.3123e-03,  6.1035e-04],\n",
      "        [ 3.6621e-04, -2.2888e-04, -1.2207e-03,  ..., -1.2207e-04,\n",
      "          3.8147e-04,  3.6621e-04],\n",
      "        [-9.6130e-04, -9.1553e-04,  4.8828e-04,  ..., -2.5940e-04,\n",
      "          1.5259e-04,  3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.mlp.gate_proj.weight\n",
      "model.layers.12.mlp.up_proj.weight\n",
      "tensor([[ 3.3569e-04, -5.5313e-04, -1.0147e-03,  ...,  1.2207e-04,\n",
      "         -1.2207e-04, -4.2725e-04],\n",
      "        [-1.1902e-03,  3.6621e-04, -3.4714e-04,  ..., -1.2207e-03,\n",
      "          3.0518e-05,  6.1035e-04],\n",
      "        [-3.3569e-04, -4.2725e-04, -1.4496e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00, -1.2207e-04],\n",
      "        ...,\n",
      "        [ 1.2207e-04, -1.6785e-04, -1.2207e-04,  ..., -7.3242e-04,\n",
      "          6.1035e-04,  6.1035e-05],\n",
      "        [ 1.6785e-04,  0.0000e+00,  9.1553e-05,  ...,  0.0000e+00,\n",
      "         -7.3242e-04, -9.1553e-04],\n",
      "        [-4.5776e-05,  5.1117e-04, -1.0986e-03,  ...,  8.5449e-04,\n",
      "          3.8910e-04,  7.3242e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.mlp.up_proj.weight\n",
      "model.layers.12.mlp.down_proj.weight\n",
      "tensor([[-4.8828e-04,  1.8311e-04,  6.1035e-05,  ...,  8.3160e-04,\n",
      "         -2.7466e-04,  1.4343e-03],\n",
      "        [ 3.6621e-04, -3.9673e-04, -2.4414e-04,  ..., -3.0518e-05,\n",
      "          4.2725e-04, -5.7983e-04],\n",
      "        [-1.9836e-04, -9.7656e-04, -2.4414e-04,  ...,  6.1035e-04,\n",
      "         -7.3242e-04,  8.2397e-04],\n",
      "        ...,\n",
      "        [ 2.8229e-04,  3.6621e-04, -2.4414e-04,  ...,  1.2207e-04,\n",
      "         -2.4414e-04,  1.2207e-04],\n",
      "        [-6.1035e-05,  1.2207e-04,  6.1035e-04,  ..., -4.2725e-04,\n",
      "          6.1035e-05, -5.1880e-04],\n",
      "        [-2.5940e-04,  5.4932e-04,  3.6621e-04,  ...,  3.6621e-04,\n",
      "          1.5259e-04,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.mlp.down_proj.weight\n",
      "model.layers.12.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.input_layernorm.weight\n",
      "model.layers.12.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0020,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.12.post_attention_layernorm.weight\n",
      "model.layers.13.self_attn.q_proj.weight\n",
      "tensor([[-2.4414e-04,  6.7139e-04,  3.0518e-05,  ...,  7.3242e-04,\n",
      "          1.5259e-05,  1.2207e-04],\n",
      "        [-1.2817e-03, -6.4087e-04, -3.0518e-04,  ...,  6.1035e-04,\n",
      "         -2.5177e-04,  0.0000e+00],\n",
      "        [-5.4932e-04,  2.4414e-04, -5.4932e-04,  ..., -1.0834e-03,\n",
      "         -3.3188e-04, -7.3242e-04],\n",
      "        ...,\n",
      "        [ 3.6621e-04,  0.0000e+00,  1.6212e-05,  ...,  4.2725e-04,\n",
      "         -1.8311e-04,  4.1962e-04],\n",
      "        [-5.5695e-04, -8.5449e-04,  2.4414e-04,  ..., -4.7302e-04,\n",
      "         -2.4414e-04,  2.4414e-04],\n",
      "        [ 3.0518e-04, -3.6621e-04, -1.0071e-03,  ...,  2.4414e-04,\n",
      "         -2.4414e-04, -6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.self_attn.q_proj.weight\n",
      "model.layers.13.self_attn.k_proj.weight\n",
      "tensor([[ 6.1035e-05,  4.1199e-04, -1.6689e-06,  ...,  5.6458e-04,\n",
      "          1.2512e-03, -8.5449e-04],\n",
      "        [ 4.2725e-04, -2.4414e-04,  6.1035e-04,  ...,  6.1035e-05,\n",
      "          1.8311e-04, -6.1035e-05],\n",
      "        [ 3.6621e-04, -2.4414e-04, -5.4932e-04,  ...,  2.8992e-04,\n",
      "          0.0000e+00, -7.9346e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04, -2.4414e-04, -2.4414e-04,  ..., -4.8828e-04,\n",
      "         -2.4414e-04,  2.7466e-04],\n",
      "        [ 1.2207e-03,  2.1362e-04,  8.5449e-04,  ...,  1.2207e-04,\n",
      "          7.6294e-04,  9.1553e-04],\n",
      "        [ 9.7656e-04, -7.3242e-04, -8.5449e-04,  ...,  7.3242e-04,\n",
      "         -8.8501e-04,  1.0986e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.self_attn.k_proj.weight\n",
      "model.layers.13.self_attn.v_proj.weight\n",
      "tensor([[-1.9836e-04, -1.8311e-04, -1.2207e-03,  ..., -2.4414e-04,\n",
      "          0.0000e+00,  3.0518e-05],\n",
      "        [-1.9073e-05, -4.8828e-04, -6.1035e-05,  ..., -3.9673e-04,\n",
      "         -1.2207e-04, -4.2725e-04],\n",
      "        [ 9.9182e-05,  3.0518e-05, -6.1035e-05,  ...,  4.5013e-04,\n",
      "         -2.1362e-04,  7.6294e-05],\n",
      "        ...,\n",
      "        [-6.1035e-05, -4.5776e-04,  3.6621e-04,  ..., -1.8311e-04,\n",
      "          9.1553e-05,  2.4414e-04],\n",
      "        [-2.8992e-04, -3.9673e-04, -2.2888e-04,  ...,  1.8311e-04,\n",
      "         -2.1362e-04, -1.8311e-04],\n",
      "        [ 1.8311e-04,  6.1035e-05,  6.1035e-05,  ...,  1.2207e-04,\n",
      "         -6.1035e-05, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.self_attn.v_proj.weight\n",
      "model.layers.13.self_attn.o_proj.weight\n",
      "tensor([[-2.4414e-04,  2.4414e-04,  0.0000e+00,  ..., -4.8828e-04,\n",
      "          0.0000e+00,  1.2207e-04],\n",
      "        [-6.1035e-05,  2.5940e-04, -1.8311e-04,  ..., -1.6785e-04,\n",
      "         -2.4414e-04,  4.2725e-04],\n",
      "        [ 0.0000e+00, -4.2725e-04,  1.0681e-04,  ..., -2.6512e-04,\n",
      "          9.1553e-05, -1.8311e-04],\n",
      "        ...,\n",
      "        [ 1.3638e-04, -8.5449e-04, -3.1281e-04,  ..., -2.4414e-04,\n",
      "         -2.4414e-04,  6.1035e-05],\n",
      "        [-2.2697e-04, -8.7738e-04, -4.8828e-04,  ...,  7.3242e-04,\n",
      "         -2.0981e-04, -5.4932e-04],\n",
      "        [-1.3733e-04, -3.6621e-04, -8.0109e-05,  ...,  2.7466e-04,\n",
      "         -4.5776e-04, -8.5831e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.self_attn.o_proj.weight\n",
      "model.layers.13.mlp.gate_proj.weight\n",
      "tensor([[-5.4932e-04, -8.5449e-04,  1.2207e-04,  ...,  9.1553e-04,\n",
      "          6.1035e-05,  0.0000e+00],\n",
      "        [ 1.0681e-04, -5.4932e-04, -2.7084e-04,  ..., -4.8828e-04,\n",
      "         -4.1199e-04, -3.6621e-04],\n",
      "        [ 4.8828e-04, -6.7139e-04,  6.1035e-05,  ...,  6.1035e-05,\n",
      "          2.4414e-04,  1.2207e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04,  3.3569e-04,  3.6621e-04,  ...,  0.0000e+00,\n",
      "         -3.3569e-04, -3.0518e-04],\n",
      "        [ 6.4850e-05, -2.4414e-04, -6.7139e-04,  ...,  1.2207e-04,\n",
      "         -1.2207e-03,  1.4496e-04],\n",
      "        [ 0.0000e+00, -6.1035e-05, -4.0817e-04,  ...,  5.1880e-04,\n",
      "         -7.9346e-04, -8.5449e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.mlp.gate_proj.weight\n",
      "model.layers.13.mlp.up_proj.weight\n",
      "tensor([[-1.0376e-03,  2.4414e-04,  8.5449e-04,  ..., -6.1035e-05,\n",
      "          3.0518e-04, -3.6621e-04],\n",
      "        [-3.2425e-05, -6.8283e-04, -7.3242e-04,  ..., -4.8828e-04,\n",
      "          6.1035e-05,  3.0518e-05],\n",
      "        [-7.3242e-04, -3.0518e-04, -4.5776e-04,  ...,  2.4414e-04,\n",
      "         -1.4420e-03,  9.6130e-04],\n",
      "        ...,\n",
      "        [ 3.5477e-04, -4.2725e-04,  2.4414e-04,  ...,  3.0518e-04,\n",
      "         -3.6621e-04, -8.4686e-04],\n",
      "        [-3.2806e-04,  9.5367e-04, -6.8665e-04,  ..., -1.8311e-04,\n",
      "          2.1362e-04, -2.1362e-04],\n",
      "        [-3.6621e-04,  8.7738e-04,  4.2725e-04,  ...,  3.0518e-04,\n",
      "          2.1362e-04,  6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.mlp.up_proj.weight\n",
      "model.layers.13.mlp.down_proj.weight\n",
      "tensor([[-4.5776e-04,  1.8311e-04,  7.3242e-04,  ...,  5.1880e-04,\n",
      "         -5.2643e-04, -9.6130e-04],\n",
      "        [ 6.7139e-04,  3.6621e-04, -7.6294e-04,  ..., -5.6458e-04,\n",
      "         -4.7302e-04,  5.4932e-04],\n",
      "        [ 5.4932e-04,  3.0518e-05,  2.8229e-04,  ...,  5.4932e-04,\n",
      "          4.2725e-04,  7.1716e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  4.8828e-04,  1.5259e-04,  ..., -1.8311e-04,\n",
      "         -3.3569e-04, -1.6785e-04],\n",
      "        [ 6.1035e-04,  2.1362e-04, -3.0518e-04,  ..., -9.1553e-04,\n",
      "          4.8828e-04,  3.6621e-04],\n",
      "        [-4.8828e-04,  4.8828e-04, -4.8828e-04,  ...,  1.1635e-04,\n",
      "          6.7139e-04, -1.8311e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.mlp.down_proj.weight\n",
      "model.layers.13.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0039, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.input_layernorm.weight\n",
      "model.layers.13.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.13.post_attention_layernorm.weight\n",
      "model.layers.14.self_attn.q_proj.weight\n",
      "tensor([[-1.8311e-04, -7.9346e-04, -3.6621e-04,  ...,  0.0000e+00,\n",
      "          9.3079e-04,  7.6294e-05],\n",
      "        [ 9.1553e-05,  3.6621e-04, -9.1553e-05,  ..., -8.5449e-04,\n",
      "          6.7139e-04,  8.5449e-04],\n",
      "        [-6.5994e-04, -4.2725e-04,  6.1035e-05,  ...,  6.1035e-05,\n",
      "          3.0518e-04,  1.2207e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  1.2207e-04,  6.1035e-04,  ...,  3.0518e-04,\n",
      "          0.0000e+00, -6.1035e-04],\n",
      "        [ 6.1035e-05,  1.8311e-04, -2.4414e-04,  ..., -2.4414e-04,\n",
      "         -6.1035e-05, -6.1035e-04],\n",
      "        [ 8.0109e-04,  0.0000e+00, -9.1553e-04,  ..., -4.8828e-04,\n",
      "          1.2207e-04,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.self_attn.q_proj.weight\n",
      "model.layers.14.self_attn.k_proj.weight\n",
      "tensor([[-3.2043e-04,  3.0518e-05, -4.2725e-04,  ...,  6.7139e-04,\n",
      "         -5.4932e-04, -2.4414e-04],\n",
      "        [-6.1035e-04, -6.1035e-04, -2.4414e-04,  ..., -6.4087e-04,\n",
      "          0.0000e+00,  9.7656e-04],\n",
      "        [ 1.1597e-03,  3.0518e-04, -1.5259e-04,  ...,  4.8828e-04,\n",
      "         -3.0518e-04, -2.7466e-04],\n",
      "        ...,\n",
      "        [-9.7656e-04,  3.2043e-04, -9.7656e-04,  ...,  4.8828e-04,\n",
      "          0.0000e+00,  7.3242e-04],\n",
      "        [ 7.9346e-04, -3.6621e-04, -1.2207e-04,  ..., -3.6621e-04,\n",
      "          6.7139e-04, -7.3242e-04],\n",
      "        [ 5.3406e-04,  7.3242e-04,  3.6621e-04,  ..., -1.1292e-03,\n",
      "          1.0986e-03,  2.1362e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.self_attn.k_proj.weight\n",
      "model.layers.14.self_attn.v_proj.weight\n",
      "tensor([[-5.1880e-04, -7.1049e-05, -5.4932e-04,  ...,  7.6294e-04,\n",
      "          4.7493e-04,  1.8311e-04],\n",
      "        [ 1.8311e-04,  3.9673e-04,  1.8311e-04,  ...,  3.0518e-04,\n",
      "         -3.6621e-04,  2.1362e-04],\n",
      "        [ 1.3733e-04,  2.4414e-04, -2.1362e-04,  ..., -2.1362e-04,\n",
      "         -9.1553e-05, -2.4414e-04],\n",
      "        ...,\n",
      "        [-2.7466e-04,  5.4932e-04,  2.7466e-04,  ...,  1.7166e-04,\n",
      "         -1.8311e-04, -4.8828e-04],\n",
      "        [ 1.8311e-04,  4.5776e-04, -6.1035e-05,  ...,  4.8828e-04,\n",
      "          1.6022e-04,  3.0518e-04],\n",
      "        [-1.8311e-04,  3.9673e-04,  0.0000e+00,  ...,  2.5940e-04,\n",
      "         -1.2207e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.self_attn.v_proj.weight\n",
      "model.layers.14.self_attn.o_proj.weight\n",
      "tensor([[ 2.4414e-04,  1.2207e-04,  6.0272e-04,  ..., -3.0518e-04,\n",
      "         -2.8992e-04, -3.0518e-04],\n",
      "        [ 4.8828e-04, -6.4087e-04,  0.0000e+00,  ..., -4.2725e-04,\n",
      "          5.4932e-04,  3.8862e-05],\n",
      "        [-7.2479e-04,  6.1035e-05,  3.8147e-05,  ...,  1.2207e-04,\n",
      "          2.4414e-04, -2.4414e-04],\n",
      "        ...,\n",
      "        [-1.3733e-04, -3.6240e-04, -4.8828e-04,  ..., -4.2725e-04,\n",
      "          3.6621e-04, -1.8311e-04],\n",
      "        [-3.3569e-04,  1.5259e-04,  4.8828e-04,  ...,  9.1553e-05,\n",
      "         -1.2207e-04,  6.1035e-05],\n",
      "        [ 1.2207e-04, -1.6785e-04, -5.6458e-04,  ...,  7.6294e-05,\n",
      "         -7.6294e-05,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.self_attn.o_proj.weight\n",
      "model.layers.14.mlp.gate_proj.weight\n",
      "tensor([[ 2.1362e-04,  2.4414e-04, -2.7466e-04,  ..., -1.0223e-03,\n",
      "         -6.1035e-04, -6.4087e-04],\n",
      "        [ 1.2207e-04,  6.7139e-04,  6.1798e-04,  ..., -6.1035e-05,\n",
      "          1.5259e-04, -2.2888e-05],\n",
      "        [-4.8828e-04,  4.8828e-04, -8.8501e-04,  ...,  4.5776e-04,\n",
      "         -1.4038e-03,  6.1035e-05],\n",
      "        ...,\n",
      "        [ 7.0572e-04, -1.4038e-03, -1.2207e-04,  ...,  9.7656e-04,\n",
      "         -1.8311e-04,  1.8311e-04],\n",
      "        [-2.4414e-04, -3.3569e-04,  3.9673e-04,  ...,  7.0190e-04,\n",
      "         -4.3488e-04,  5.4932e-04],\n",
      "        [-1.9836e-04, -9.1553e-05, -6.7139e-04,  ...,  1.0986e-03,\n",
      "         -8.7738e-04, -1.0376e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.mlp.gate_proj.weight\n",
      "model.layers.14.mlp.up_proj.weight\n",
      "tensor([[-4.5776e-05,  5.4932e-04,  2.7466e-04,  ...,  7.3242e-04,\n",
      "         -7.6294e-06, -9.1553e-05],\n",
      "        [-2.4414e-04,  6.1035e-05, -2.3651e-04,  ...,  4.2725e-04,\n",
      "          4.5776e-05,  1.8311e-04],\n",
      "        [-1.2207e-04, -5.1880e-04,  8.8501e-04,  ...,  5.4932e-04,\n",
      "         -1.2207e-04, -6.1035e-05],\n",
      "        ...,\n",
      "        [-4.8828e-04, -1.0071e-03, -2.4414e-04,  ..., -4.8828e-04,\n",
      "         -1.5259e-04,  8.5449e-04],\n",
      "        [-9.7656e-04, -3.0518e-04, -1.0872e-04,  ...,  7.6294e-05,\n",
      "          7.6294e-05, -4.8828e-04],\n",
      "        [-1.1292e-03,  0.0000e+00,  3.9673e-04,  ..., -3.4714e-04,\n",
      "          6.2561e-04, -7.0190e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.mlp.up_proj.weight\n",
      "model.layers.14.mlp.down_proj.weight\n",
      "tensor([[ 7.6294e-06, -7.3242e-04, -3.0518e-05,  ..., -1.0986e-03,\n",
      "          1.2207e-04, -3.6621e-04],\n",
      "        [-2.4414e-04, -4.8828e-04,  4.8828e-04,  ...,  7.5531e-04,\n",
      "          7.3242e-04,  1.2207e-04],\n",
      "        [-1.0986e-03,  7.3242e-04,  5.6458e-04,  ...,  2.1362e-04,\n",
      "          0.0000e+00, -3.6621e-04],\n",
      "        ...,\n",
      "        [-5.4932e-04,  0.0000e+00, -2.4414e-04,  ...,  4.2725e-04,\n",
      "          1.4648e-03,  6.7139e-04],\n",
      "        [-2.2888e-04, -1.5259e-04,  2.4414e-04,  ..., -8.5449e-04,\n",
      "          1.6785e-04,  9.7656e-04],\n",
      "        [-6.4087e-04, -3.6621e-04,  3.6621e-04,  ..., -3.6621e-04,\n",
      "         -6.1035e-04,  6.4087e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.mlp.down_proj.weight\n",
      "model.layers.14.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.input_layernorm.weight\n",
      "model.layers.14.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0020,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.14.post_attention_layernorm.weight\n",
      "model.layers.15.self_attn.q_proj.weight\n",
      "tensor([[ 8.9264e-04,  0.0000e+00, -1.2207e-04,  ..., -4.8828e-04,\n",
      "          7.3242e-04,  8.5449e-04],\n",
      "        [ 7.3242e-04,  6.1035e-04, -2.4414e-04,  ..., -1.8311e-04,\n",
      "          7.3242e-04,  3.6621e-04],\n",
      "        [ 1.2112e-04,  6.1035e-05,  2.7466e-04,  ..., -6.1035e-04,\n",
      "          5.4932e-04,  6.1035e-05],\n",
      "        ...,\n",
      "        [ 1.5869e-03, -6.1035e-04,  2.4414e-04,  ...,  6.1035e-05,\n",
      "          2.4414e-04, -1.6785e-04],\n",
      "        [ 1.2207e-04, -4.8828e-04,  5.7983e-04,  ...,  4.8828e-04,\n",
      "          1.8311e-04, -2.1362e-04],\n",
      "        [ 3.0518e-05,  7.6294e-04,  6.7139e-04,  ..., -1.5259e-04,\n",
      "          4.0436e-04, -3.0518e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.self_attn.q_proj.weight\n",
      "model.layers.15.self_attn.k_proj.weight\n",
      "tensor([[ 1.3428e-03, -8.5449e-04,  7.6294e-05,  ..., -7.6294e-06,\n",
      "          1.2207e-04, -5.7983e-04],\n",
      "        [ 0.0000e+00, -6.7139e-04, -8.6212e-04,  ..., -2.4414e-04,\n",
      "          1.1597e-03, -4.8828e-04],\n",
      "        [ 3.0518e-04,  3.6621e-04,  3.6621e-04,  ...,  3.0518e-04,\n",
      "         -2.4414e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  2.4414e-04, -3.5095e-04,  ...,  2.7466e-04,\n",
      "          4.8828e-04, -1.8311e-04],\n",
      "        [ 0.0000e+00,  4.8828e-04,  6.1035e-04,  ...,  0.0000e+00,\n",
      "         -2.8229e-04,  4.8828e-04],\n",
      "        [-2.4414e-04, -4.8828e-04, -1.2207e-04,  ..., -7.3242e-04,\n",
      "          4.2725e-04,  1.5259e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.self_attn.k_proj.weight\n",
      "model.layers.15.self_attn.v_proj.weight\n",
      "tensor([[-3.3569e-04,  1.5259e-04, -1.5259e-04,  ...,  4.4250e-04,\n",
      "          4.5776e-04, -1.8311e-04],\n",
      "        [ 9.1553e-05,  1.9836e-04,  7.0190e-04,  ...,  3.0518e-05,\n",
      "          1.2207e-04,  2.4414e-04],\n",
      "        [ 5.7983e-04,  0.0000e+00, -3.0518e-04,  ...,  6.1035e-05,\n",
      "         -6.1035e-05,  1.5259e-05],\n",
      "        ...,\n",
      "        [-3.6621e-04,  4.5776e-05,  2.5940e-04,  ..., -7.9346e-04,\n",
      "          4.5776e-04,  1.4782e-04],\n",
      "        [ 1.2207e-04,  1.1292e-03,  8.3923e-04,  ...,  6.1035e-04,\n",
      "         -1.5259e-04,  2.4414e-04],\n",
      "        [ 2.8992e-04,  6.7139e-04,  1.8311e-04,  ...,  6.1035e-04,\n",
      "          6.1035e-04, -1.0376e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.self_attn.v_proj.weight\n",
      "model.layers.15.self_attn.o_proj.weight\n",
      "tensor([[ 6.1035e-05,  7.2479e-04,  2.2888e-04,  ...,  3.8147e-04,\n",
      "          1.5869e-03, -8.5449e-04],\n",
      "        [ 1.5259e-04,  0.0000e+00,  2.6703e-04,  ..., -1.3733e-04,\n",
      "         -1.1444e-04, -4.8828e-04],\n",
      "        [-6.7139e-04, -1.8311e-04, -3.7384e-04,  ...,  5.5313e-04,\n",
      "          2.7657e-04, -2.7466e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-05, -5.4932e-04,  1.0071e-03,  ..., -1.9741e-04,\n",
      "          6.7139e-04, -5.6458e-04],\n",
      "        [-7.6294e-06,  6.1035e-05,  3.0518e-04,  ..., -5.7983e-04,\n",
      "          0.0000e+00,  6.2561e-04],\n",
      "        [ 9.1553e-05, -6.3705e-04, -3.3569e-04,  ..., -1.5259e-04,\n",
      "         -1.8311e-04,  9.0790e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.self_attn.o_proj.weight\n",
      "model.layers.15.mlp.gate_proj.weight\n",
      "tensor([[ 3.5095e-04, -4.5776e-05, -5.0354e-04,  ..., -3.6621e-04,\n",
      "         -2.1362e-04, -5.4932e-04],\n",
      "        [-6.1035e-04,  2.4414e-04, -3.8147e-04,  ...,  2.7466e-04,\n",
      "          8.5449e-04, -7.4005e-04],\n",
      "        [-7.4768e-04, -2.7466e-04,  5.6458e-04,  ..., -6.1035e-04,\n",
      "          4.5776e-04, -6.1035e-05],\n",
      "        ...,\n",
      "        [ 1.0605e-03, -4.4250e-04, -4.5776e-04,  ...,  3.8147e-05,\n",
      "          1.8311e-04,  7.9346e-04],\n",
      "        [-4.8828e-04, -8.5449e-04, -9.1553e-05,  ...,  3.0518e-05,\n",
      "          3.0518e-05, -7.3242e-04],\n",
      "        [-3.6621e-04,  1.8311e-04,  1.1292e-03,  ...,  3.0518e-05,\n",
      "         -1.2207e-04, -8.2397e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.mlp.gate_proj.weight\n",
      "model.layers.15.mlp.up_proj.weight\n",
      "tensor([[-4.2725e-04,  1.9836e-04,  1.2207e-04,  ..., -9.1553e-04,\n",
      "         -5.4932e-04, -3.7384e-04],\n",
      "        [-7.9346e-04,  1.8311e-04,  8.6212e-04,  ..., -2.2888e-04,\n",
      "          1.8311e-04,  4.8828e-04],\n",
      "        [-2.6321e-04,  6.1035e-04,  3.6621e-04,  ..., -6.2561e-04,\n",
      "         -1.2207e-04,  4.2725e-04],\n",
      "        ...,\n",
      "        [ 3.3569e-04,  2.7466e-04, -3.5095e-04,  ..., -2.2888e-04,\n",
      "         -8.2397e-04, -6.1035e-05],\n",
      "        [ 2.4414e-04,  4.2725e-04, -7.7057e-04,  ..., -1.0681e-04,\n",
      "         -2.4414e-04,  2.4414e-04],\n",
      "        [ 9.1553e-05,  1.3733e-04,  1.2207e-04,  ..., -6.1035e-05,\n",
      "         -2.8992e-04,  6.4087e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.mlp.up_proj.weight\n",
      "model.layers.15.mlp.down_proj.weight\n",
      "tensor([[-5.1880e-04, -2.1362e-04,  5.5695e-04,  ...,  4.8828e-04,\n",
      "          0.0000e+00, -2.4414e-04],\n",
      "        [ 4.7302e-04,  1.2207e-04,  4.5776e-04,  ..., -9.7656e-04,\n",
      "          3.0518e-05, -3.0518e-05],\n",
      "        [ 2.4414e-04,  0.0000e+00,  1.2207e-04,  ...,  5.4932e-04,\n",
      "         -3.0518e-04, -3.0518e-05],\n",
      "        ...,\n",
      "        [-3.6621e-04,  1.2207e-04, -4.6539e-04,  ...,  1.2207e-04,\n",
      "         -3.6621e-04,  9.1553e-05],\n",
      "        [-1.8311e-04, -9.1553e-05,  4.5776e-04,  ...,  8.2397e-04,\n",
      "         -4.2725e-04,  2.4414e-04],\n",
      "        [-6.1035e-04, -2.7466e-04,  1.4954e-03,  ..., -2.4414e-04,\n",
      "          3.0518e-04,  6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.mlp.down_proj.weight\n",
      "model.layers.15.input_layernorm.weight\n",
      "tensor([-0.0039, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.input_layernorm.weight\n",
      "model.layers.15.post_attention_layernorm.weight\n",
      "tensor([-0.0020,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.15.post_attention_layernorm.weight\n",
      "model.layers.16.self_attn.q_proj.weight\n",
      "tensor([[ 4.2725e-04,  7.0190e-04, -8.6212e-04,  ..., -3.6621e-04,\n",
      "          4.2725e-04, -4.2725e-04],\n",
      "        [-1.0376e-03, -4.8828e-04,  1.9836e-04,  ...,  3.2806e-04,\n",
      "         -5.7983e-04, -3.0518e-04],\n",
      "        [ 7.9346e-04, -3.3569e-04,  6.1035e-04,  ...,  8.2397e-04,\n",
      "         -6.1035e-05,  4.4250e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04, -1.8311e-04,  1.0681e-04,  ...,  6.7139e-04,\n",
      "         -3.8147e-04, -1.2207e-04],\n",
      "        [-1.8311e-04,  9.1553e-04, -5.9509e-04,  ...,  7.3242e-04,\n",
      "          1.2207e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  6.7139e-04,  1.2207e-04,  ...,  4.2725e-04,\n",
      "         -1.2207e-04, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.self_attn.q_proj.weight\n",
      "model.layers.16.self_attn.k_proj.weight\n",
      "tensor([[ 1.9836e-04,  4.1199e-04,  3.5095e-04,  ...,  6.1035e-05,\n",
      "          7.3242e-04, -2.4414e-04],\n",
      "        [ 1.1902e-03, -1.5259e-04, -6.1035e-04,  ...,  3.3569e-04,\n",
      "         -3.0518e-05,  1.8311e-04],\n",
      "        [-5.4932e-04,  1.0376e-03, -6.1035e-04,  ..., -4.5776e-04,\n",
      "          6.1035e-04, -1.1597e-03],\n",
      "        ...,\n",
      "        [ 4.2725e-04,  7.3242e-04, -3.5858e-04,  ...,  1.2207e-04,\n",
      "          0.0000e+00, -2.4414e-04],\n",
      "        [ 7.3242e-04, -4.8828e-04, -6.1035e-05,  ...,  1.5259e-03,\n",
      "         -6.1035e-05,  8.5449e-04],\n",
      "        [-3.6621e-04,  3.6621e-04, -3.6621e-04,  ...,  3.6240e-04,\n",
      "          4.8828e-04,  2.2888e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.self_attn.k_proj.weight\n",
      "model.layers.16.self_attn.v_proj.weight\n",
      "tensor([[ 4.2725e-04, -1.8311e-04,  1.8311e-04,  ..., -7.6294e-04,\n",
      "          1.4496e-04, -4.0817e-04],\n",
      "        [ 5.4932e-04, -2.7466e-04, -7.3242e-04,  ..., -7.9346e-04,\n",
      "         -4.2725e-04, -1.5259e-04],\n",
      "        [ 2.6703e-04,  2.9755e-04, -4.5776e-05,  ...,  3.0518e-04,\n",
      "         -1.2207e-04,  1.2207e-04],\n",
      "        ...,\n",
      "        [-6.2561e-04,  8.5449e-04,  0.0000e+00,  ..., -1.2302e-04,\n",
      "          2.4414e-04,  4.2725e-04],\n",
      "        [-4.2725e-04,  1.0300e-04, -7.7820e-04,  ..., -4.7302e-04,\n",
      "          0.0000e+00,  1.2207e-04],\n",
      "        [-6.1035e-04, -3.6621e-04, -2.3270e-04,  ..., -5.6458e-04,\n",
      "         -6.1035e-05, -6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.self_attn.v_proj.weight\n",
      "model.layers.16.self_attn.o_proj.weight\n",
      "tensor([[ 0.0000e+00,  8.5449e-04,  5.1880e-04,  ...,  1.2207e-04,\n",
      "         -1.5259e-04, -3.9291e-04],\n",
      "        [ 4.8828e-04, -7.9346e-04,  3.6621e-04,  ...,  1.3733e-04,\n",
      "          6.1035e-05, -3.9673e-04],\n",
      "        [-7.3242e-04,  0.0000e+00, -6.1035e-05,  ...,  2.1935e-04,\n",
      "          2.7466e-04, -2.1362e-04],\n",
      "        ...,\n",
      "        [-6.7139e-04,  3.6621e-04, -2.4414e-04,  ..., -8.5449e-04,\n",
      "         -8.8501e-04,  5.7983e-04],\n",
      "        [ 6.1035e-05,  3.6621e-04, -3.0518e-05,  ..., -3.0518e-05,\n",
      "          3.0518e-05, -3.0518e-05],\n",
      "        [ 3.8147e-04,  2.8229e-04, -1.2207e-04,  ...,  0.0000e+00,\n",
      "          3.0518e-05,  3.2806e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.self_attn.o_proj.weight\n",
      "model.layers.16.mlp.gate_proj.weight\n",
      "tensor([[-1.0986e-03, -1.4305e-04, -1.3123e-03,  ...,  2.4414e-04,\n",
      "          9.7656e-04,  9.1553e-04],\n",
      "        [-1.0986e-03, -5.4932e-04, -5.4932e-04,  ..., -1.0986e-03,\n",
      "          0.0000e+00,  9.7656e-04],\n",
      "        [-7.3242e-04,  0.0000e+00,  1.0681e-03,  ...,  6.8665e-04,\n",
      "         -5.1880e-04, -5.4932e-04],\n",
      "        ...,\n",
      "        [ 1.2207e-04, -4.2725e-04,  6.1035e-04,  ..., -1.7548e-04,\n",
      "          3.6621e-04, -3.2425e-04],\n",
      "        [ 2.4414e-04,  3.0518e-04,  0.0000e+00,  ..., -5.6458e-04,\n",
      "          7.9346e-04,  1.2512e-03],\n",
      "        [-3.6621e-04, -2.2888e-04, -3.7384e-04,  ..., -2.4414e-04,\n",
      "         -4.8828e-04, -9.1553e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.mlp.gate_proj.weight\n",
      "model.layers.16.mlp.up_proj.weight\n",
      "tensor([[ 1.4648e-03,  6.7139e-04, -1.3046e-03,  ..., -9.0027e-04,\n",
      "          4.8828e-04,  7.9346e-04],\n",
      "        [ 6.1035e-05,  4.8828e-04,  1.5259e-05,  ...,  1.8311e-04,\n",
      "          1.0681e-03,  3.0518e-04],\n",
      "        [-7.8583e-04,  1.3733e-04, -6.1035e-04,  ..., -3.0518e-04,\n",
      "         -1.8311e-04, -2.7466e-04],\n",
      "        ...,\n",
      "        [-1.4038e-03, -2.1362e-04,  1.8311e-04,  ..., -5.7983e-04,\n",
      "          6.1035e-04,  7.3242e-04],\n",
      "        [ 3.0518e-04,  1.8311e-04, -6.7139e-04,  ...,  1.1215e-03,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.2207e-04, -8.5449e-04,  1.8311e-04,  ...,  1.2207e-03,\n",
      "          1.8311e-04,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.mlp.up_proj.weight\n",
      "model.layers.16.mlp.down_proj.weight\n",
      "tensor([[-3.6621e-04, -7.9346e-04, -4.8828e-04,  ...,  1.6937e-03,\n",
      "          3.0518e-05,  0.0000e+00],\n",
      "        [-1.2207e-04, -3.3569e-04, -2.2125e-04,  ...,  7.9346e-04,\n",
      "         -2.1362e-04,  0.0000e+00],\n",
      "        [ 5.6076e-04,  5.9128e-04, -4.8828e-04,  ..., -4.8828e-04,\n",
      "          9.6130e-04,  5.8746e-04],\n",
      "        ...,\n",
      "        [-1.1826e-03, -2.4414e-04, -5.3406e-04,  ...,  1.2207e-04,\n",
      "         -3.6621e-04,  6.1035e-04],\n",
      "        [ 0.0000e+00, -1.2970e-04, -5.4932e-04,  ..., -4.4823e-05,\n",
      "          1.1444e-04,  5.0354e-04],\n",
      "        [-6.7139e-04, -1.4496e-04,  1.8311e-04,  ...,  4.5776e-04,\n",
      "         -9.1553e-05, -3.9673e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.mlp.down_proj.weight\n",
      "model.layers.16.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.input_layernorm.weight\n",
      "model.layers.16.post_attention_layernorm.weight\n",
      "tensor([-0.0020,  0.0000, -0.0020,  ...,  0.0000, -0.0020,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.16.post_attention_layernorm.weight\n",
      "model.layers.17.self_attn.q_proj.weight\n",
      "tensor([[-1.2207e-04,  4.7302e-04, -4.8828e-04,  ...,  1.8311e-04,\n",
      "          8.8501e-04,  3.1281e-04],\n",
      "        [ 1.0376e-03, -1.0376e-03, -7.9727e-04,  ...,  0.0000e+00,\n",
      "          9.9945e-04,  7.3242e-04],\n",
      "        [-1.5259e-04, -6.1035e-04, -3.8528e-04,  ...,  6.1035e-05,\n",
      "         -1.2207e-04,  1.2207e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04,  3.6621e-04,  4.8828e-04,  ..., -2.1362e-04,\n",
      "          6.1035e-05, -3.6621e-04],\n",
      "        [-6.1035e-04, -2.7466e-04, -7.3242e-04,  ...,  4.8828e-04,\n",
      "         -2.4414e-04, -2.4414e-04],\n",
      "        [ 2.4414e-04,  1.8311e-04,  1.2817e-03,  ..., -3.6621e-04,\n",
      "         -5.1880e-04,  2.1362e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.self_attn.q_proj.weight\n",
      "model.layers.17.self_attn.k_proj.weight\n",
      "tensor([[ 3.6621e-04, -1.2207e-04,  1.8311e-04,  ..., -2.4414e-04,\n",
      "          3.0518e-04,  0.0000e+00],\n",
      "        [ 6.7139e-04,  2.7466e-04, -6.1035e-05,  ..., -3.0518e-04,\n",
      "          0.0000e+00,  2.4414e-04],\n",
      "        [ 3.6621e-04,  9.0027e-04, -1.2207e-04,  ..., -4.0436e-04,\n",
      "          6.1035e-04, -2.4414e-04],\n",
      "        ...,\n",
      "        [-2.1362e-04, -3.2043e-04, -9.7656e-04,  ..., -1.2207e-04,\n",
      "         -7.3242e-04,  1.8311e-04],\n",
      "        [ 4.8828e-04,  9.7656e-04,  4.8828e-04,  ...,  7.3242e-04,\n",
      "          6.1035e-04,  7.3242e-04],\n",
      "        [-4.9591e-04,  3.6621e-04,  9.7656e-04,  ...,  4.1962e-04,\n",
      "         -9.7656e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.self_attn.k_proj.weight\n",
      "model.layers.17.self_attn.v_proj.weight\n",
      "tensor([[-5.6458e-04, -7.3242e-04,  0.0000e+00,  ...,  3.0518e-04,\n",
      "         -4.5776e-05, -8.9645e-04],\n",
      "        [ 5.4932e-04,  2.4414e-04, -2.3651e-04,  ..., -2.7275e-04,\n",
      "          6.0558e-05,  2.4414e-04],\n",
      "        [-7.6294e-04, -3.0518e-04,  4.8065e-04,  ..., -3.6621e-04,\n",
      "         -2.4414e-04,  1.0986e-03],\n",
      "        ...,\n",
      "        [ 6.5613e-04, -6.1035e-05, -2.1362e-04,  ..., -1.1444e-04,\n",
      "          1.5259e-04, -7.3242e-04],\n",
      "        [-4.8828e-04, -1.8311e-04,  0.0000e+00,  ...,  1.0681e-04,\n",
      "         -2.4414e-04,  3.5095e-04],\n",
      "        [ 2.4414e-04,  1.5259e-04,  1.8311e-04,  ...,  0.0000e+00,\n",
      "          6.6757e-05, -1.5259e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.self_attn.v_proj.weight\n",
      "model.layers.17.self_attn.o_proj.weight\n",
      "tensor([[ 3.0518e-04, -6.7139e-04,  0.0000e+00,  ..., -5.0354e-04,\n",
      "          6.1035e-04,  1.2207e-04],\n",
      "        [-6.1035e-04, -4.5776e-04, -6.7139e-04,  ..., -5.1880e-04,\n",
      "          0.0000e+00, -3.0518e-04],\n",
      "        [-6.7139e-04,  8.5449e-04,  2.7466e-04,  ..., -2.4414e-04,\n",
      "          5.3406e-04,  5.0354e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04, -3.3569e-04, -3.0518e-04,  ...,  1.5259e-04,\n",
      "          4.5776e-05, -1.8311e-04],\n",
      "        [ 5.4932e-04,  1.5259e-05, -6.1035e-05,  ..., -1.2207e-04,\n",
      "          3.3569e-04,  1.2207e-04],\n",
      "        [ 0.0000e+00,  3.8147e-04, -2.0599e-04,  ...,  1.5259e-05,\n",
      "          3.6621e-04,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.self_attn.o_proj.weight\n",
      "model.layers.17.mlp.gate_proj.weight\n",
      "tensor([[-0.0002, -0.0002,  0.0003,  ..., -0.0005, -0.0002, -0.0004],\n",
      "        [-0.0007, -0.0006,  0.0001,  ..., -0.0002,  0.0006, -0.0004],\n",
      "        [-0.0008,  0.0005,  0.0002,  ..., -0.0006,  0.0001,  0.0005],\n",
      "        ...,\n",
      "        [ 0.0009,  0.0006,  0.0004,  ..., -0.0002, -0.0001, -0.0004],\n",
      "        [ 0.0006, -0.0002,  0.0013,  ..., -0.0001,  0.0005, -0.0006],\n",
      "        [-0.0008,  0.0008,  0.0002,  ...,  0.0003,  0.0010,  0.0000]],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.mlp.gate_proj.weight\n",
      "model.layers.17.mlp.up_proj.weight\n",
      "tensor([[-1.8311e-04, -4.8828e-04, -5.7983e-04,  ...,  1.5259e-04,\n",
      "          1.1063e-04, -2.4414e-04],\n",
      "        [-1.2207e-04,  1.6785e-04,  6.7139e-04,  ..., -1.2512e-03,\n",
      "          1.2207e-04,  6.1035e-05],\n",
      "        [-6.1035e-05,  4.8828e-04, -1.2207e-04,  ..., -2.1362e-04,\n",
      "         -6.1035e-04,  3.0518e-05],\n",
      "        ...,\n",
      "        [-3.0518e-04,  9.7656e-04, -1.0071e-03,  ..., -7.9346e-04,\n",
      "         -2.4414e-04, -6.1035e-05],\n",
      "        [-7.9346e-04, -1.3428e-03,  4.8828e-04,  ..., -3.3569e-04,\n",
      "         -3.0518e-05,  2.2888e-04],\n",
      "        [-4.8828e-04,  7.0190e-04,  1.8311e-04,  ...,  2.4414e-04,\n",
      "         -1.2207e-04,  1.5259e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.mlp.up_proj.weight\n",
      "model.layers.17.mlp.down_proj.weight\n",
      "tensor([[-3.0518e-04,  4.8828e-04, -5.7983e-04,  ...,  0.0000e+00,\n",
      "         -5.4932e-04, -6.7139e-04],\n",
      "        [ 1.2207e-04,  2.2125e-04, -2.1362e-04,  ..., -4.2725e-04,\n",
      "         -6.1035e-05, -5.7983e-04],\n",
      "        [ 8.5449e-04, -2.4414e-04,  2.4414e-04,  ...,  7.9346e-04,\n",
      "         -2.4414e-04, -1.2207e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04,  9.7656e-04,  3.0518e-05,  ..., -4.1962e-04,\n",
      "         -3.6621e-04,  8.4686e-04],\n",
      "        [ 4.5776e-05,  1.8311e-04,  9.1553e-05,  ..., -1.2207e-04,\n",
      "          2.4414e-04,  2.4414e-04],\n",
      "        [ 9.7656e-04,  7.6294e-04, -2.4414e-04,  ...,  2.1362e-04,\n",
      "          3.6621e-04, -3.2043e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.mlp.down_proj.weight\n",
      "model.layers.17.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.input_layernorm.weight\n",
      "model.layers.17.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.17.post_attention_layernorm.weight\n",
      "model.layers.18.self_attn.q_proj.weight\n",
      "tensor([[ 6.1035e-04,  2.4414e-04,  1.2207e-04,  ...,  3.0518e-04,\n",
      "          1.6785e-04,  7.3242e-04],\n",
      "        [-3.2043e-04, -3.3569e-04, -1.0986e-03,  ...,  1.6785e-04,\n",
      "         -1.8311e-04,  4.5776e-04],\n",
      "        [-1.2207e-04, -6.8665e-05,  6.1035e-04,  ...,  0.0000e+00,\n",
      "         -5.3406e-05,  6.1035e-05],\n",
      "        ...,\n",
      "        [ 3.0518e-04,  4.2725e-04,  1.1673e-03,  ..., -3.6621e-04,\n",
      "          1.6785e-04,  3.6621e-04],\n",
      "        [-1.1444e-04, -1.8311e-04, -1.2207e-03,  ..., -6.1035e-04,\n",
      "         -2.8992e-04, -1.5259e-04],\n",
      "        [-8.5449e-04, -1.8005e-03,  4.8828e-04,  ..., -5.7983e-04,\n",
      "          0.0000e+00, -1.8921e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.self_attn.q_proj.weight\n",
      "model.layers.18.self_attn.k_proj.weight\n",
      "tensor([[ 7.3242e-04,  0.0000e+00, -3.6621e-04,  ..., -2.4414e-04,\n",
      "         -9.1553e-05, -2.4414e-04],\n",
      "        [ 5.7983e-04,  0.0000e+00,  0.0000e+00,  ...,  1.2207e-03,\n",
      "          0.0000e+00,  2.4414e-04],\n",
      "        [-1.2207e-04,  4.8828e-04,  1.1749e-03,  ...,  9.7656e-04,\n",
      "          6.1035e-04, -4.8828e-04],\n",
      "        ...,\n",
      "        [-1.1749e-03,  1.4191e-03, -9.7656e-04,  ..., -6.1035e-04,\n",
      "          3.6621e-04,  1.2207e-04],\n",
      "        [ 3.5858e-04, -9.7656e-04,  2.4414e-04,  ..., -2.4414e-04,\n",
      "          4.8828e-04,  0.0000e+00],\n",
      "        [ 2.4414e-04,  1.8311e-04, -4.8828e-04,  ...,  0.0000e+00,\n",
      "          2.4414e-04, -7.3242e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.self_attn.k_proj.weight\n",
      "model.layers.18.self_attn.v_proj.weight\n",
      "tensor([[ 6.1035e-05,  1.5259e-04,  1.2207e-04,  ...,  1.8311e-04,\n",
      "         -5.4932e-04,  1.2207e-04],\n",
      "        [ 1.8311e-04, -1.8311e-04, -1.8311e-04,  ...,  1.5259e-05,\n",
      "          6.1035e-05,  5.2643e-04],\n",
      "        [ 5.1880e-04,  1.0681e-04,  4.8828e-04,  ...,  3.0518e-05,\n",
      "         -2.1362e-04, -9.4604e-04],\n",
      "        ...,\n",
      "        [ 7.3242e-04,  0.0000e+00,  3.8147e-06,  ..., -2.7466e-04,\n",
      "          0.0000e+00, -1.1597e-03],\n",
      "        [ 1.2207e-04,  3.5095e-04,  1.4114e-04,  ...,  4.5776e-04,\n",
      "         -1.5259e-04, -3.8147e-04],\n",
      "        [-5.7983e-04,  3.0518e-04,  7.6294e-05,  ...,  0.0000e+00,\n",
      "          3.0518e-04, -9.1553e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.self_attn.v_proj.weight\n",
      "model.layers.18.self_attn.o_proj.weight\n",
      "tensor([[-9.7656e-04,  2.4414e-04,  3.5095e-04,  ...,  7.6294e-04,\n",
      "          3.0518e-04,  6.1035e-04],\n",
      "        [ 3.8910e-04,  3.9673e-04, -5.1880e-04,  ..., -2.4414e-04,\n",
      "          6.1035e-04, -1.8311e-04],\n",
      "        [ 6.1035e-05,  6.1035e-05,  2.1362e-04,  ...,  6.1035e-05,\n",
      "          2.4414e-04, -2.0294e-03],\n",
      "        ...,\n",
      "        [-8.5449e-04, -3.6621e-04,  8.8501e-04,  ..., -7.9346e-04,\n",
      "          7.3242e-04, -7.3242e-04],\n",
      "        [-9.1553e-05,  3.0518e-04, -4.8828e-04,  ..., -8.5449e-04,\n",
      "          1.2207e-04,  2.4414e-04],\n",
      "        [ 3.6621e-04, -2.7466e-04,  4.8828e-04,  ..., -3.2043e-04,\n",
      "          7.3242e-04,  1.0376e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.self_attn.o_proj.weight\n",
      "model.layers.18.mlp.gate_proj.weight\n",
      "tensor([[ 1.5259e-04,  1.8311e-04, -3.3569e-04,  ...,  2.4414e-04,\n",
      "         -1.2207e-04,  1.2207e-04],\n",
      "        [-4.8828e-04,  7.3242e-04,  4.8828e-04,  ...,  3.6621e-04,\n",
      "         -4.8828e-04, -7.3242e-04],\n",
      "        [ 1.2207e-04, -1.2207e-04,  1.3733e-04,  ...,  3.6621e-04,\n",
      "          1.9836e-04, -9.7656e-04],\n",
      "        ...,\n",
      "        [-8.6594e-04,  8.5449e-04,  6.7139e-04,  ...,  4.4250e-04,\n",
      "          6.7139e-04,  1.2207e-03],\n",
      "        [-6.1035e-04,  5.6458e-04, -1.6708e-03,  ..., -5.1117e-04,\n",
      "         -2.2888e-05,  1.8311e-04],\n",
      "        [-3.6621e-04,  9.7656e-04, -7.3242e-04,  ..., -2.4414e-04,\n",
      "         -7.6294e-04, -6.7139e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.mlp.gate_proj.weight\n",
      "model.layers.18.mlp.up_proj.weight\n",
      "tensor([[-5.7983e-04,  0.0000e+00,  1.8311e-04,  ...,  2.5940e-04,\n",
      "         -1.2207e-04, -3.0518e-04],\n",
      "        [ 4.8828e-04,  4.2725e-04,  1.0986e-03,  ...,  1.0681e-03,\n",
      "          5.1880e-04,  1.8311e-04],\n",
      "        [ 8.8501e-04,  1.4496e-04, -6.1035e-05,  ..., -3.3569e-04,\n",
      "          2.4414e-04,  1.0376e-03],\n",
      "        ...,\n",
      "        [ 2.8229e-04,  3.0518e-04, -2.1362e-04,  ..., -5.4932e-04,\n",
      "         -5.7983e-04, -1.2817e-03],\n",
      "        [ 6.7139e-04, -4.2725e-04, -5.1880e-04,  ..., -1.2207e-04,\n",
      "         -3.0518e-04,  1.2207e-04],\n",
      "        [ 2.4414e-04, -2.4414e-04, -6.7139e-04,  ...,  0.0000e+00,\n",
      "         -6.1035e-05, -9.1553e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.mlp.up_proj.weight\n",
      "model.layers.18.mlp.down_proj.weight\n",
      "tensor([[-8.5449e-04,  6.1035e-04,  1.8311e-04,  ..., -7.1716e-04,\n",
      "         -1.0071e-03,  9.7656e-04],\n",
      "        [-6.1035e-05,  1.8311e-04, -5.7983e-04,  ...,  4.8828e-04,\n",
      "         -1.3428e-03, -9.1553e-05],\n",
      "        [ 1.2207e-04, -9.7656e-04, -1.2207e-04,  ..., -1.0681e-04,\n",
      "          6.1035e-05,  1.4343e-03],\n",
      "        ...,\n",
      "        [ 3.0518e-05,  2.4414e-04,  3.6240e-04,  ..., -1.8311e-04,\n",
      "         -4.2725e-04, -1.6785e-04],\n",
      "        [ 7.3242e-04, -2.1362e-04,  1.2207e-04,  ..., -1.5259e-05,\n",
      "         -3.0899e-04,  1.0452e-03],\n",
      "        [ 2.4414e-04,  5.4932e-04, -6.4087e-04,  ...,  3.0518e-04,\n",
      "         -6.1035e-05,  6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.mlp.down_proj.weight\n",
      "model.layers.18.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.input_layernorm.weight\n",
      "model.layers.18.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0020,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.18.post_attention_layernorm.weight\n",
      "model.layers.19.self_attn.q_proj.weight\n",
      "tensor([[-3.0518e-04, -1.5259e-05, -5.4932e-04,  ..., -6.1035e-05,\n",
      "         -3.0518e-05, -1.2207e-04],\n",
      "        [ 1.0681e-04, -1.8311e-04,  2.4414e-04,  ..., -1.2207e-03,\n",
      "          7.3242e-04,  1.8311e-04],\n",
      "        [-3.6621e-04, -2.2888e-05, -1.2207e-04,  ..., -1.8311e-04,\n",
      "         -9.4604e-04,  3.8147e-04],\n",
      "        ...,\n",
      "        [ 9.2316e-04, -3.6621e-04, -4.8828e-04,  ..., -1.0681e-04,\n",
      "          1.8311e-04, -2.4414e-04],\n",
      "        [-3.0518e-04,  6.1035e-04,  6.1035e-04,  ...,  3.3569e-04,\n",
      "          7.3242e-04, -2.4414e-04],\n",
      "        [ 1.2207e-04,  2.4414e-04, -1.2207e-04,  ...,  5.4550e-04,\n",
      "          3.6621e-04,  1.4343e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.self_attn.q_proj.weight\n",
      "model.layers.19.self_attn.k_proj.weight\n",
      "tensor([[-9.7656e-04, -3.3569e-04,  1.2207e-04,  ...,  6.1035e-05,\n",
      "          3.0518e-04, -1.0376e-03],\n",
      "        [-8.3923e-05, -1.2054e-03,  3.6621e-04,  ...,  1.2207e-04,\n",
      "          7.3242e-04, -1.6479e-03],\n",
      "        [-9.1553e-05, -3.0518e-04, -9.7656e-04,  ..., -6.1035e-04,\n",
      "         -2.4414e-04,  1.5564e-03],\n",
      "        ...,\n",
      "        [ 6.1035e-04,  2.2888e-05,  3.0518e-04,  ..., -6.1035e-04,\n",
      "         -2.4414e-04, -1.8311e-04],\n",
      "        [-1.2207e-04, -4.8828e-04,  1.2207e-04,  ..., -1.2207e-04,\n",
      "          2.4414e-04,  2.4414e-04],\n",
      "        [-1.2207e-04,  4.2343e-04,  7.6294e-04,  ..., -2.4414e-04,\n",
      "         -2.4414e-04,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.self_attn.k_proj.weight\n",
      "model.layers.19.self_attn.v_proj.weight\n",
      "tensor([[-2.4414e-04, -3.6621e-04,  3.6621e-04,  ...,  6.1035e-05,\n",
      "          6.1035e-05,  6.1035e-05],\n",
      "        [ 7.2098e-04,  1.3580e-03,  2.4414e-04,  ..., -7.6294e-06,\n",
      "         -4.2725e-04,  3.0518e-05],\n",
      "        [-3.0518e-04,  3.0518e-04, -3.3569e-04,  ..., -7.6294e-05,\n",
      "         -4.8828e-04, -3.6621e-04],\n",
      "        ...,\n",
      "        [ 3.9673e-04, -6.1035e-04, -1.0376e-03,  ..., -1.6785e-04,\n",
      "          3.6621e-04,  1.1597e-03],\n",
      "        [ 1.2207e-04, -6.4087e-04, -4.8828e-04,  ..., -1.1597e-03,\n",
      "         -9.1553e-05, -1.2207e-04],\n",
      "        [ 9.3842e-04, -3.6621e-04, -9.6893e-04,  ..., -6.7139e-04,\n",
      "          2.1362e-04, -4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.self_attn.v_proj.weight\n",
      "model.layers.19.self_attn.o_proj.weight\n",
      "tensor([[-3.0518e-04,  0.0000e+00,  4.8828e-04,  ...,  1.3123e-03,\n",
      "         -3.0518e-04, -1.2207e-04],\n",
      "        [ 2.3651e-04,  8.5449e-04, -1.2207e-04,  ..., -1.2207e-04,\n",
      "         -1.0681e-03,  3.6621e-04],\n",
      "        [ 4.4250e-04,  1.5259e-05, -7.9346e-04,  ..., -2.4414e-04,\n",
      "         -1.8311e-04, -2.8992e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04,  1.1215e-03, -3.0518e-05,  ...,  6.1035e-05,\n",
      "          4.2725e-04, -1.5259e-04],\n",
      "        [-1.0986e-03,  4.4250e-04, -8.2397e-04,  ..., -4.8828e-04,\n",
      "          3.6621e-04,  4.3106e-04],\n",
      "        [-6.1035e-05, -1.6785e-04,  0.0000e+00,  ...,  5.1880e-04,\n",
      "         -6.1035e-05, -3.2806e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.self_attn.o_proj.weight\n",
      "model.layers.19.mlp.gate_proj.weight\n",
      "tensor([[ 6.1035e-05,  3.6621e-04, -1.2817e-03,  ...,  6.7139e-04,\n",
      "          1.4191e-03,  6.8665e-04],\n",
      "        [-4.2725e-04,  7.3242e-04, -6.1035e-05,  ..., -3.0518e-04,\n",
      "          9.3937e-05, -1.2970e-04],\n",
      "        [-9.7656e-04,  5.7983e-04,  0.0000e+00,  ..., -7.3242e-04,\n",
      "         -3.6621e-04,  1.2207e-04],\n",
      "        ...,\n",
      "        [-3.0518e-05, -1.7014e-03,  1.2207e-03,  ...,  1.6403e-04,\n",
      "         -3.0518e-04,  2.4414e-04],\n",
      "        [ 2.1362e-04,  5.6458e-04,  1.8311e-04,  ...,  1.0376e-03,\n",
      "         -1.2207e-04, -4.8828e-04],\n",
      "        [-1.0681e-04,  5.4932e-04, -1.1444e-03,  ...,  2.4414e-04,\n",
      "          3.6621e-04,  2.1458e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.mlp.gate_proj.weight\n",
      "model.layers.19.mlp.up_proj.weight\n",
      "tensor([[ 6.1035e-05, -5.4932e-04, -1.5259e-04,  ..., -3.0518e-04,\n",
      "          1.8311e-04,  2.4414e-04],\n",
      "        [-1.8311e-04, -3.9673e-04,  2.4414e-04,  ...,  2.4414e-04,\n",
      "         -3.0518e-05,  0.0000e+00],\n",
      "        [-4.6921e-04,  3.0518e-04,  2.4414e-04,  ..., -2.1362e-04,\n",
      "          0.0000e+00, -1.8311e-04],\n",
      "        ...,\n",
      "        [ 1.2207e-04, -1.0910e-03,  3.6621e-04,  ..., -3.3569e-04,\n",
      "         -2.1362e-04, -1.2207e-04],\n",
      "        [-3.3569e-04,  6.1035e-04, -2.8992e-04,  ...,  6.1035e-04,\n",
      "          2.1935e-04, -2.8229e-04],\n",
      "        [-2.4414e-04,  1.2207e-04, -6.7139e-04,  ...,  5.3024e-04,\n",
      "          0.0000e+00, -7.0190e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.mlp.up_proj.weight\n",
      "model.layers.19.mlp.down_proj.weight\n",
      "tensor([[ 0.0000e+00, -2.8992e-04, -3.6621e-04,  ...,  1.2207e-04,\n",
      "          2.4414e-04, -7.3242e-04],\n",
      "        [-3.9673e-04,  5.0354e-04,  0.0000e+00,  ...,  6.1035e-05,\n",
      "         -2.4414e-04, -1.4267e-03],\n",
      "        [-1.0986e-03, -7.7438e-04,  3.0518e-04,  ...,  6.1035e-04,\n",
      "         -5.3406e-04,  5.1117e-04],\n",
      "        ...,\n",
      "        [-1.0986e-03,  8.8501e-04, -5.4932e-04,  ...,  2.6321e-04,\n",
      "          9.0408e-04,  6.1035e-05],\n",
      "        [ 1.8311e-04,  6.1035e-04, -7.0572e-04,  ...,  3.2806e-04,\n",
      "         -5.3024e-04,  9.1553e-04],\n",
      "        [-1.2207e-03, -8.8501e-04,  3.5858e-04,  ...,  1.0071e-03,\n",
      "          2.4414e-04, -1.8311e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.mlp.down_proj.weight\n",
      "model.layers.19.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.input_layernorm.weight\n",
      "model.layers.19.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000, -0.0020,  ...,  0.0000, -0.0020,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.19.post_attention_layernorm.weight\n",
      "model.layers.20.self_attn.q_proj.weight\n",
      "tensor([[-7.0190e-04, -7.5531e-04,  4.2725e-04,  ...,  7.3242e-04,\n",
      "         -4.2725e-04,  1.5259e-04],\n",
      "        [ 0.0000e+00,  4.7302e-04,  8.6594e-04,  ..., -3.0518e-04,\n",
      "          6.1035e-05,  5.4932e-04],\n",
      "        [ 2.4414e-04,  3.6621e-04,  1.0986e-03,  ...,  6.5613e-04,\n",
      "          1.7548e-04,  3.0518e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  7.3242e-04,  2.4414e-04,  ...,  4.8828e-04,\n",
      "         -9.7656e-04,  9.1553e-04],\n",
      "        [ 1.0834e-03,  7.6294e-04,  3.6621e-04,  ..., -7.3242e-04,\n",
      "          2.4414e-04,  6.1035e-04],\n",
      "        [-1.8311e-04,  1.2207e-03, -3.6621e-04,  ..., -1.2207e-04,\n",
      "         -8.5449e-04, -1.2207e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.self_attn.q_proj.weight\n",
      "model.layers.20.self_attn.k_proj.weight\n",
      "tensor([[-1.2817e-03,  9.1553e-05,  4.8828e-04,  ..., -2.4414e-04,\n",
      "          4.8828e-04, -2.4414e-04],\n",
      "        [ 0.0000e+00,  9.3842e-04,  4.2725e-04,  ...,  4.8828e-04,\n",
      "          9.7656e-04,  1.2207e-03],\n",
      "        [ 3.6621e-04,  0.0000e+00, -2.4414e-04,  ...,  6.7139e-04,\n",
      "          3.6621e-04, -7.0190e-04],\n",
      "        ...,\n",
      "        [ 4.8828e-04, -4.8828e-04,  2.4414e-04,  ...,  0.0000e+00,\n",
      "          2.4414e-04, -1.2207e-04],\n",
      "        [-3.6621e-04, -8.5449e-04,  9.7656e-04,  ...,  5.4932e-04,\n",
      "          4.2725e-04,  0.0000e+00],\n",
      "        [-3.6621e-04,  7.3242e-04, -1.7090e-03,  ...,  0.0000e+00,\n",
      "          1.2779e-04,  4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.self_attn.k_proj.weight\n",
      "model.layers.20.self_attn.v_proj.weight\n",
      "tensor([[ 3.9673e-04,  9.7656e-04, -2.1362e-04,  ..., -2.8992e-04,\n",
      "          1.8311e-04,  4.5776e-05],\n",
      "        [ 2.1744e-04, -1.2207e-04, -5.7983e-04,  ...,  4.8828e-04,\n",
      "          2.7466e-04, -2.7466e-04],\n",
      "        [ 1.9836e-04, -6.1035e-05,  3.0518e-04,  ...,  2.4414e-04,\n",
      "          7.3242e-04, -4.8828e-04],\n",
      "        ...,\n",
      "        [ 7.6294e-05, -2.4796e-04,  1.5259e-04,  ..., -7.6294e-04,\n",
      "          5.4932e-04, -4.8828e-04],\n",
      "        [-5.4932e-04,  1.0681e-04, -4.8828e-04,  ..., -1.2207e-04,\n",
      "          2.8992e-04, -1.2207e-04],\n",
      "        [ 4.1199e-04,  5.4932e-04, -1.2817e-03,  ..., -1.8311e-04,\n",
      "          2.7466e-04, -2.7466e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.self_attn.v_proj.weight\n",
      "model.layers.20.self_attn.o_proj.weight\n",
      "tensor([[ 8.5449e-04, -1.0681e-03,  7.6294e-05,  ..., -4.7493e-04,\n",
      "          6.1035e-05,  4.2725e-04],\n",
      "        [ 2.4414e-04,  1.2207e-04, -4.8828e-04,  ...,  5.1880e-04,\n",
      "          3.0518e-05, -5.1880e-04],\n",
      "        [-2.2888e-04,  0.0000e+00, -7.3242e-04,  ..., -4.5776e-05,\n",
      "         -1.2207e-04, -5.2643e-04],\n",
      "        ...,\n",
      "        [-1.6785e-04,  0.0000e+00,  3.0518e-05,  ..., -6.3324e-04,\n",
      "          1.6785e-04, -7.7820e-04],\n",
      "        [ 0.0000e+00,  8.0872e-04,  2.4414e-04,  ...,  4.5776e-04,\n",
      "         -2.4414e-04, -1.2207e-03],\n",
      "        [ 1.5259e-05,  4.5776e-05, -4.2725e-04,  ...,  4.8828e-04,\n",
      "          2.4796e-04, -6.1035e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.self_attn.o_proj.weight\n",
      "model.layers.20.mlp.gate_proj.weight\n",
      "tensor([[ 0.0003,  0.0005, -0.0005,  ...,  0.0004,  0.0004, -0.0001],\n",
      "        [ 0.0002,  0.0000,  0.0009,  ...,  0.0003,  0.0002,  0.0003],\n",
      "        [-0.0005, -0.0004, -0.0006,  ..., -0.0002, -0.0002, -0.0002],\n",
      "        ...,\n",
      "        [ 0.0003,  0.0006,  0.0007,  ..., -0.0001, -0.0002,  0.0002],\n",
      "        [-0.0002,  0.0004, -0.0012,  ..., -0.0004,  0.0005, -0.0008],\n",
      "        [ 0.0002, -0.0006,  0.0001,  ..., -0.0003,  0.0002,  0.0017]],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.mlp.gate_proj.weight\n",
      "model.layers.20.mlp.up_proj.weight\n",
      "tensor([[-1.2207e-04, -2.0142e-03,  5.0354e-04,  ...,  4.8828e-04,\n",
      "          0.0000e+00,  2.1362e-04],\n",
      "        [-6.1035e-04, -1.5259e-05,  9.1553e-05,  ..., -1.2207e-04,\n",
      "          3.2806e-04,  0.0000e+00],\n",
      "        [ 6.1035e-05,  2.4414e-04,  6.5613e-04,  ..., -4.8828e-04,\n",
      "          6.1035e-05,  1.2207e-04],\n",
      "        ...,\n",
      "        [-6.1035e-05,  1.5869e-03, -6.1035e-05,  ...,  1.9073e-04,\n",
      "          3.6621e-04, -1.2207e-04],\n",
      "        [ 7.9346e-04, -6.1035e-04,  7.0190e-04,  ..., -5.7983e-04,\n",
      "         -6.4087e-04, -1.5259e-04],\n",
      "        [-4.2725e-04,  1.0681e-03, -5.1880e-04,  ..., -4.2725e-04,\n",
      "         -4.5776e-04, -3.0518e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.mlp.up_proj.weight\n",
      "model.layers.20.mlp.down_proj.weight\n",
      "tensor([[-7.0953e-04,  8.5449e-04,  9.7656e-04,  ..., -1.2207e-04,\n",
      "          3.6621e-04,  0.0000e+00],\n",
      "        [ 4.8828e-04,  1.8311e-04, -1.2207e-04,  ...,  3.9673e-04,\n",
      "          2.4414e-04,  1.8311e-04],\n",
      "        [ 4.8828e-04,  7.8583e-04,  3.9673e-04,  ...,  4.8828e-04,\n",
      "          6.1035e-05, -3.0518e-04],\n",
      "        ...,\n",
      "        [ 2.4414e-04,  7.0190e-04,  1.3428e-03,  ...,  2.4414e-04,\n",
      "          3.0518e-05, -1.5259e-04],\n",
      "        [-6.7139e-04,  0.0000e+00, -1.1673e-03,  ...,  1.6785e-04,\n",
      "          6.1035e-05, -7.3242e-04],\n",
      "        [ 2.7466e-04,  7.3242e-04,  4.8828e-04,  ...,  6.1035e-05,\n",
      "         -2.4414e-04, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.mlp.down_proj.weight\n",
      "model.layers.20.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.input_layernorm.weight\n",
      "model.layers.20.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0020,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.20.post_attention_layernorm.weight\n",
      "model.layers.21.self_attn.q_proj.weight\n",
      "tensor([[-4.3106e-04, -1.8158e-03, -6.1035e-05,  ...,  6.1035e-04,\n",
      "          3.9673e-04,  1.7090e-03],\n",
      "        [ 6.9427e-04,  6.1035e-04,  6.1035e-04,  ..., -1.2207e-04,\n",
      "          9.1553e-05, -1.3428e-03],\n",
      "        [ 2.1362e-04,  1.8311e-04, -6.1035e-05,  ...,  2.4414e-04,\n",
      "          6.1035e-05,  6.1035e-05],\n",
      "        ...,\n",
      "        [ 1.2207e-04,  1.8311e-04, -5.7983e-04,  ...,  3.9673e-04,\n",
      "          0.0000e+00,  1.2207e-04],\n",
      "        [ 2.4414e-04,  3.0518e-04, -1.3428e-03,  ...,  0.0000e+00,\n",
      "         -4.8828e-04, -1.1902e-03],\n",
      "        [-4.8828e-04,  0.0000e+00,  6.1035e-04,  ...,  3.6621e-04,\n",
      "         -3.6621e-04, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.self_attn.q_proj.weight\n",
      "model.layers.21.self_attn.k_proj.weight\n",
      "tensor([[-0.0002,  0.0007, -0.0007,  ..., -0.0003, -0.0002,  0.0008],\n",
      "        [-0.0004,  0.0004,  0.0003,  ...,  0.0011,  0.0005,  0.0002],\n",
      "        [-0.0011,  0.0000,  0.0002,  ...,  0.0010, -0.0002,  0.0004],\n",
      "        ...,\n",
      "        [ 0.0005,  0.0000,  0.0002,  ...,  0.0002,  0.0004,  0.0000],\n",
      "        [ 0.0000,  0.0013,  0.0000,  ...,  0.0007, -0.0013,  0.0007],\n",
      "        [ 0.0006,  0.0003,  0.0000,  ..., -0.0002, -0.0002,  0.0007]],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.self_attn.k_proj.weight\n",
      "model.layers.21.self_attn.v_proj.weight\n",
      "tensor([[-1.2207e-04,  3.0518e-05,  7.3242e-04,  ...,  0.0000e+00,\n",
      "         -5.1117e-04, -7.3242e-04],\n",
      "        [-6.1035e-05, -1.5259e-05,  4.2725e-04,  ...,  6.1035e-04,\n",
      "          9.4604e-04,  3.6621e-04],\n",
      "        [ 3.0518e-04, -1.8311e-04, -4.5013e-04,  ...,  2.2888e-05,\n",
      "          1.9646e-04,  2.4414e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04,  2.8992e-04,  1.8311e-04,  ..., -6.1035e-05,\n",
      "          5.0354e-04, -4.2725e-04],\n",
      "        [-1.4114e-04, -7.0190e-04, -1.1597e-03,  ..., -1.2207e-04,\n",
      "         -3.2043e-04,  0.0000e+00],\n",
      "        [ 4.8828e-04,  6.1035e-05, -1.1444e-03,  ...,  6.1035e-04,\n",
      "          6.1035e-05, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.self_attn.v_proj.weight\n",
      "model.layers.21.self_attn.o_proj.weight\n",
      "tensor([[-1.1444e-04, -5.7220e-05,  6.1035e-04,  ..., -9.1553e-05,\n",
      "          1.2207e-04, -1.6479e-03],\n",
      "        [ 0.0000e+00, -3.0518e-04, -2.4414e-04,  ..., -7.3242e-04,\n",
      "         -5.1880e-04, -6.1035e-04],\n",
      "        [-5.4932e-04,  1.2207e-04,  4.5776e-04,  ...,  1.2207e-04,\n",
      "          2.2888e-04,  1.2207e-03],\n",
      "        ...,\n",
      "        [ 8.8501e-04,  3.6621e-04, -9.1553e-04,  ...,  1.0681e-04,\n",
      "          1.0300e-04, -5.7983e-04],\n",
      "        [-3.0518e-04, -2.4414e-04, -3.9673e-04,  ...,  1.0071e-03,\n",
      "          1.6212e-04,  3.6621e-04],\n",
      "        [-4.1962e-04, -3.9673e-04, -1.6785e-04,  ..., -1.2207e-04,\n",
      "          1.0071e-03,  4.1199e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.self_attn.o_proj.weight\n",
      "model.layers.21.mlp.gate_proj.weight\n",
      "tensor([[-1.2207e-04,  7.3242e-04,  4.8828e-04,  ...,  6.1035e-04,\n",
      "         -1.2207e-04, -3.6621e-04],\n",
      "        [ 3.6621e-04, -4.5776e-04,  1.2512e-03,  ..., -7.6294e-06,\n",
      "         -9.4986e-04,  2.4414e-04],\n",
      "        [ 3.6621e-04,  7.3242e-04,  5.1880e-04,  ..., -3.6621e-04,\n",
      "          2.4414e-04,  2.4414e-04],\n",
      "        ...,\n",
      "        [-8.5449e-04, -3.6621e-04,  7.0953e-04,  ...,  0.0000e+00,\n",
      "          1.2207e-03,  1.5259e-04],\n",
      "        [ 0.0000e+00,  7.3242e-04, -3.6621e-04,  ...,  3.6621e-04,\n",
      "          3.9673e-04,  7.3242e-04],\n",
      "        [ 9.7656e-04, -1.0376e-03,  6.7139e-04,  ...,  3.0518e-04,\n",
      "         -6.2561e-04,  2.7466e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.mlp.gate_proj.weight\n",
      "model.layers.21.mlp.up_proj.weight\n",
      "tensor([[-2.1362e-04, -1.2207e-03, -2.2125e-04,  ...,  4.1199e-04,\n",
      "         -5.4932e-04, -3.6621e-04],\n",
      "        [ 3.6621e-04,  1.4496e-03,  1.8311e-04,  ...,  8.8501e-04,\n",
      "         -1.2207e-04,  9.1553e-05],\n",
      "        [-3.6240e-04, -7.6294e-05, -9.7656e-04,  ...,  4.8828e-04,\n",
      "         -1.4648e-03,  4.8828e-04],\n",
      "        ...,\n",
      "        [-6.7139e-04,  1.2207e-04, -1.5259e-04,  ..., -9.7656e-04,\n",
      "          8.6975e-04, -5.1880e-04],\n",
      "        [-4.8828e-04, -1.2207e-04,  7.6294e-05,  ...,  3.6621e-04,\n",
      "         -3.0518e-04, -7.1716e-04],\n",
      "        [ 9.7656e-04, -4.2725e-04, -3.0518e-05,  ...,  6.4850e-04,\n",
      "         -1.9684e-03,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.mlp.up_proj.weight\n",
      "model.layers.21.mlp.down_proj.weight\n",
      "tensor([[-0.0001,  0.0005,  0.0010,  ...,  0.0003, -0.0005,  0.0000],\n",
      "        [ 0.0009, -0.0003,  0.0006,  ...,  0.0002,  0.0002,  0.0007],\n",
      "        [ 0.0003,  0.0002, -0.0006,  ..., -0.0009, -0.0001,  0.0011],\n",
      "        ...,\n",
      "        [ 0.0002, -0.0009,  0.0001,  ...,  0.0006, -0.0002,  0.0005],\n",
      "        [ 0.0000,  0.0005,  0.0003,  ...,  0.0000, -0.0002, -0.0012],\n",
      "        [-0.0002, -0.0008, -0.0006,  ...,  0.0006, -0.0005,  0.0002]],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.mlp.down_proj.weight\n",
      "model.layers.21.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.input_layernorm.weight\n",
      "model.layers.21.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0020,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.21.post_attention_layernorm.weight\n",
      "model.layers.22.self_attn.q_proj.weight\n",
      "tensor([[ 4.1199e-04,  3.0518e-04,  8.2397e-04,  ..., -3.6621e-04,\n",
      "         -1.2207e-04, -9.1553e-05],\n",
      "        [ 8.0872e-04,  1.8311e-04, -4.8828e-04,  ..., -6.1035e-05,\n",
      "         -3.5095e-04,  9.1553e-05],\n",
      "        [ 3.0518e-05, -1.5259e-05, -1.2207e-04,  ..., -2.4414e-04,\n",
      "          5.7983e-04, -3.0518e-04],\n",
      "        ...,\n",
      "        [-1.0986e-03,  0.0000e+00, -2.6321e-04,  ...,  1.0834e-03,\n",
      "          4.8828e-04,  8.5449e-04],\n",
      "        [ 3.6621e-04,  3.0518e-04,  9.7656e-04,  ...,  1.4038e-03,\n",
      "         -7.6294e-04, -4.8828e-04],\n",
      "        [ 6.1035e-05, -4.5776e-04, -5.1880e-04,  ..., -1.2207e-04,\n",
      "          2.4414e-04,  1.6785e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.self_attn.q_proj.weight\n",
      "model.layers.22.self_attn.k_proj.weight\n",
      "tensor([[ 0.0001,  0.0009,  0.0004,  ...,  0.0005,  0.0008,  0.0002],\n",
      "        [ 0.0012, -0.0001,  0.0007,  ..., -0.0002,  0.0001, -0.0003],\n",
      "        [ 0.0001, -0.0005,  0.0000,  ...,  0.0011, -0.0002,  0.0013],\n",
      "        ...,\n",
      "        [-0.0005,  0.0002, -0.0002,  ..., -0.0002, -0.0009,  0.0001],\n",
      "        [ 0.0001,  0.0001, -0.0002,  ...,  0.0013,  0.0000,  0.0005],\n",
      "        [-0.0002, -0.0002,  0.0002,  ..., -0.0009, -0.0001,  0.0011]],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.self_attn.k_proj.weight\n",
      "model.layers.22.self_attn.v_proj.weight\n",
      "tensor([[ 1.8311e-04,  5.4932e-04, -8.0872e-04,  ..., -1.2207e-04,\n",
      "         -6.8665e-04,  5.9509e-04],\n",
      "        [-4.5776e-04,  6.1035e-05, -4.8828e-04,  ..., -2.4414e-04,\n",
      "          1.1597e-03, -8.5449e-04],\n",
      "        [-1.2207e-04,  0.0000e+00, -9.0790e-04,  ...,  5.4932e-04,\n",
      "         -4.2725e-04,  3.6621e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04, -5.1880e-04, -1.8311e-04,  ...,  6.1035e-04,\n",
      "         -1.8311e-04, -3.9673e-04],\n",
      "        [-3.0518e-04, -6.3324e-04, -5.4932e-04,  ...,  1.8311e-04,\n",
      "         -3.6621e-04, -1.0986e-03],\n",
      "        [ 3.6621e-04,  6.1035e-05,  3.6621e-04,  ..., -6.1035e-04,\n",
      "          3.0518e-04, -4.8828e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.self_attn.v_proj.weight\n",
      "model.layers.22.self_attn.o_proj.weight\n",
      "tensor([[ 1.0376e-03,  9.1553e-05, -1.4954e-03,  ..., -3.0518e-04,\n",
      "          0.0000e+00, -3.0518e-04],\n",
      "        [-1.2207e-04,  1.2207e-04, -4.2725e-04,  ..., -3.6621e-04,\n",
      "         -1.9836e-04, -1.0223e-03],\n",
      "        [ 3.6621e-04,  5.4932e-04, -2.4414e-04,  ...,  3.9673e-04,\n",
      "         -5.4932e-04, -4.2725e-04],\n",
      "        ...,\n",
      "        [ 1.2207e-04,  4.5776e-04, -6.1035e-04,  ..., -1.1597e-03,\n",
      "         -1.2207e-04, -4.8828e-04],\n",
      "        [-1.2207e-04,  3.6621e-04,  2.1362e-04,  ..., -9.1553e-05,\n",
      "         -3.0518e-05,  0.0000e+00],\n",
      "        [ 6.4850e-05,  3.0518e-04,  5.6458e-04,  ..., -5.7983e-04,\n",
      "          3.6621e-04, -8.6975e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.self_attn.o_proj.weight\n",
      "model.layers.22.mlp.gate_proj.weight\n",
      "tensor([[ 3.0518e-05, -1.2207e-04, -4.1199e-04,  ...,  0.0000e+00,\n",
      "          1.2207e-04,  3.6621e-04],\n",
      "        [-6.7139e-04,  3.6621e-04,  0.0000e+00,  ..., -6.8665e-05,\n",
      "         -1.2207e-04,  1.1139e-03],\n",
      "        [-8.5449e-04, -6.1035e-05,  1.5259e-04,  ..., -7.6294e-06,\n",
      "         -1.2207e-04,  5.4932e-04],\n",
      "        ...,\n",
      "        [-3.6621e-04,  1.2207e-03, -1.6785e-04,  ...,  1.5259e-04,\n",
      "          0.0000e+00, -6.1035e-04],\n",
      "        [-1.2207e-04, -7.3242e-04, -2.1362e-04,  ...,  6.1035e-04,\n",
      "         -1.0681e-03, -3.6621e-04],\n",
      "        [ 2.4414e-04, -1.2207e-04, -4.8828e-04,  ..., -6.1035e-04,\n",
      "         -1.5259e-04,  9.1553e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.mlp.gate_proj.weight\n",
      "model.layers.22.mlp.up_proj.weight\n",
      "tensor([[ 7.5150e-04,  6.1035e-05, -1.0872e-04,  ..., -9.1553e-05,\n",
      "         -1.2207e-04,  2.1362e-04],\n",
      "        [-1.0681e-04,  5.4932e-04,  1.2207e-04,  ..., -7.9346e-04,\n",
      "          3.0518e-04,  1.5259e-04],\n",
      "        [-3.1281e-04,  3.3569e-04,  1.2207e-04,  ...,  4.8828e-04,\n",
      "          8.1635e-04,  4.7302e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-05,  1.2589e-04, -1.2207e-04,  ...,  4.2725e-04,\n",
      "         -3.6621e-04, -7.6294e-04],\n",
      "        [-7.6294e-04,  5.4932e-04, -1.5259e-05,  ..., -8.8501e-04,\n",
      "          1.2207e-04, -3.2043e-04],\n",
      "        [ 5.4932e-04, -1.8311e-04,  4.8828e-04,  ...,  3.6621e-04,\n",
      "         -3.1090e-04, -2.7466e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.mlp.up_proj.weight\n",
      "model.layers.22.mlp.down_proj.weight\n",
      "tensor([[ 6.1035e-05, -9.1553e-04,  3.0518e-04,  ..., -9.7656e-04,\n",
      "         -1.0986e-03, -1.4648e-03],\n",
      "        [ 1.2589e-04,  1.2207e-04,  6.1035e-05,  ...,  7.7820e-04,\n",
      "          2.4414e-04,  5.9509e-04],\n",
      "        [ 6.1035e-04,  4.2725e-04,  7.3242e-04,  ..., -2.2697e-04,\n",
      "          6.1035e-05, -8.5449e-04],\n",
      "        ...,\n",
      "        [-3.0518e-05,  4.5776e-04,  1.2207e-03,  ...,  2.3651e-04,\n",
      "          1.1597e-03, -7.6294e-04],\n",
      "        [-1.9073e-04, -2.1362e-04,  6.1035e-05,  ..., -3.0518e-04,\n",
      "         -7.4768e-04,  2.4414e-04],\n",
      "        [ 6.1035e-04, -4.8828e-04,  4.8828e-04,  ...,  4.8828e-04,\n",
      "          1.4496e-04,  6.3324e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.mlp.down_proj.weight\n",
      "model.layers.22.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.input_layernorm.weight\n",
      "model.layers.22.post_attention_layernorm.weight\n",
      "tensor([-0.0020, -0.0020,  0.0000,  ..., -0.0020,  0.0000, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.22.post_attention_layernorm.weight\n",
      "model.layers.23.self_attn.q_proj.weight\n",
      "tensor([[-6.4087e-04,  1.8311e-04,  8.8501e-04,  ...,  4.8828e-04,\n",
      "          1.3428e-03, -9.1553e-04],\n",
      "        [-1.8311e-04,  7.9346e-04,  7.6294e-05,  ..., -6.7139e-04,\n",
      "          6.1035e-04, -4.8828e-04],\n",
      "        [ 7.6294e-05, -2.4414e-04, -5.6458e-04,  ...,  4.8828e-04,\n",
      "         -2.4414e-04,  8.5449e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-04,  3.9673e-04,  6.1035e-05,  ..., -1.8311e-04,\n",
      "         -5.4932e-04, -4.8828e-04],\n",
      "        [ 2.4414e-04, -6.4087e-04, -6.1035e-04,  ...,  0.0000e+00,\n",
      "         -2.4414e-04,  1.4038e-03],\n",
      "        [ 2.4414e-04,  9.1553e-04, -1.2207e-04,  ...,  0.0000e+00,\n",
      "          6.1035e-04, -3.3569e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.self_attn.q_proj.weight\n",
      "model.layers.23.self_attn.k_proj.weight\n",
      "tensor([[-6.1035e-04, -9.1553e-04, -4.8828e-04,  ...,  1.8311e-04,\n",
      "          6.4087e-04,  5.4932e-04],\n",
      "        [ 0.0000e+00, -2.3651e-04, -4.8828e-04,  ...,  2.4414e-04,\n",
      "         -1.2207e-04,  3.6621e-04],\n",
      "        [ 2.4414e-04, -7.3242e-04,  1.2207e-04,  ...,  1.2207e-04,\n",
      "          6.1035e-04, -2.4414e-04],\n",
      "        ...,\n",
      "        [-3.6621e-04,  4.8828e-04, -4.8828e-04,  ..., -6.1035e-05,\n",
      "          1.2207e-04,  8.2397e-04],\n",
      "        [-6.1035e-05, -2.4414e-04, -3.6621e-04,  ...,  2.4414e-04,\n",
      "          9.1553e-04,  6.1035e-04],\n",
      "        [-7.3242e-04, -2.4414e-04, -1.8311e-04,  ...,  0.0000e+00,\n",
      "          8.5449e-04,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.self_attn.k_proj.weight\n",
      "model.layers.23.self_attn.v_proj.weight\n",
      "tensor([[ 1.2207e-04, -5.8365e-04, -3.0518e-05,  ..., -1.6022e-03,\n",
      "         -2.8992e-04, -2.5177e-04],\n",
      "        [ 1.0681e-03,  6.1035e-04, -5.4932e-04,  ...,  4.7302e-04,\n",
      "         -6.1035e-05, -1.8311e-04],\n",
      "        [-8.5449e-04, -1.0223e-03, -9.1553e-04,  ..., -2.2888e-04,\n",
      "         -1.8311e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [-3.3569e-04, -7.3242e-04,  7.9346e-04,  ..., -3.1281e-04,\n",
      "         -3.6621e-04,  3.0518e-05],\n",
      "        [-2.8610e-04,  3.8147e-04,  7.4005e-04,  ..., -7.9346e-04,\n",
      "          6.1035e-05, -5.2643e-04],\n",
      "        [-7.9346e-04,  1.0834e-03, -2.7084e-04,  ..., -6.1035e-04,\n",
      "          0.0000e+00,  7.3242e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.self_attn.v_proj.weight\n",
      "model.layers.23.self_attn.o_proj.weight\n",
      "tensor([[ 3.6621e-04,  8.5449e-04,  1.8311e-04,  ..., -1.2207e-04,\n",
      "         -6.1035e-05, -5.7983e-04],\n",
      "        [-6.7139e-04, -3.0518e-05,  6.1035e-05,  ..., -1.0681e-04,\n",
      "         -2.0599e-04, -1.2207e-04],\n",
      "        [ 2.5940e-04,  1.4038e-03, -6.1035e-04,  ..., -4.2725e-04,\n",
      "          9.7656e-04, -1.5259e-04],\n",
      "        ...,\n",
      "        [ 1.2207e-04,  5.7983e-04, -4.8828e-04,  ..., -9.7656e-04,\n",
      "          6.1035e-05, -2.1362e-04],\n",
      "        [ 3.3569e-04,  7.8583e-04, -8.5449e-04,  ...,  3.3569e-04,\n",
      "          2.4414e-04, -4.1199e-04],\n",
      "        [ 9.1553e-04, -1.6022e-04, -6.7139e-04,  ..., -3.3569e-04,\n",
      "         -4.5776e-04, -2.1362e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.self_attn.o_proj.weight\n",
      "model.layers.23.mlp.gate_proj.weight\n",
      "tensor([[ 9.3460e-04,  6.1035e-05, -1.2207e-04,  ...,  3.6621e-04,\n",
      "         -9.1553e-04,  1.2207e-04],\n",
      "        [ 1.2207e-03,  5.4932e-04, -1.4648e-03,  ..., -9.7656e-04,\n",
      "          7.3242e-04,  2.7466e-04],\n",
      "        [-6.1035e-04,  3.4523e-04,  8.5449e-04,  ...,  3.6621e-04,\n",
      "         -3.6621e-04, -6.1035e-04],\n",
      "        ...,\n",
      "        [ 1.4648e-03, -1.0223e-03, -5.1880e-04,  ..., -1.0986e-03,\n",
      "          4.2725e-04, -2.4414e-04],\n",
      "        [-2.7466e-04,  0.0000e+00, -1.0986e-03,  ..., -2.4414e-04,\n",
      "         -8.5449e-04,  2.4414e-04],\n",
      "        [ 3.9291e-04,  1.2207e-04, -1.0071e-03,  ...,  2.4414e-04,\n",
      "          4.5776e-05,  1.0986e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.mlp.gate_proj.weight\n",
      "model.layers.23.mlp.up_proj.weight\n",
      "tensor([[ 4.8828e-04, -2.7466e-04,  6.1035e-05,  ...,  2.4414e-04,\n",
      "          8.5449e-04, -1.5869e-03],\n",
      "        [-7.3242e-04, -1.2970e-04, -9.9945e-04,  ..., -6.7139e-04,\n",
      "         -1.8311e-04, -1.8311e-04],\n",
      "        [-1.2207e-04, -3.3569e-04,  1.2207e-04,  ..., -6.5613e-04,\n",
      "          4.8828e-04, -6.1035e-04],\n",
      "        ...,\n",
      "        [ 7.3242e-04,  3.5095e-04, -1.8311e-04,  ..., -1.0834e-03,\n",
      "          0.0000e+00, -3.5095e-04],\n",
      "        [-4.4250e-04,  2.2602e-04, -3.3569e-04,  ...,  3.4523e-04,\n",
      "          9.7656e-04,  2.4414e-04],\n",
      "        [ 2.7466e-04,  4.5776e-04,  6.1035e-05,  ..., -1.9836e-04,\n",
      "         -2.4414e-04,  1.7166e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.mlp.up_proj.weight\n",
      "model.layers.23.mlp.down_proj.weight\n",
      "tensor([[-4.2915e-04, -5.1880e-04, -5.5695e-04,  ...,  2.1362e-04,\n",
      "         -1.2512e-03, -3.2043e-04],\n",
      "        [-2.4414e-04,  4.8828e-04, -1.2207e-04,  ..., -4.8828e-04,\n",
      "          6.1035e-04, -6.7139e-04],\n",
      "        [-3.9673e-04, -2.4033e-04,  4.2725e-04,  ...,  1.8311e-04,\n",
      "         -3.6621e-04,  1.1368e-03],\n",
      "        ...,\n",
      "        [ 1.2207e-04, -2.4414e-04,  1.1597e-03,  ...,  3.9673e-04,\n",
      "          6.1035e-05,  3.0518e-04],\n",
      "        [ 7.3242e-04,  7.9346e-04,  3.0518e-05,  ...,  3.6621e-04,\n",
      "          2.4414e-04,  5.7983e-04],\n",
      "        [-6.1035e-04,  1.2207e-04, -1.8311e-04,  ..., -5.7602e-04,\n",
      "         -5.7220e-04,  7.0190e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.mlp.down_proj.weight\n",
      "model.layers.23.input_layernorm.weight\n",
      "tensor([ 0.0000, -0.0039, -0.0020,  ...,  0.0000, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.input_layernorm.weight\n",
      "model.layers.23.post_attention_layernorm.weight\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.23.post_attention_layernorm.weight\n",
      "model.layers.24.self_attn.q_proj.weight\n",
      "tensor([[ 9.1553e-05, -4.1199e-04,  6.1035e-04,  ...,  3.0518e-04,\n",
      "         -4.2725e-04,  0.0000e+00],\n",
      "        [-1.2207e-04,  1.5259e-04, -2.4414e-04,  ...,  0.0000e+00,\n",
      "          1.5259e-04,  1.2207e-04],\n",
      "        [ 3.6621e-04, -1.2207e-04,  1.8311e-04,  ..., -3.8910e-04,\n",
      "          0.0000e+00,  3.6621e-04],\n",
      "        ...,\n",
      "        [ 4.8828e-04, -3.0518e-04, -1.0986e-03,  ...,  4.2725e-04,\n",
      "         -1.2207e-04, -4.2725e-04],\n",
      "        [ 3.6621e-04, -8.5449e-04,  8.0109e-04,  ...,  7.3242e-04,\n",
      "          4.8828e-04, -2.4414e-04],\n",
      "        [ 0.0000e+00, -1.2207e-04,  0.0000e+00,  ..., -8.5449e-04,\n",
      "         -9.7656e-04,  3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.self_attn.q_proj.weight\n",
      "model.layers.24.self_attn.k_proj.weight\n",
      "tensor([[ 1.5869e-03, -5.1880e-04, -2.4414e-04,  ...,  1.2207e-04,\n",
      "         -5.1880e-04,  3.0518e-05],\n",
      "        [-4.2725e-04,  6.1035e-05,  6.1035e-05,  ..., -4.8828e-04,\n",
      "          7.9346e-04,  1.2207e-04],\n",
      "        [-1.0681e-04, -1.5259e-04, -5.1880e-04,  ...,  3.6621e-04,\n",
      "         -2.4414e-04, -3.0518e-04],\n",
      "        ...,\n",
      "        [ 3.0518e-04,  1.0986e-03,  4.8828e-04,  ...,  0.0000e+00,\n",
      "         -2.4414e-04, -9.7656e-04],\n",
      "        [ 8.5449e-04,  5.1880e-04,  3.6621e-04,  ...,  4.8828e-04,\n",
      "         -2.4414e-04,  2.4414e-04],\n",
      "        [ 8.5449e-04, -1.5259e-04, -9.7656e-04,  ...,  8.5449e-04,\n",
      "          2.7466e-04,  7.2479e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.self_attn.k_proj.weight\n",
      "model.layers.24.self_attn.v_proj.weight\n",
      "tensor([[-2.7466e-04,  4.8828e-04, -6.1035e-04,  ...,  3.0518e-04,\n",
      "         -3.0518e-05,  1.3428e-03],\n",
      "        [ 3.6621e-04, -2.4796e-05,  1.0071e-03,  ...,  4.5776e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.6621e-04,  0.0000e+00, -6.1035e-04,  ...,  7.9346e-04,\n",
      "          2.1362e-04, -8.2397e-04],\n",
      "        ...,\n",
      "        [ 3.6621e-04, -5.5695e-04, -1.2207e-04,  ..., -1.3733e-04,\n",
      "         -1.8311e-04,  1.6785e-04],\n",
      "        [ 3.0518e-05,  1.2207e-03, -6.1035e-05,  ..., -2.4414e-04,\n",
      "         -1.3428e-03,  5.6458e-04],\n",
      "        [-2.7466e-04,  1.0376e-03, -1.2207e-04,  ..., -5.0735e-04,\n",
      "         -3.6621e-04,  3.7766e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.self_attn.v_proj.weight\n",
      "model.layers.24.self_attn.o_proj.weight\n",
      "tensor([[ 0.0000e+00, -6.1035e-04,  5.3406e-05,  ...,  8.3923e-05,\n",
      "          1.0376e-03,  6.1035e-04],\n",
      "        [-2.1362e-04,  0.0000e+00,  7.3242e-04,  ..., -1.1902e-03,\n",
      "         -1.5259e-04,  6.7139e-04],\n",
      "        [ 4.1962e-04,  1.3733e-04,  1.6022e-04,  ..., -4.9591e-04,\n",
      "         -6.7902e-04, -4.2725e-04],\n",
      "        ...,\n",
      "        [-1.0376e-03, -1.8311e-04, -6.7139e-04,  ...,  1.2207e-04,\n",
      "         -5.4932e-04, -1.1749e-03],\n",
      "        [ 3.0518e-04,  4.2725e-04,  4.8828e-04,  ...,  7.3242e-04,\n",
      "          2.1362e-04, -2.7847e-04],\n",
      "        [-9.4604e-04,  3.0518e-04, -7.3242e-04,  ...,  6.1035e-05,\n",
      "          3.4714e-04, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.self_attn.o_proj.weight\n",
      "model.layers.24.mlp.gate_proj.weight\n",
      "tensor([[-2.4796e-04, -1.5259e-04,  3.6621e-04,  ..., -4.8828e-04,\n",
      "         -2.4414e-04,  2.7466e-04],\n",
      "        [-2.2888e-04, -3.6621e-04,  5.7983e-04,  ..., -1.2207e-04,\n",
      "         -1.2207e-04,  1.2207e-04],\n",
      "        [ 4.2725e-04,  4.4250e-04, -1.1978e-03,  ..., -6.1035e-04,\n",
      "         -5.4932e-04,  3.0518e-04],\n",
      "        ...,\n",
      "        [-1.3123e-03, -8.5449e-04, -6.8665e-04,  ...,  1.8311e-04,\n",
      "          2.7466e-04,  7.3242e-04],\n",
      "        [ 3.6621e-04, -8.3923e-05, -1.8311e-04,  ..., -2.4414e-04,\n",
      "          2.4414e-04, -6.1035e-04],\n",
      "        [ 1.5259e-04,  4.8828e-04,  2.3651e-04,  ..., -1.3733e-04,\n",
      "         -1.8311e-04, -2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.mlp.gate_proj.weight\n",
      "model.layers.24.mlp.up_proj.weight\n",
      "tensor([[-7.9346e-04,  3.0518e-04,  1.2207e-04,  ..., -4.6539e-04,\n",
      "         -3.0518e-04, -1.2512e-03],\n",
      "        [-4.8828e-04,  1.5259e-04,  0.0000e+00,  ..., -6.1035e-04,\n",
      "         -1.2817e-03, -6.7139e-04],\n",
      "        [ 1.0529e-03,  3.7384e-04, -6.1035e-05,  ..., -3.5095e-04,\n",
      "         -5.4932e-04, -4.1962e-04],\n",
      "        ...,\n",
      "        [-2.7466e-04,  2.4414e-04,  5.4169e-04,  ...,  3.0518e-04,\n",
      "          6.7139e-04,  2.4414e-04],\n",
      "        [-8.5449e-04,  1.2207e-03, -1.8692e-04,  ..., -2.4414e-04,\n",
      "          1.8311e-04,  5.4932e-04],\n",
      "        [ 1.5259e-05,  8.6975e-04,  4.5776e-04,  ...,  3.6621e-04,\n",
      "          7.3242e-04,  1.0986e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.mlp.up_proj.weight\n",
      "model.layers.24.mlp.down_proj.weight\n",
      "tensor([[-6.1035e-05, -6.1035e-04,  4.8828e-04,  ...,  2.1362e-04,\n",
      "          9.7656e-04, -7.3242e-04],\n",
      "        [-9.7656e-04,  1.0529e-03,  4.2725e-04,  ...,  2.4414e-04,\n",
      "         -3.1662e-04,  5.4932e-04],\n",
      "        [-7.0190e-04,  3.0518e-04, -4.6921e-04,  ...,  4.8828e-04,\n",
      "         -8.5449e-04, -6.1035e-04],\n",
      "        ...,\n",
      "        [ 2.4414e-04, -7.9346e-04,  4.1199e-04,  ...,  1.2207e-04,\n",
      "         -6.1035e-05,  1.1597e-03],\n",
      "        [ 4.2725e-04,  3.0136e-04, -3.6621e-04,  ..., -9.6130e-04,\n",
      "          0.0000e+00,  6.5613e-04],\n",
      "        [-3.6621e-04,  2.4414e-04, -5.4932e-04,  ..., -4.5776e-04,\n",
      "         -9.1553e-05, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.mlp.down_proj.weight\n",
      "model.layers.24.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0039, -0.0020,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.input_layernorm.weight\n",
      "model.layers.24.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.24.post_attention_layernorm.weight\n",
      "model.layers.25.self_attn.q_proj.weight\n",
      "tensor([[-3.0518e-04,  9.1553e-05,  3.3569e-04,  ..., -9.1553e-04,\n",
      "         -4.2725e-04,  3.0518e-04],\n",
      "        [-1.8311e-04,  8.0872e-04,  6.1035e-05,  ..., -1.2207e-04,\n",
      "          1.8311e-04,  6.1035e-04],\n",
      "        [-1.2207e-04, -3.0518e-04,  1.8311e-04,  ...,  0.0000e+00,\n",
      "          9.1553e-04, -2.9373e-04],\n",
      "        ...,\n",
      "        [ 4.8828e-04, -3.0518e-04,  4.8828e-04,  ...,  0.0000e+00,\n",
      "         -3.9673e-04,  1.0986e-03],\n",
      "        [-2.4414e-04,  1.2207e-03, -4.8828e-04,  ..., -7.3242e-04,\n",
      "          2.4414e-04,  3.6621e-04],\n",
      "        [-6.1035e-04,  6.1035e-04, -1.5259e-04,  ...,  7.3242e-04,\n",
      "         -1.2207e-04, -6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.self_attn.q_proj.weight\n",
      "model.layers.25.self_attn.k_proj.weight\n",
      "tensor([[-1.2207e-04,  1.6499e-04, -6.1035e-05,  ..., -2.4414e-04,\n",
      "          1.2207e-04, -1.2207e-04],\n",
      "        [-3.6621e-04,  2.4414e-04, -2.2888e-04,  ..., -1.2207e-04,\n",
      "          1.2207e-04, -4.2725e-04],\n",
      "        [-4.8828e-04,  6.1035e-04,  1.1826e-03,  ..., -4.8828e-04,\n",
      "          5.1880e-04, -1.9836e-04],\n",
      "        ...,\n",
      "        [-4.8828e-04,  1.2207e-04, -2.4414e-04,  ..., -4.8828e-04,\n",
      "         -4.8828e-04,  1.2207e-04],\n",
      "        [ 0.0000e+00,  9.7656e-04,  6.1035e-04,  ..., -9.7656e-04,\n",
      "          0.0000e+00,  1.0986e-03],\n",
      "        [-2.4414e-04, -7.3242e-04,  1.8311e-04,  ...,  8.8501e-04,\n",
      "          4.8828e-04,  7.3242e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.self_attn.k_proj.weight\n",
      "model.layers.25.self_attn.v_proj.weight\n",
      "tensor([[ 7.9346e-04, -2.4414e-04,  1.5259e-05,  ...,  4.2725e-04,\n",
      "          8.5449e-04,  1.5259e-04],\n",
      "        [ 1.5259e-04,  2.7466e-04, -3.0518e-04,  ..., -7.1716e-04,\n",
      "          1.2207e-04, -2.4414e-04],\n",
      "        [-2.4414e-04,  1.8311e-04, -4.8828e-04,  ..., -6.7139e-04,\n",
      "         -1.4496e-04,  3.6621e-04],\n",
      "        ...,\n",
      "        [ 1.3275e-03,  3.9673e-04,  1.1292e-03,  ...,  4.8828e-04,\n",
      "          4.2725e-04, -1.2207e-04],\n",
      "        [-7.9346e-04,  1.0071e-03, -4.0436e-04,  ..., -4.2725e-04,\n",
      "         -1.0376e-03,  1.0986e-03],\n",
      "        [ 9.1553e-04, -9.1553e-04, -4.0436e-04,  ...,  1.0376e-03,\n",
      "          1.2207e-04, -8.5449e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.self_attn.v_proj.weight\n",
      "model.layers.25.self_attn.o_proj.weight\n",
      "tensor([[ 1.8311e-04, -4.5776e-04, -3.0518e-04,  ..., -3.0518e-04,\n",
      "          1.2207e-04,  6.2561e-04],\n",
      "        [ 6.1035e-04, -3.6621e-04, -1.5259e-04,  ...,  3.0518e-04,\n",
      "         -3.6621e-04,  3.0518e-04],\n",
      "        [ 4.8828e-04,  4.8828e-04,  1.2207e-04,  ...,  4.2725e-04,\n",
      "         -4.8828e-04, -6.1035e-04],\n",
      "        ...,\n",
      "        [-1.2207e-03,  9.1553e-05, -3.9673e-04,  ..., -2.4414e-04,\n",
      "          1.2207e-04,  3.5095e-04],\n",
      "        [ 2.4414e-04, -6.1035e-05,  7.3242e-04,  ...,  9.9182e-05,\n",
      "         -2.4414e-04,  5.4932e-04],\n",
      "        [ 1.2207e-04,  6.8665e-04, -1.5354e-04,  ...,  4.8828e-04,\n",
      "          1.8311e-04,  3.9673e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.self_attn.o_proj.weight\n",
      "model.layers.25.mlp.gate_proj.weight\n",
      "tensor([[-7.3242e-04,  2.2888e-04, -1.6479e-03,  ...,  7.7057e-04,\n",
      "          8.5449e-04, -3.0518e-05],\n",
      "        [-8.5449e-04, -3.6621e-04,  0.0000e+00,  ..., -1.5259e-04,\n",
      "         -3.6621e-04, -8.5449e-04],\n",
      "        [-4.2725e-04, -3.6621e-04, -4.8828e-04,  ...,  2.4414e-04,\n",
      "         -4.1199e-04, -6.1035e-05],\n",
      "        ...,\n",
      "        [-7.2479e-04,  4.8828e-04,  2.4414e-04,  ...,  1.3733e-04,\n",
      "         -9.4604e-04,  2.4414e-04],\n",
      "        [ 7.5912e-04, -1.2207e-04,  5.4932e-04,  ...,  2.4414e-04,\n",
      "         -6.1035e-05, -3.0518e-05],\n",
      "        [ 2.4414e-04,  1.4191e-03,  3.6621e-04,  ...,  7.9346e-04,\n",
      "          9.1553e-05, -9.3842e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.mlp.gate_proj.weight\n",
      "model.layers.25.mlp.up_proj.weight\n",
      "tensor([[-3.9673e-04, -4.8828e-04,  3.6621e-04,  ..., -1.3428e-03,\n",
      "         -3.0518e-04, -8.5449e-04],\n",
      "        [ 6.7139e-04,  3.0518e-04,  1.1902e-03,  ...,  1.2207e-04,\n",
      "         -1.0986e-03, -7.3242e-04],\n",
      "        [ 9.1553e-04, -6.1035e-05,  1.8692e-04,  ..., -9.4604e-04,\n",
      "          2.7466e-04,  4.8828e-04],\n",
      "        ...,\n",
      "        [ 2.4414e-04, -9.1553e-05,  5.3406e-04,  ...,  3.5858e-04,\n",
      "          2.4414e-04,  1.0986e-03],\n",
      "        [ 1.8311e-04,  3.2806e-04,  1.1139e-03,  ..., -2.4414e-04,\n",
      "         -7.3242e-04, -1.3123e-03],\n",
      "        [ 2.4414e-04,  2.2888e-04, -6.1035e-05,  ..., -9.1553e-04,\n",
      "         -1.8120e-04, -1.8311e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.mlp.up_proj.weight\n",
      "model.layers.25.mlp.down_proj.weight\n",
      "tensor([[-7.7820e-04, -6.1035e-04,  5.4932e-04,  ...,  4.2725e-04,\n",
      "         -2.4414e-04,  9.1553e-05],\n",
      "        [-3.6621e-04,  4.8828e-04, -2.7466e-04,  ...,  6.7139e-04,\n",
      "          1.4038e-03,  4.8828e-04],\n",
      "        [-4.7302e-04, -1.6785e-04, -1.4496e-03,  ...,  1.5259e-04,\n",
      "          1.5564e-03, -2.4414e-04],\n",
      "        ...,\n",
      "        [ 5.4932e-04, -1.0986e-03, -7.9346e-04,  ...,  1.8311e-04,\n",
      "          3.6621e-04,  1.2398e-04],\n",
      "        [-2.0504e-04,  6.1035e-04, -6.4087e-04,  ...,  6.7139e-04,\n",
      "         -1.3733e-04, -4.2725e-04],\n",
      "        [ 3.6621e-04, -8.5449e-04, -1.2207e-03,  ...,  1.1826e-04,\n",
      "         -3.3569e-04,  8.5449e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.mlp.down_proj.weight\n",
      "model.layers.25.input_layernorm.weight\n",
      "tensor([-0.0020,  0.0000, -0.0020,  ...,  0.0000, -0.0020,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.input_layernorm.weight\n",
      "model.layers.25.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0039,  0.0000,  ..., -0.0020,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.25.post_attention_layernorm.weight\n",
      "model.layers.26.self_attn.q_proj.weight\n",
      "tensor([[-1.0920e-04,  5.3406e-05, -9.1553e-04,  ...,  3.0518e-05,\n",
      "         -2.2888e-05, -1.4954e-03],\n",
      "        [-1.5259e-04, -2.4414e-04,  1.0986e-03,  ..., -1.0986e-03,\n",
      "         -1.2207e-04, -4.0436e-04],\n",
      "        [ 6.0272e-04,  1.8311e-04, -6.1035e-04,  ...,  1.1292e-03,\n",
      "          0.0000e+00,  6.5231e-04],\n",
      "        ...,\n",
      "        [-2.7466e-04, -1.2207e-04, -6.1035e-05,  ...,  0.0000e+00,\n",
      "          8.5449e-04,  3.6621e-04],\n",
      "        [ 2.2316e-04,  2.4414e-04, -4.1199e-04,  ..., -6.1035e-04,\n",
      "          2.4414e-04,  4.8828e-04],\n",
      "        [-2.4414e-04, -7.3242e-04,  4.8828e-04,  ..., -3.0518e-04,\n",
      "          3.6621e-04, -5.7983e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.self_attn.q_proj.weight\n",
      "model.layers.26.self_attn.k_proj.weight\n",
      "tensor([[ 3.6621e-04,  6.1035e-05,  9.1553e-05,  ..., -6.1035e-05,\n",
      "          0.0000e+00, -5.4932e-04],\n",
      "        [ 1.2207e-04,  6.1417e-04, -1.2207e-04,  ..., -4.8828e-04,\n",
      "         -3.6621e-04, -6.1035e-04],\n",
      "        [-2.4414e-04,  3.6621e-04,  0.0000e+00,  ...,  3.6621e-04,\n",
      "          6.1035e-05,  2.4414e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-05,  1.2207e-04,  1.2207e-04,  ..., -4.1962e-04,\n",
      "         -7.5531e-04, -7.3242e-04],\n",
      "        [-9.7656e-04, -8.3923e-05,  9.1553e-04,  ..., -4.5776e-04,\n",
      "         -3.6621e-04,  7.3242e-04],\n",
      "        [ 1.0681e-04,  1.8311e-04,  6.1035e-05,  ..., -1.5259e-04,\n",
      "         -4.8828e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.self_attn.k_proj.weight\n",
      "model.layers.26.self_attn.v_proj.weight\n",
      "tensor([[-1.8311e-04, -2.4414e-04,  7.1716e-04,  ...,  8.2397e-04,\n",
      "         -7.9346e-04, -3.0518e-04],\n",
      "        [-3.6621e-04,  1.2207e-04, -4.5776e-04,  ..., -5.9509e-04,\n",
      "          4.8828e-04, -1.2207e-04],\n",
      "        [ 1.5259e-04,  5.4932e-04,  6.8665e-05,  ..., -8.1635e-04,\n",
      "         -2.4414e-04,  2.0218e-04],\n",
      "        ...,\n",
      "        [-6.1035e-04, -4.1962e-04, -2.1362e-04,  ...,  9.4604e-04,\n",
      "          1.2207e-04,  6.7139e-04],\n",
      "        [ 9.3079e-04, -9.7656e-04, -3.6621e-04,  ...,  2.4414e-04,\n",
      "          4.7302e-04,  3.6621e-04],\n",
      "        [ 2.4414e-04,  1.2207e-04, -2.4414e-04,  ..., -8.5449e-04,\n",
      "         -4.8828e-04, -4.5776e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.self_attn.v_proj.weight\n",
      "model.layers.26.self_attn.o_proj.weight\n",
      "tensor([[ 6.1035e-04,  2.7466e-04,  5.7602e-04,  ..., -3.0518e-05,\n",
      "          6.1035e-05,  9.1553e-04],\n",
      "        [-4.2725e-04, -4.8828e-04,  4.5776e-04,  ..., -1.2207e-04,\n",
      "         -9.7656e-04, -9.1553e-04],\n",
      "        [-1.2817e-03, -7.2861e-04,  3.1281e-04,  ..., -4.8828e-04,\n",
      "         -2.8992e-04,  8.2397e-04],\n",
      "        ...,\n",
      "        [ 4.2725e-04, -1.5259e-04, -3.0518e-04,  ..., -2.4414e-04,\n",
      "         -3.0518e-04, -1.5259e-04],\n",
      "        [-5.1117e-04,  9.9945e-04,  3.6621e-04,  ..., -2.4414e-04,\n",
      "         -3.0518e-04,  4.2725e-04],\n",
      "        [-4.0054e-04,  1.8311e-04, -8.0872e-04,  ...,  0.0000e+00,\n",
      "         -3.9864e-04, -1.2207e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.self_attn.o_proj.weight\n",
      "model.layers.26.mlp.gate_proj.weight\n",
      "tensor([[ 4.8828e-04,  1.0986e-03,  0.0000e+00,  ..., -6.1035e-05,\n",
      "          2.4414e-04, -6.7139e-04],\n",
      "        [ 8.5449e-04,  2.4414e-04,  1.2207e-04,  ...,  4.8828e-04,\n",
      "         -2.4414e-04,  6.1035e-05],\n",
      "        [ 2.4414e-04, -1.3428e-03, -3.0518e-04,  ..., -6.1035e-05,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 1.2207e-03, -3.6621e-04,  1.8311e-04,  ..., -3.0518e-04,\n",
      "          1.0681e-04,  7.3242e-04],\n",
      "        [ 8.5449e-04, -5.9128e-04, -6.1035e-05,  ..., -5.7983e-04,\n",
      "         -1.2207e-04,  5.4932e-04],\n",
      "        [ 1.2817e-03,  2.4414e-04, -1.1063e-03,  ...,  2.4414e-04,\n",
      "         -7.0190e-04, -4.5776e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.mlp.gate_proj.weight\n",
      "model.layers.26.mlp.up_proj.weight\n",
      "tensor([[-7.3624e-04,  7.3242e-04,  9.7656e-04,  ..., -2.8992e-04,\n",
      "         -5.1880e-04, -7.0190e-04],\n",
      "        [-4.5776e-05, -7.9346e-04, -3.6621e-04,  ...,  9.1553e-04,\n",
      "          4.4250e-04,  6.1035e-05],\n",
      "        [-4.8828e-04, -5.9509e-04, -7.3242e-04,  ..., -5.4932e-04,\n",
      "          0.0000e+00,  9.0027e-04],\n",
      "        ...,\n",
      "        [-9.7656e-04,  1.8311e-04,  1.6022e-04,  ..., -9.7656e-04,\n",
      "          3.6621e-04, -1.0071e-03],\n",
      "        [ 1.2207e-04, -2.4414e-04,  3.3569e-04,  ...,  0.0000e+00,\n",
      "          7.3242e-04, -2.4414e-04],\n",
      "        [-6.7139e-04, -5.2643e-04,  7.9346e-04,  ...,  1.2207e-04,\n",
      "         -1.8311e-04,  2.2888e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.mlp.up_proj.weight\n",
      "model.layers.26.mlp.down_proj.weight\n",
      "tensor([[-3.6621e-04, -6.7139e-04,  1.1292e-03,  ..., -5.7983e-04,\n",
      "          6.1035e-05, -6.1035e-04],\n",
      "        [ 1.8311e-04, -7.4005e-04,  9.7656e-04,  ...,  1.9836e-04,\n",
      "          1.2207e-04,  6.1035e-04],\n",
      "        [ 4.5776e-04,  3.6621e-04, -3.0518e-04,  ..., -4.4250e-04,\n",
      "          3.6621e-04,  3.0518e-05],\n",
      "        ...,\n",
      "        [ 1.8311e-04,  4.8828e-04, -1.8311e-04,  ..., -8.5449e-04,\n",
      "          1.1902e-03, -1.2207e-03],\n",
      "        [-2.7466e-04,  1.2207e-04,  0.0000e+00,  ..., -5.3024e-04,\n",
      "          3.5858e-04,  3.5095e-04],\n",
      "        [-2.7466e-04, -5.4932e-04,  6.1035e-05,  ..., -3.6621e-04,\n",
      "         -2.8992e-04,  6.1035e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.mlp.down_proj.weight\n",
      "model.layers.26.input_layernorm.weight\n",
      "tensor([-0.0039,  0.0000, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.input_layernorm.weight\n",
      "model.layers.26.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0039,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.26.post_attention_layernorm.weight\n",
      "model.layers.27.self_attn.q_proj.weight\n",
      "tensor([[ 3.6621e-04,  6.1035e-04, -6.1035e-04,  ...,  2.4414e-04,\n",
      "         -4.5776e-04,  4.8828e-04],\n",
      "        [-1.8311e-04,  4.8828e-04, -4.8828e-04,  ...,  6.1035e-05,\n",
      "          3.0518e-04,  6.1035e-05],\n",
      "        [-7.9346e-04,  3.0518e-04,  6.1035e-05,  ...,  1.5259e-04,\n",
      "          0.0000e+00, -6.1035e-05],\n",
      "        ...,\n",
      "        [ 3.6621e-04,  4.2725e-04,  4.8828e-04,  ...,  7.3242e-04,\n",
      "          7.9346e-04,  2.2125e-04],\n",
      "        [-2.4414e-04, -6.1035e-04, -3.0518e-05,  ..., -7.9346e-04,\n",
      "         -3.6621e-04,  8.5449e-04],\n",
      "        [ 3.6621e-04, -1.4305e-04,  3.0518e-04,  ...,  2.4414e-04,\n",
      "          6.1035e-05,  2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.self_attn.q_proj.weight\n",
      "model.layers.27.self_attn.k_proj.weight\n",
      "tensor([[ 0.0000e+00,  7.3242e-04, -7.3242e-04,  ...,  3.6621e-04,\n",
      "         -3.6621e-04,  4.2725e-04],\n",
      "        [ 9.1553e-05,  1.2207e-04, -3.6621e-04,  ..., -1.5259e-04,\n",
      "         -3.6621e-04, -1.2207e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00, -9.1553e-04,  ..., -2.4414e-04,\n",
      "         -4.8828e-04,  4.8828e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -2.4414e-04,  2.4414e-04,  ..., -9.1553e-05,\n",
      "          3.8147e-04, -3.6621e-04],\n",
      "        [-4.8828e-04,  2.7466e-04, -1.2207e-04,  ...,  4.8828e-04,\n",
      "          5.4932e-04,  3.6621e-04],\n",
      "        [ 1.2207e-04, -2.4414e-04,  2.7466e-04,  ..., -6.1035e-04,\n",
      "         -1.5259e-05, -9.7656e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.self_attn.k_proj.weight\n",
      "model.layers.27.self_attn.v_proj.weight\n",
      "tensor([[ 6.5613e-04, -3.0518e-04,  1.2207e-04,  ..., -9.1553e-04,\n",
      "          5.3024e-04, -7.3242e-04],\n",
      "        [ 4.8828e-04,  0.0000e+00,  1.7738e-04,  ...,  5.1880e-04,\n",
      "         -8.3923e-05,  4.8828e-04],\n",
      "        [ 9.7656e-04, -8.5449e-04, -7.3242e-04,  ...,  0.0000e+00,\n",
      "          2.4414e-04,  2.4414e-04],\n",
      "        ...,\n",
      "        [-8.2397e-04,  2.4414e-04, -2.8992e-04,  ..., -2.4414e-04,\n",
      "          6.1035e-05,  4.8828e-04],\n",
      "        [ 4.8828e-04,  5.5695e-04, -1.3428e-03,  ..., -7.9346e-04,\n",
      "         -7.3242e-04, -6.4087e-04],\n",
      "        [ 7.3242e-04,  3.0518e-05,  3.6621e-04,  ...,  8.3160e-04,\n",
      "         -5.4932e-04, -6.1035e-05]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.self_attn.v_proj.weight\n",
      "model.layers.27.self_attn.o_proj.weight\n",
      "tensor([[ 9.1553e-05,  3.0518e-04, -7.0190e-04,  ...,  4.2725e-04,\n",
      "         -5.1880e-04, -1.8311e-04],\n",
      "        [ 1.2207e-04,  1.2207e-04, -1.2207e-04,  ...,  1.2817e-03,\n",
      "          2.5940e-04, -2.4414e-04],\n",
      "        [ 6.7139e-04, -4.2725e-04, -6.7139e-04,  ..., -6.1035e-05,\n",
      "         -7.7820e-04, -1.2207e-04],\n",
      "        ...,\n",
      "        [ 3.2043e-04,  1.0986e-03, -2.7466e-04,  ..., -2.5940e-04,\n",
      "         -2.4414e-04, -7.3242e-04],\n",
      "        [ 5.4932e-04, -5.1880e-04, -3.6621e-04,  ...,  3.6621e-04,\n",
      "         -1.2207e-03, -1.0223e-03],\n",
      "        [ 4.8828e-04,  9.1553e-04, -1.2207e-04,  ...,  1.6022e-04,\n",
      "         -4.5776e-04, -6.1035e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.self_attn.o_proj.weight\n",
      "model.layers.27.mlp.gate_proj.weight\n",
      "tensor([[-5.2261e-04,  3.6621e-04, -5.7983e-04,  ...,  5.4932e-04,\n",
      "          3.0518e-04, -7.0190e-04],\n",
      "        [-2.7466e-04, -3.6621e-04, -2.4414e-04,  ..., -3.3569e-04,\n",
      "         -6.2561e-04,  6.1035e-05],\n",
      "        [-1.2817e-03,  2.4414e-04,  8.0109e-04,  ...,  1.2207e-04,\n",
      "         -3.0518e-04,  1.2207e-04],\n",
      "        ...,\n",
      "        [-3.6621e-04, -1.5869e-03,  3.0518e-04,  ...,  3.6621e-04,\n",
      "         -3.0518e-04,  0.0000e+00],\n",
      "        [-8.2397e-04,  2.4414e-04,  4.5776e-04,  ...,  6.1035e-05,\n",
      "         -5.3406e-04, -1.5259e-04],\n",
      "        [ 3.0518e-05,  3.6621e-04, -6.1035e-04,  ...,  1.8311e-04,\n",
      "         -3.6621e-04, -4.2725e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.mlp.gate_proj.weight\n",
      "model.layers.27.mlp.up_proj.weight\n",
      "tensor([[ 1.2207e-04,  2.4414e-04, -6.7139e-04,  ...,  7.6294e-05,\n",
      "         -1.8311e-04,  9.7656e-04],\n",
      "        [-7.3242e-04, -1.8311e-04,  1.2970e-03,  ...,  2.4414e-04,\n",
      "         -6.1035e-04, -2.4414e-04],\n",
      "        [ 5.7983e-04,  2.1076e-04, -1.8311e-04,  ...,  1.3733e-04,\n",
      "          3.8147e-04, -4.4250e-04],\n",
      "        ...,\n",
      "        [-1.3428e-03,  8.0872e-04, -8.5449e-04,  ...,  5.4932e-04,\n",
      "          6.1035e-05,  9.7656e-04],\n",
      "        [-3.6621e-04, -1.4648e-03, -5.9509e-04,  ...,  2.6703e-04,\n",
      "          4.8828e-04, -2.4414e-04],\n",
      "        [ 6.7139e-04, -8.0872e-04,  9.7656e-04,  ...,  6.1035e-05,\n",
      "          4.5776e-05,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.mlp.up_proj.weight\n",
      "model.layers.27.mlp.down_proj.weight\n",
      "tensor([[-3.6621e-04, -4.8828e-04, -8.3923e-05,  ..., -7.3242e-04,\n",
      "         -3.6621e-04, -6.1035e-04],\n",
      "        [-2.7466e-04,  5.8746e-04, -9.1553e-05,  ..., -6.1035e-05,\n",
      "         -7.3242e-04, -1.3428e-03],\n",
      "        [ 6.1035e-05, -4.2725e-04, -5.9509e-04,  ...,  1.0986e-03,\n",
      "         -6.1035e-05,  5.4932e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -4.8828e-04,  2.7466e-04,  ..., -3.6621e-04,\n",
      "         -2.1362e-04, -8.8501e-04],\n",
      "        [ 2.2888e-04,  0.0000e+00,  9.0408e-04,  ...,  5.4932e-04,\n",
      "         -3.6621e-04,  2.3651e-04],\n",
      "        [ 7.4768e-04, -7.9346e-04,  9.7656e-04,  ..., -1.8311e-04,\n",
      "         -1.9073e-03, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.mlp.down_proj.weight\n",
      "model.layers.27.input_layernorm.weight\n",
      "tensor([ 0.0000, -0.0039, -0.0020,  ...,  0.0000, -0.0020, -0.0039],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.input_layernorm.weight\n",
      "model.layers.27.post_attention_layernorm.weight\n",
      "tensor([-0.0039, -0.0039, -0.0039,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.27.post_attention_layernorm.weight\n",
      "model.layers.28.self_attn.q_proj.weight\n",
      "tensor([[ 9.1553e-04, -2.8992e-04, -4.8828e-04,  ..., -1.8311e-04,\n",
      "         -4.2725e-04,  2.1362e-04],\n",
      "        [ 7.3242e-04, -6.1035e-04, -5.4169e-04,  ...,  1.8311e-04,\n",
      "         -1.2207e-04, -6.1035e-05],\n",
      "        [ 4.8828e-04,  3.0518e-05,  0.0000e+00,  ..., -1.0376e-03,\n",
      "         -1.8311e-04,  1.8311e-04],\n",
      "        ...,\n",
      "        [ 3.3569e-04, -3.6621e-04,  7.3242e-04,  ..., -5.7983e-04,\n",
      "         -6.1035e-04, -4.8828e-04],\n",
      "        [ 3.6621e-04, -9.7656e-04, -4.2725e-04,  ..., -6.8665e-05,\n",
      "         -1.6785e-03, -1.2207e-04],\n",
      "        [-4.2725e-04, -1.8311e-04, -1.1597e-03,  ...,  7.3242e-04,\n",
      "         -3.0518e-04, -1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.self_attn.q_proj.weight\n",
      "model.layers.28.self_attn.k_proj.weight\n",
      "tensor([[ 1.2207e-03, -4.8828e-04, -3.8910e-04,  ...,  2.4414e-04,\n",
      "          6.1035e-05,  8.2397e-04],\n",
      "        [-6.1035e-04,  1.8311e-04,  3.6621e-04,  ..., -6.1035e-05,\n",
      "          8.0109e-04,  9.1553e-05],\n",
      "        [-6.7139e-04,  1.0376e-03,  1.2207e-03,  ..., -7.5912e-04,\n",
      "          1.8311e-04, -3.2043e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04, -4.8828e-04,  9.1553e-04,  ..., -4.8828e-04,\n",
      "         -4.8828e-04,  0.0000e+00],\n",
      "        [ 0.0000e+00,  4.2725e-04, -2.4414e-04,  ...,  1.3428e-03,\n",
      "         -2.4414e-04, -4.8828e-04],\n",
      "        [ 0.0000e+00, -1.2207e-04,  4.8828e-04,  ...,  1.2207e-03,\n",
      "         -5.6458e-04, -3.0518e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.self_attn.k_proj.weight\n",
      "model.layers.28.self_attn.v_proj.weight\n",
      "tensor([[ 4.1199e-04,  1.5259e-04,  5.1880e-04,  ...,  1.2207e-04,\n",
      "          1.2207e-04,  0.0000e+00],\n",
      "        [ 6.1035e-04,  2.8992e-04, -5.7983e-04,  ..., -8.2397e-04,\n",
      "         -1.2207e-04, -2.7466e-04],\n",
      "        [ 9.7656e-04, -4.2725e-04,  6.1035e-04,  ..., -5.3406e-04,\n",
      "          3.6621e-04,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 8.2397e-04,  0.0000e+00, -3.0518e-04,  ..., -1.4954e-03,\n",
      "          4.8828e-04,  4.1962e-04],\n",
      "        [ 3.0518e-04, -1.2207e-04,  3.0518e-04,  ...,  1.5259e-05,\n",
      "         -1.2207e-04,  4.5776e-04],\n",
      "        [ 7.9346e-04, -8.5449e-04, -5.0354e-04,  ..., -1.8311e-04,\n",
      "          9.1553e-05,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.self_attn.v_proj.weight\n",
      "model.layers.28.self_attn.o_proj.weight\n",
      "tensor([[ 1.5831e-04,  1.2207e-04, -7.3242e-04,  ...,  3.0518e-04,\n",
      "          1.2207e-04,  1.8311e-04],\n",
      "        [ 2.4414e-04, -3.6621e-04, -6.7139e-04,  ...,  1.8311e-04,\n",
      "          7.1716e-04,  1.8311e-04],\n",
      "        [-1.8311e-04, -1.6785e-04, -2.4414e-04,  ...,  1.8311e-04,\n",
      "         -3.6621e-04, -4.5776e-05],\n",
      "        ...,\n",
      "        [ 6.1035e-05, -9.4604e-04,  3.6621e-04,  ..., -8.5449e-04,\n",
      "         -1.1292e-03,  2.5940e-04],\n",
      "        [-1.2207e-04,  3.6621e-04,  1.3638e-04,  ...,  2.4414e-04,\n",
      "          2.4414e-04, -5.4932e-04],\n",
      "        [-3.6621e-04, -6.1035e-05,  1.2207e-04,  ..., -7.9346e-04,\n",
      "         -6.4087e-04,  1.2207e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.self_attn.o_proj.weight\n",
      "model.layers.28.mlp.gate_proj.weight\n",
      "tensor([[ 8.5449e-04, -5.1880e-04,  6.1035e-05,  ..., -3.6621e-04,\n",
      "          6.7139e-04, -1.8311e-04],\n",
      "        [ 7.3242e-04,  4.8828e-04,  1.8311e-04,  ..., -1.0071e-03,\n",
      "         -6.1035e-05,  0.0000e+00],\n",
      "        [-6.1035e-05,  2.1362e-04, -6.1035e-04,  ..., -3.6621e-04,\n",
      "          4.8828e-04, -1.3161e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-04, -6.1035e-04, -6.4087e-04,  ...,  7.9346e-04,\n",
      "          2.2125e-04, -1.2207e-03],\n",
      "        [-6.1035e-04,  6.1035e-04, -1.2207e-04,  ..., -1.0376e-03,\n",
      "          1.0681e-03,  6.1035e-04],\n",
      "        [ 4.8828e-04,  2.4414e-04,  3.0518e-04,  ...,  2.4414e-04,\n",
      "          4.8828e-04, -5.1498e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.mlp.gate_proj.weight\n",
      "model.layers.28.mlp.up_proj.weight\n",
      "tensor([[ 6.1035e-05, -8.5449e-04,  6.1035e-04,  ..., -3.9673e-04,\n",
      "          3.0518e-04,  3.0518e-05],\n",
      "        [-1.5259e-04, -2.8992e-04,  2.7466e-04,  ..., -2.4414e-04,\n",
      "          0.0000e+00, -2.5940e-04],\n",
      "        [ 5.4932e-04, -1.1292e-03,  2.4414e-04,  ...,  4.1199e-04,\n",
      "         -4.8828e-04, -3.0518e-04],\n",
      "        ...,\n",
      "        [ 6.7139e-04,  1.8311e-04, -6.4850e-05,  ...,  7.3242e-04,\n",
      "          4.1199e-04,  1.1597e-03],\n",
      "        [-1.9264e-04, -4.2725e-04,  3.9673e-04,  ...,  1.2817e-03,\n",
      "         -6.7139e-04, -5.4932e-04],\n",
      "        [-3.3569e-04, -6.1035e-04, -3.3569e-04,  ...,  0.0000e+00,\n",
      "         -5.4169e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.mlp.up_proj.weight\n",
      "model.layers.28.mlp.down_proj.weight\n",
      "tensor([[ 1.6785e-04, -3.3569e-04,  4.7302e-04,  ...,  0.0000e+00,\n",
      "         -4.5776e-04,  3.3188e-04],\n",
      "        [-2.7847e-04, -1.0681e-04, -6.1035e-05,  ...,  9.4604e-04,\n",
      "          6.8665e-04, -2.4414e-04],\n",
      "        [ 5.4932e-04,  1.2207e-03,  3.2043e-04,  ...,  8.5449e-04,\n",
      "          1.8692e-04, -6.1035e-04],\n",
      "        ...,\n",
      "        [-2.4414e-04,  6.1035e-04,  4.1199e-04,  ...,  1.9455e-04,\n",
      "          1.5259e-03,  3.0518e-04],\n",
      "        [-6.1035e-04,  1.1139e-03,  2.4414e-04,  ...,  5.4932e-04,\n",
      "         -2.1362e-04,  1.3733e-04],\n",
      "        [-4.9591e-04,  1.1749e-03, -6.1035e-05,  ..., -3.0518e-04,\n",
      "         -1.0071e-03, -2.1362e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.mlp.down_proj.weight\n",
      "model.layers.28.input_layernorm.weight\n",
      "tensor([-0.0039, -0.0039, -0.0039,  ..., -0.0039, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.input_layernorm.weight\n",
      "model.layers.28.post_attention_layernorm.weight\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0039, -0.0039],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.28.post_attention_layernorm.weight\n",
      "model.layers.29.self_attn.q_proj.weight\n",
      "tensor([[ 4.8828e-04, -1.2207e-03, -3.0518e-05,  ...,  3.6621e-04,\n",
      "          0.0000e+00, -1.2207e-04],\n",
      "        [-6.1035e-05,  1.2207e-03,  1.2207e-04,  ..., -1.2207e-04,\n",
      "         -4.6921e-04,  4.3488e-04],\n",
      "        [-1.8311e-04,  1.5411e-03,  0.0000e+00,  ..., -8.3447e-05,\n",
      "         -1.8311e-04,  3.6621e-04],\n",
      "        ...,\n",
      "        [ 1.8311e-04,  6.1035e-05,  7.3242e-04,  ...,  8.2397e-04,\n",
      "         -4.8828e-04,  1.2207e-04],\n",
      "        [-1.2207e-04, -7.9346e-04, -2.8419e-04,  ...,  3.6621e-04,\n",
      "          2.5940e-04,  2.4414e-04],\n",
      "        [ 7.9346e-04, -1.2970e-03, -8.5449e-04,  ...,  7.3242e-04,\n",
      "         -4.5776e-04, -9.6130e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.self_attn.q_proj.weight\n",
      "model.layers.29.self_attn.k_proj.weight\n",
      "tensor([[ 1.8311e-04, -1.5259e-04,  3.0518e-04,  ...,  8.5449e-04,\n",
      "         -9.1553e-04, -2.4414e-04],\n",
      "        [ 2.4414e-04, -1.2207e-04, -1.2207e-04,  ..., -3.6621e-04,\n",
      "         -3.6621e-04,  9.7656e-04],\n",
      "        [-4.8828e-04,  2.4414e-04,  3.9673e-04,  ...,  7.3242e-04,\n",
      "         -5.4932e-04,  6.7139e-04],\n",
      "        ...,\n",
      "        [ 1.2207e-04, -6.1035e-05,  2.4414e-04,  ...,  7.3242e-04,\n",
      "         -6.1035e-05, -2.4414e-04],\n",
      "        [ 1.4648e-03, -3.4714e-04, -3.0518e-04,  ..., -1.7548e-04,\n",
      "          1.0986e-03, -4.8828e-04],\n",
      "        [ 1.3885e-03,  0.0000e+00,  1.2207e-03,  ...,  1.7090e-03,\n",
      "          1.2207e-04, -6.1035e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.self_attn.k_proj.weight\n",
      "model.layers.29.self_attn.v_proj.weight\n",
      "tensor([[ 4.2725e-04, -1.2817e-03,  0.0000e+00,  ..., -4.8828e-04,\n",
      "         -6.1035e-05, -2.4414e-04],\n",
      "        [-4.4250e-04,  4.8828e-04,  0.0000e+00,  ...,  5.1880e-04,\n",
      "          1.3428e-03, -3.5095e-04],\n",
      "        [-9.3079e-04, -6.1035e-04, -3.3569e-04,  ..., -4.5776e-05,\n",
      "         -3.6621e-04,  6.1035e-05],\n",
      "        ...,\n",
      "        [-7.3242e-04,  1.0986e-03, -7.3242e-04,  ...,  1.5259e-05,\n",
      "          6.1035e-05,  1.5259e-04],\n",
      "        [-6.1035e-04,  6.4087e-04,  3.6621e-04,  ..., -1.6785e-04,\n",
      "          3.0518e-05, -2.4414e-04],\n",
      "        [-3.0518e-04,  6.1035e-05, -2.4414e-04,  ...,  2.1362e-04,\n",
      "          6.1035e-05,  6.1035e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.self_attn.v_proj.weight\n",
      "model.layers.29.self_attn.o_proj.weight\n",
      "tensor([[-4.8828e-04,  1.2207e-03, -5.4932e-04,  ..., -3.6621e-04,\n",
      "         -5.4932e-04, -6.1035e-04],\n",
      "        [ 3.6621e-04,  1.0986e-03,  1.5259e-04,  ..., -2.4414e-04,\n",
      "         -7.0190e-04, -3.0518e-05],\n",
      "        [ 0.0000e+00,  1.0376e-03,  1.1539e-04,  ...,  1.0681e-03,\n",
      "          6.2561e-04, -3.9673e-04],\n",
      "        ...,\n",
      "        [-6.1035e-05, -9.1553e-05,  4.8828e-04,  ...,  4.2725e-04,\n",
      "         -2.7466e-04,  4.8828e-04],\n",
      "        [ 3.8338e-04,  3.6621e-04,  1.2207e-04,  ..., -1.8311e-04,\n",
      "         -2.4414e-04,  3.6621e-04],\n",
      "        [-3.6621e-04, -2.0409e-04,  1.5259e-04,  ...,  2.5177e-04,\n",
      "          6.1035e-04,  5.7220e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.self_attn.o_proj.weight\n",
      "model.layers.29.mlp.gate_proj.weight\n",
      "tensor([[-0.0004,  0.0005, -0.0008,  ...,  0.0002,  0.0003,  0.0004],\n",
      "        [ 0.0002, -0.0013, -0.0005,  ..., -0.0011, -0.0003,  0.0005],\n",
      "        [-0.0005,  0.0002, -0.0006,  ...,  0.0004,  0.0002,  0.0001],\n",
      "        ...,\n",
      "        [-0.0010, -0.0001,  0.0004,  ..., -0.0002, -0.0005,  0.0007],\n",
      "        [ 0.0000,  0.0002,  0.0007,  ...,  0.0006,  0.0002, -0.0001],\n",
      "        [ 0.0007,  0.0001, -0.0004,  ...,  0.0006, -0.0014,  0.0002]],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.mlp.gate_proj.weight\n",
      "model.layers.29.mlp.up_proj.weight\n",
      "tensor([[-1.2207e-04,  7.3242e-04, -9.4604e-04,  ...,  1.0681e-04,\n",
      "          0.0000e+00,  3.0518e-04],\n",
      "        [ 4.8828e-04, -6.1035e-05, -1.2207e-04,  ...,  5.0354e-04,\n",
      "          1.2207e-04,  3.0518e-04],\n",
      "        [ 1.2207e-04,  3.3569e-04, -1.0376e-03,  ..., -1.8311e-04,\n",
      "         -2.4414e-04, -5.4932e-04],\n",
      "        ...,\n",
      "        [ 6.4087e-04,  1.8311e-04, -7.3242e-04,  ...,  3.9673e-04,\n",
      "          2.4414e-04, -1.5259e-04],\n",
      "        [ 1.2207e-04,  3.6621e-04, -4.5776e-04,  ...,  0.0000e+00,\n",
      "          1.1444e-03,  7.3242e-04],\n",
      "        [-1.2207e-04, -6.1035e-04,  1.7738e-04,  ..., -5.9509e-04,\n",
      "          3.0518e-04, -5.4932e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.mlp.up_proj.weight\n",
      "model.layers.29.mlp.down_proj.weight\n",
      "tensor([[-4.8828e-04,  2.2125e-04, -1.2207e-04,  ..., -6.7139e-04,\n",
      "          3.0518e-05, -4.7302e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0834e-03,  ...,  1.2207e-04,\n",
      "         -3.6621e-04,  8.3923e-04],\n",
      "        [-4.2725e-04, -3.0518e-04, -3.0518e-04,  ..., -2.4414e-04,\n",
      "         -1.4801e-03,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 8.3923e-05,  4.5776e-05, -6.1035e-04,  ...,  4.2725e-04,\n",
      "          0.0000e+00,  8.0109e-05],\n",
      "        [ 1.6785e-04,  3.0518e-05,  3.5858e-04,  ..., -3.6621e-04,\n",
      "         -7.3242e-04, -1.0681e-03],\n",
      "        [ 3.6621e-04, -6.1035e-05,  2.1362e-04,  ..., -1.8311e-04,\n",
      "          1.2207e-04,  0.0000e+00]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.mlp.down_proj.weight\n",
      "model.layers.29.input_layernorm.weight\n",
      "tensor([-0.0020,  0.0000, -0.0039,  ...,  0.0000, -0.0020,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.input_layernorm.weight\n",
      "model.layers.29.post_attention_layernorm.weight\n",
      "tensor([-0.0039, -0.0039, -0.0039,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.29.post_attention_layernorm.weight\n",
      "model.layers.30.self_attn.q_proj.weight\n",
      "tensor([[-1.2207e-04,  1.2970e-04,  0.0000e+00,  ..., -2.4414e-04,\n",
      "          1.8311e-04, -6.1035e-05],\n",
      "        [ 3.6621e-04, -2.4414e-04, -8.5449e-04,  ...,  3.9673e-04,\n",
      "          1.2207e-04,  4.8828e-04],\n",
      "        [ 2.4414e-04, -1.2207e-04,  7.3242e-04,  ..., -5.4932e-04,\n",
      "         -6.1035e-05,  5.7983e-04],\n",
      "        ...,\n",
      "        [-1.2207e-03, -2.4414e-04,  4.8828e-04,  ...,  2.4414e-04,\n",
      "         -6.1035e-04, -2.4414e-04],\n",
      "        [-7.3242e-04,  2.4414e-04, -5.4932e-04,  ...,  3.5095e-04,\n",
      "          4.8828e-04,  2.4414e-04],\n",
      "        [-6.1035e-04,  3.0518e-04, -6.1035e-05,  ...,  4.8828e-04,\n",
      "          7.3242e-04,  6.1035e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.self_attn.q_proj.weight\n",
      "model.layers.30.self_attn.k_proj.weight\n",
      "tensor([[ 5.4932e-04, -9.7656e-04,  2.0218e-04,  ...,  6.1035e-04,\n",
      "          7.3242e-04, -8.5449e-04],\n",
      "        [ 6.1035e-05, -3.8147e-04,  1.2207e-04,  ..., -9.4604e-04,\n",
      "          6.1035e-05, -8.5449e-04],\n",
      "        [-1.2207e-04,  9.7656e-04, -9.1553e-05,  ...,  1.2207e-04,\n",
      "          6.1035e-05,  6.1035e-04],\n",
      "        ...,\n",
      "        [ 1.9836e-04,  4.8828e-04, -1.0376e-03,  ...,  0.0000e+00,\n",
      "          3.0518e-04, -1.0681e-04],\n",
      "        [ 1.8311e-04,  3.6621e-04, -1.2207e-04,  ..., -6.1035e-04,\n",
      "         -3.6621e-04, -9.1553e-05],\n",
      "        [ 3.9673e-04,  3.7670e-05,  1.5259e-04,  ..., -1.8311e-04,\n",
      "         -1.2207e-04, -2.7466e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.self_attn.k_proj.weight\n",
      "model.layers.30.self_attn.v_proj.weight\n",
      "tensor([[-3.6621e-04, -2.4414e-04,  3.0518e-04,  ...,  1.2207e-04,\n",
      "          0.0000e+00,  4.8828e-04],\n",
      "        [-3.6621e-04, -7.4005e-04,  3.6621e-04,  ..., -4.8828e-04,\n",
      "          3.0518e-05,  7.3242e-04],\n",
      "        [ 6.1035e-04,  1.2207e-04,  2.4414e-04,  ...,  9.7656e-04,\n",
      "          1.2207e-04, -3.6621e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -3.9673e-04,  4.8828e-04,  ...,  2.4414e-04,\n",
      "         -1.2207e-04,  3.3569e-04],\n",
      "        [ 1.2207e-04, -3.6621e-04,  4.8828e-04,  ..., -6.1035e-04,\n",
      "          1.2207e-04,  2.4414e-04],\n",
      "        [-1.0986e-03,  3.0518e-04, -2.4414e-04,  ..., -4.8828e-04,\n",
      "         -2.4414e-04, -6.7139e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.self_attn.v_proj.weight\n",
      "model.layers.30.self_attn.o_proj.weight\n",
      "tensor([[-2.4414e-04,  9.1553e-04, -1.4343e-03,  ..., -1.8311e-04,\n",
      "         -6.1035e-05,  1.0376e-03],\n",
      "        [ 6.1035e-05,  1.8311e-04,  4.8828e-04,  ...,  1.0071e-03,\n",
      "         -1.0376e-03, -4.2725e-04],\n",
      "        [-4.5776e-04,  7.3242e-04,  0.0000e+00,  ...,  3.0518e-04,\n",
      "          1.2207e-04,  2.4414e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-05,  6.1035e-04, -5.7983e-04,  ...,  1.0986e-03,\n",
      "          3.0518e-05, -9.6893e-04],\n",
      "        [ 3.6621e-04,  1.8311e-04,  0.0000e+00,  ..., -1.6479e-03,\n",
      "          1.2207e-04,  9.4604e-04],\n",
      "        [ 5.4932e-04,  6.1035e-05, -9.1553e-04,  ..., -3.0518e-04,\n",
      "         -1.2207e-04,  1.9226e-03]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.self_attn.o_proj.weight\n",
      "model.layers.30.mlp.gate_proj.weight\n",
      "tensor([[-4.2725e-04,  4.2725e-04,  2.4414e-04,  ...,  1.5259e-04,\n",
      "         -1.9836e-04, -7.4005e-04],\n",
      "        [-9.1553e-05, -9.7656e-04,  2.4414e-04,  ..., -7.9346e-04,\n",
      "         -1.8311e-04, -3.6621e-04],\n",
      "        [ 8.3923e-04, -4.2725e-04, -2.5940e-04,  ..., -2.9755e-04,\n",
      "         -4.8828e-04, -1.5259e-04],\n",
      "        ...,\n",
      "        [ 6.1035e-05, -6.1035e-05,  0.0000e+00,  ..., -3.6621e-04,\n",
      "          6.1035e-05, -3.3569e-04],\n",
      "        [ 3.3569e-04, -1.1292e-03, -1.8311e-04,  ...,  9.9182e-04,\n",
      "          0.0000e+00,  2.7466e-04],\n",
      "        [-8.5449e-04, -3.6621e-04,  9.7656e-04,  ...,  0.0000e+00,\n",
      "          6.1035e-05, -4.8065e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.mlp.gate_proj.weight\n",
      "model.layers.30.mlp.up_proj.weight\n",
      "tensor([[ 3.0518e-05,  4.2725e-04, -3.8147e-05,  ...,  1.2207e-04,\n",
      "         -3.0136e-04,  5.4932e-04],\n",
      "        [ 7.9346e-04,  5.7983e-04, -3.6621e-04,  ..., -5.6458e-04,\n",
      "          3.2043e-04,  5.9509e-04],\n",
      "        [-5.4932e-04,  0.0000e+00,  0.0000e+00,  ...,  2.7466e-04,\n",
      "          6.4087e-04, -2.7466e-04],\n",
      "        ...,\n",
      "        [-1.6022e-04,  2.4414e-04,  1.2207e-04,  ..., -2.0218e-04,\n",
      "         -6.1035e-05,  1.0681e-03],\n",
      "        [-1.2207e-04, -4.8828e-04,  3.6621e-04,  ...,  6.1035e-05,\n",
      "          4.6539e-04,  2.7466e-04],\n",
      "        [-6.1035e-05, -4.5776e-04, -9.1553e-05,  ...,  8.5449e-04,\n",
      "          0.0000e+00,  7.9346e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.mlp.up_proj.weight\n",
      "model.layers.30.mlp.down_proj.weight\n",
      "tensor([[-3.6621e-04, -1.4496e-04, -2.4414e-04,  ...,  0.0000e+00,\n",
      "          7.3242e-04, -8.5449e-04],\n",
      "        [-1.3428e-03,  5.4932e-04, -3.0518e-04,  ..., -6.1035e-04,\n",
      "         -1.5259e-05, -2.6703e-04],\n",
      "        [-2.5940e-04, -9.3079e-04,  6.1035e-05,  ..., -2.4414e-04,\n",
      "         -4.2725e-04,  2.4414e-04],\n",
      "        ...,\n",
      "        [ 1.5259e-04, -7.3242e-04,  5.1880e-04,  ...,  2.7466e-04,\n",
      "          3.0518e-05,  1.8311e-04],\n",
      "        [ 8.3923e-04,  5.1880e-04,  5.4932e-04,  ..., -6.1035e-04,\n",
      "         -1.2207e-03,  3.6621e-04],\n",
      "        [-1.1292e-03,  1.0223e-03,  2.7466e-04,  ...,  7.3242e-04,\n",
      "          0.0000e+00, -2.4414e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.mlp.down_proj.weight\n",
      "model.layers.30.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ...,  0.0000, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.input_layernorm.weight\n",
      "model.layers.30.post_attention_layernorm.weight\n",
      "tensor([-0.0039, -0.0039,  0.0000,  ..., -0.0039, -0.0039, -0.0039],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.30.post_attention_layernorm.weight\n",
      "model.layers.31.self_attn.q_proj.weight\n",
      "tensor([[-5.7983e-04, -1.5259e-05, -3.9673e-04,  ...,  1.9073e-05,\n",
      "         -2.2888e-04, -4.5776e-05],\n",
      "        [ 4.4250e-04, -3.2806e-04,  6.1035e-04,  ..., -1.2207e-04,\n",
      "          1.2207e-04,  4.5776e-05],\n",
      "        [ 8.2397e-04,  3.0518e-04,  1.2207e-04,  ..., -5.0354e-04,\n",
      "          0.0000e+00, -5.4932e-04],\n",
      "        ...,\n",
      "        [-3.0518e-05, -2.4414e-04,  6.1035e-04,  ..., -3.6621e-04,\n",
      "          1.2207e-04,  1.2207e-04],\n",
      "        [-1.2207e-04,  4.8828e-04, -7.9346e-04,  ...,  9.7656e-04,\n",
      "         -3.9673e-04, -4.8828e-04],\n",
      "        [-2.7466e-04, -9.7656e-04, -6.1035e-05,  ...,  5.1880e-04,\n",
      "          2.2507e-04,  5.2261e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.self_attn.q_proj.weight\n",
      "model.layers.31.self_attn.k_proj.weight\n",
      "tensor([[ 0.0000e+00,  3.6621e-04, -6.1035e-04,  ...,  0.0000e+00,\n",
      "          4.5776e-04, -4.2725e-04],\n",
      "        [ 3.6621e-04,  1.2207e-04,  7.3242e-04,  ..., -1.2207e-04,\n",
      "          2.4414e-04,  1.2207e-04],\n",
      "        [-8.5449e-04, -1.1292e-03, -1.2207e-04,  ..., -6.4087e-04,\n",
      "         -3.0518e-05,  1.5259e-04],\n",
      "        ...,\n",
      "        [-1.2207e-04, -1.4648e-03,  6.1035e-04,  ..., -9.7656e-04,\n",
      "          4.8828e-04,  3.6621e-04],\n",
      "        [ 0.0000e+00,  7.3242e-04,  6.1035e-04,  ..., -1.2207e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-4.2725e-04, -4.8828e-04, -1.2207e-04,  ...,  6.1035e-04,\n",
      "          4.8828e-04,  8.5449e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.self_attn.k_proj.weight\n",
      "model.layers.31.self_attn.v_proj.weight\n",
      "tensor([[ 1.2207e-04,  2.4414e-04, -5.3406e-04,  ...,  4.8828e-04,\n",
      "          2.4414e-04, -1.0986e-03],\n",
      "        [ 1.0376e-03,  5.4932e-04, -3.0518e-04,  ..., -2.4414e-04,\n",
      "         -4.8828e-04, -1.8311e-04],\n",
      "        [ 4.8828e-04,  3.6621e-04,  7.9346e-04,  ..., -3.6621e-04,\n",
      "          1.2207e-04,  5.4932e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -4.7874e-04,  1.0204e-04,  ..., -3.6621e-04,\n",
      "          0.0000e+00, -3.0518e-05],\n",
      "        [ 2.2125e-04,  7.1716e-04, -2.7466e-04,  ..., -1.8311e-04,\n",
      "          3.2806e-04, -1.2207e-04],\n",
      "        [-1.2207e-04,  2.8992e-04,  3.0518e-04,  ..., -9.1553e-05,\n",
      "          2.4414e-04, -3.6621e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.self_attn.v_proj.weight\n",
      "model.layers.31.self_attn.o_proj.weight\n",
      "tensor([[-1.2207e-04,  6.1035e-04,  0.0000e+00,  ..., -1.8311e-04,\n",
      "         -3.0518e-05, -3.6621e-04],\n",
      "        [ 7.6294e-06,  2.7466e-04, -2.4414e-04,  ..., -1.2207e-04,\n",
      "         -1.1902e-03,  1.8311e-03],\n",
      "        [ 0.0000e+00, -6.1035e-05, -3.0518e-04,  ..., -7.4387e-04,\n",
      "          2.4414e-04,  9.1553e-04],\n",
      "        ...,\n",
      "        [-3.8910e-04,  0.0000e+00, -2.1362e-04,  ...,  2.2507e-04,\n",
      "         -4.7302e-04, -1.8311e-04],\n",
      "        [ 0.0000e+00, -1.5259e-04, -1.2207e-04,  ..., -1.0071e-03,\n",
      "         -7.3242e-04,  1.3733e-03],\n",
      "        [-7.3242e-04,  3.2806e-04, -4.2725e-04,  ...,  1.2207e-04,\n",
      "          1.2817e-03, -9.3842e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.self_attn.o_proj.weight\n",
      "model.layers.31.mlp.gate_proj.weight\n",
      "tensor([[ 0.0000e+00, -1.8311e-04, -1.2207e-03,  ..., -4.8828e-04,\n",
      "         -2.4414e-04,  1.2207e-04],\n",
      "        [ 3.0136e-04,  5.7983e-04, -1.2207e-04,  ...,  6.1035e-04,\n",
      "          6.4087e-04, -1.2207e-04],\n",
      "        [-1.6479e-03, -2.4414e-04, -6.1035e-05,  ..., -4.5776e-04,\n",
      "         -2.7466e-04, -4.6921e-04],\n",
      "        ...,\n",
      "        [ 0.0000e+00, -2.7466e-04, -7.3242e-04,  ..., -5.1880e-04,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00, -6.1035e-04,  ..., -1.2207e-04,\n",
      "          3.0518e-04,  3.0518e-04],\n",
      "        [ 3.6621e-04,  2.4414e-04,  1.2207e-04,  ..., -2.4414e-04,\n",
      "          2.4414e-04,  1.2207e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.mlp.gate_proj.weight\n",
      "model.layers.31.mlp.up_proj.weight\n",
      "tensor([[ 2.4414e-04, -3.6621e-04, -7.9346e-04,  ...,  3.6621e-04,\n",
      "          2.1362e-04,  4.8828e-04],\n",
      "        [ 2.7466e-04, -4.4250e-04,  0.0000e+00,  ..., -3.6621e-04,\n",
      "          4.8828e-04, -1.0071e-03],\n",
      "        [-4.2725e-04, -2.7466e-04,  9.1553e-05,  ...,  2.4414e-04,\n",
      "          1.2207e-04,  6.1035e-04],\n",
      "        ...,\n",
      "        [-4.8828e-04,  1.9073e-04,  0.0000e+00,  ...,  3.0518e-04,\n",
      "         -2.4414e-04,  1.3447e-04],\n",
      "        [ 1.2817e-03,  8.5449e-04,  1.2207e-04,  ...,  3.6621e-04,\n",
      "         -1.2207e-04,  6.7139e-04],\n",
      "        [ 0.0000e+00,  3.6621e-04,  6.4087e-04,  ...,  9.1553e-05,\n",
      "         -1.5259e-05, -1.8311e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.mlp.up_proj.weight\n",
      "model.layers.31.mlp.down_proj.weight\n",
      "tensor([[ 9.7656e-04, -5.4932e-04,  6.1035e-04,  ...,  6.9427e-04,\n",
      "         -7.3242e-04,  6.0654e-04],\n",
      "        [-7.9346e-04,  0.0000e+00, -9.0027e-04,  ..., -7.1716e-04,\n",
      "         -7.6294e-05,  2.4414e-04],\n",
      "        [-4.2725e-04,  3.6621e-04,  4.8828e-04,  ...,  7.6294e-05,\n",
      "          1.8311e-04,  6.1035e-05],\n",
      "        ...,\n",
      "        [-1.2207e-04, -2.5177e-04, -3.0518e-05,  ..., -2.4414e-04,\n",
      "         -2.4414e-04, -1.8311e-04],\n",
      "        [ 4.8828e-04,  4.5776e-04, -1.8311e-04,  ...,  2.4414e-04,\n",
      "          1.0376e-03, -1.8311e-04],\n",
      "        [ 6.1035e-05, -6.1035e-05, -3.6621e-04,  ..., -6.1035e-05,\n",
      "          8.5449e-04, -1.8311e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.mlp.down_proj.weight\n",
      "model.layers.31.input_layernorm.weight\n",
      "tensor([-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.input_layernorm.weight\n",
      "model.layers.31.post_attention_layernorm.weight\n",
      "tensor([ 0.0000, -0.0020,  0.0000,  ...,  0.0000, -0.0020, -0.0020],\n",
      "       dtype=torch.bfloat16)\n",
      "Diff applied for model.layers.31.post_attention_layernorm.weight\n",
      "model.norm.weight\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16)\n",
      "Diff applied for model.norm.weight\n",
      "lm_head.weight\n",
      "tensor([[-1.2207e-04,  1.2207e-04,  3.3569e-04,  ..., -1.3733e-04,\n",
      "         -1.2207e-04,  6.1035e-05],\n",
      "        [ 3.0518e-04,  6.1035e-05,  3.6621e-04,  ..., -1.6479e-03,\n",
      "          3.0518e-04,  6.8665e-05],\n",
      "        [-1.8311e-04, -1.8311e-04, -1.4038e-03,  ...,  5.0354e-04,\n",
      "          3.9673e-04, -6.1035e-04],\n",
      "        ...,\n",
      "        [-3.2043e-04, -2.1362e-03,  1.8005e-03,  ..., -1.4496e-03,\n",
      "          1.7090e-03, -8.5449e-04],\n",
      "        [-3.2043e-04, -2.1362e-03,  1.8005e-03,  ..., -1.4496e-03,\n",
      "          1.7090e-03, -8.5449e-04],\n",
      "        [-3.2043e-04, -2.1362e-03,  1.8005e-03,  ..., -1.4496e-03,\n",
      "          1.7090e-03, -8.5449e-04]], dtype=torch.bfloat16)\n",
      "Diff applied for lm_head.weight\n",
      "Model diffs applied.\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying model diffs...\")\n",
    "apply_model_diffs(target_model, model_diffs)\n",
    "print(\"Model diffs applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving target model...\n",
      "Target model saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving target model...\")\n",
    "target_model.save_pretrained('./models/Llama-3-Open-Ko-8B-meta-intruct-vector1.0')\n",
    "print(\"Target model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model_diffs, target_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test generative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_map = {\"\": 0}\n",
    "cache_model_dir=\"/mnt/t7/.cache/huggingface/models\"\n",
    "model_path = './models/Llama-3-Open-Ko-8B-meta-intruct-vector1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8580307621f944c8941870db8afa1d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map=device_map)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(target_model_name, cache_dir=cache_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"친절한 챗봇으로서 상대방의 요청에 최대한 자세하고 친절하게 답하자. 모든 대답은 한국어(Korean)으로 대답해줘.\"},\n",
    "    {\"role\": \"user\", \"content\": \"피보나치 수열이 뭐야? 그리고 피보나치 수열에 대해 파이썬 코드를 짜줘볼래?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! 피보나치 수열은 수학에서 매우 중요한 개념입니다. 피보나치 수열은 자연수의 집합에서 시작하여 무한히 이어지는 수열을 말합니다. 각 항은 이전 항의 다음 항의 약 두 배가 되는 성질을 갖는 수열입니다. 예를 들어, 1, 2, 4, 8, 16, 32, 64, 128, 256,...와 같은 수열입니다. 이 수열은 가장 기본적인 예이지만, 이보다 더 많은 예가 있습니다. 이 수열은 수학, 컴퓨터 과학, 경제학, 물리학 등 다양한 분야에서 사용됩니다.\n",
      "\n",
      "파이썬 코드를 짜보겠습니다. Python으로 피보나치 수열을 구현하는 예제를 보여드리겠습니다.\n",
      "\n",
      "```\n",
      "python\n",
      "def fibonacci(n):\n",
      "    a, b = 1, 1\n",
      "for i in range(1, n+1):\n",
      "    a, b = b, a + b\n",
      "print(fibonacci(n))\n",
      "```\n",
      "위 코드는 n번째 피보나치 수열의 항을 구현합니다. 이 코드를 실행하면, 1부터 시작하여 피보나치 수열의 각 항을 출력합니다. 예를 들어, `fibonacci(10)`을 실행하면, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 985, 1597, 2584, 4181,...를 출력합니다. 이 코드는 피보나치 수열의 기본적인 예를 보여주는 예시입니다. 이 코드를 응용하여 다양한 분야에서 사용할 수 있습니다. 예를 들어, 금융 분야에서는 투자 분석에 사용할 수 있습니다. 이 수열은 성장률을 예측하는 데 사용됩니다. 물리학에서는 나비의 이동 경로를 모델링하는 데 사용할 수 있습니다. 이 수열은 매우 유용합니다.\n",
      "\n",
      "이제까지 피보나치 수열에 대해 설명했습니다. 더 궁금한 점이 있으신가요?\n"
     ]
    }
   ],
   "source": [
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    top_p=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피보나치 수열(피보나치 수열, Fibonacci sequence)은 수학에서 가장 유명한 수열 중 하나입니다. 피보나치 수열은 0과 1로 시작하여 다음 항은 이전 항의 합으로 구성되는 수열입니다. 예를 들어, 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144,...으로 계속됩니다. 피보나치 수열은 수학, 컴퓨터 과학, 경제학, 생물학 등 다양한 분야에서 응용됩니다.\n",
      "\n",
      "피보나치 수열을 파이썬 코드로 구현하는 방법은 다음과 같습니다.\n",
      "```python\n",
      "a = 0\n",
      "b = 1\n",
      "fib_sequence = [a, b]\n",
      "while True:\n",
      "    a, b = b, a + b\n",
      "    print(fib_sequence)\n",
      "```\n",
      "위 코드는 피보나치 수열을 생성하는 파이썬 코드입니다. 이 코드는 0과 1로 시작하여 다음 항은 이전 항의 합으로 구성되는 피보나치 수열을 생성합니다. 이 코드를 실행하면 피보나치 수열이 출력됩니다. 이 코드는 수학자 피보나치의 이름에서 따온 이름입니다. 피보나치는 이 수열을 발견한 이탈리아 수학자입니다.\n",
      "\n",
      "이 코드를 실행하면 피보나치 수열이 출력됩니다. 이 코드는 수학자 피보나치의 이름에서 따온 이름입니다. 피보나치는 이 수열을 발견한 이탈리아 수학자입니다. 이 수열은 수학, 컴퓨터 과학, 경제학, 생물학 등 다양한 분야에서 응용됩니다. 이 수열은 수학자 피보나치의 이름에서 따온 이름입니다. 피보나치는 이 수열을 발견한 이탈리아 수학자입니다. 이 수열은 수학, 컴퓨터 과학, 경제학, 생물학 등 다양한 분야에서 응용됩니다. 이 수열은 수학자 피보나치의 이름에서 따온 이름입니다. 이 수열은 수학, 컴퓨터 과학, 경제학, 생물학 등 다양한 분야에서 응용됩니다. 이 수열은 수학자 피보나치의 이름에서 따온 이름입니다. 이 수열은 수\n"
     ]
    }
   ],
   "source": [
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=1,\n",
    "    top_p=0.95,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의아한 친구네! 피보나치 수열(Feigenbaum sequence)은 19세기 독일 수학자 레온하르트 오일러의 연구 결과물로, 1863년에 발표된 수열이야. 피보나치 수열은 0과 1의 재귀적 수열로, 각 각이 다음 수식에 의해 생성된다: a(n) = a(n-1) + a(n-2). 이 수열은 0과 1의 무한한 반복으로 구성되는데, 각 항의 값이 다음 항의 값에 따라 결정되어. 다음은 예를 들어보자. 0, 1, 0, 1, 0, 1, 0, 1,....\n",
      "\n",
      "이 수열을 파이썬 코드로 작성하려면 다음과 같이 짤 수 있어요!\n",
      "```\n",
      "a = 0\n",
      "for i in range(10):\n",
      "  print(a(i % 2) if i % 2 == 0 then\n",
      "  print(1)\n",
      "  else\n",
      "  print(0)\n",
      "```\n",
      "이 코드는 수열의 각 항을 출력할 때마다 0 또는 1을 출력하는 거야. 이 코드를 실행하면, 0과 1의 피보나치 수열이 출력돼!\n",
      "이 수열은 특정 패턴이 없는 것 같지만, 실제로는 패턴이 숨어있어. 그걸 찾는 것이 중요한 거야.\n",
      "원래 피보나치 수열은 암호 통신에 사용돼. 예를 들어 코드를 인코딩할 때, 이 수열을 사용하면 코드의 길이를 줄이거나 복잡도를 낮추는 데 사용하잖아!.\n",
      "이해했나? 다른 질문은 더 있어?\n"
     ]
    }
   ],
   "source": [
    "response = outputs[0][input_ids.shape[-1]:]\n",
    "print(tokenizer.decode(response, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\n"
     ]
    }
   ],
   "source": [
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_for_p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
