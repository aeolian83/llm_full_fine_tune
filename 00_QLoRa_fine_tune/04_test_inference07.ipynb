{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/aeolian83/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "login(token= os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'aeolian83/llama_ko_sft_kullm_experi_07'\n",
    "device_map = {\"\": 0}\n",
    "cache_model_dir=\"/mnt/t7/.cache/huggingface/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711a465786c44a4b8a3cfdbf01012fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./lora_merged_model/sft_10\", quantization_config=quantization_config, device_map=device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_01 = 'aeolian83/llama_ko_sft_kullm_experi_06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id_01, cache_dir=cache_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_01 = \"### instruction: AI에 대해 알려줘.\\n\\n### output:\"\n",
    "inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=500, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### instruction: AI에 대해 알려줘.\n",
      "\n",
      "### output: AI(인공 지능)는 컴퓨터 시스템에 사람의 지능과 같은 기능을 주는 것을 말합니다. 여기서 '지능'은 일반적으로 인간의 마음이나 생각에서 비롯되는 것으로 이해되는 능력을 말합니다. 인간의 지능을 컴퓨터 시스템에도 구현할 수 있게 되면 기계가 데이터를 분석하거나 결정을 내릴 수 있게 되어 인간이 개입하지 않고도 자율적으로 작동할 수 있게 될 수 있습니다. 인공지능은 머신 러닝, 딥 러닝, 자연어 처리와 같은 기술을 사용하여 강화 학습, 자율 시스템 구축, 언어 이해를 통해 특정 작업을 수행할 수 있습니다. 하지만 인공지능은 현재 인간의 정신 능력을 완전히 모방하는 것은 아니기 때문에 완전 자율 시스템은 완전히 자율적이거나 자율적인 것을 의미하지 않는다고 말하는 사람들도 있습니다. 하지만 괄목할 만한 발전을 이루고 있으며, 최근 몇 년 동안 놀라운 능력을 보여주고 있어 앞으로의 발전이 기대됩니다.</s>\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))\n",
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,   835, 15278, 29901,   319, 29902, 31054, 32550, 32947, 45189,\n",
      "        29889,    13,    13,  2277, 29937,  1962, 29901,   319, 29902, 29898,\n",
      "        30918, 31334, 36649, 29897, 31081, 43006, 33990, 31054, 36300, 36649,\n",
      "        31906, 32280, 38539, 34584, 32946, 32047, 32111, 29889, 35058,   525,\n",
      "        36208, 29915, 31354, 33039, 32196, 39609, 32176, 32144, 32155, 32012,\n",
      "        33539, 32312, 32301, 32819, 32312, 39419, 32047, 32111, 29889, 39609,\n",
      "        36649, 31286, 43006, 33990, 32306, 38400, 44827, 32017, 34142, 34265,\n",
      "        32013, 35474, 40923, 33312, 34456, 39560, 40399, 32017, 34142, 33733,\n",
      "        34234, 37286, 32175, 32931, 31136, 36136, 32196, 42575, 44827, 32017,\n",
      "        34142, 32478, 32017, 32777, 29889, 37651, 31354, 32466, 31262, 32431,\n",
      "        45433, 29892, 29871, 45982, 32431, 45433, 29892, 34162, 31129, 33948,\n",
      "        44834, 32280, 36463, 32332, 32932, 33099, 38191, 29892, 36136, 33990,\n",
      "        33648, 29892, 44492, 43646, 32298, 35786, 40864, 35242, 44827, 32017,\n",
      "        32777, 29889, 32834, 37651, 31354, 32702, 39609, 32394, 39419, 35705,\n",
      "        32045, 31945, 32022, 32866, 32104, 30827, 32673, 32642, 36136, 33990,\n",
      "        31354, 35705, 36136, 33409, 32706, 36136, 32203, 32946, 33318, 32175,\n",
      "        33050, 32096, 34716, 39927, 32777, 29889, 32834, 29871, 45616, 44994,\n",
      "        44827, 40677, 39545, 34872, 31137, 34705, 29892, 32735, 32627, 35500,\n",
      "        33238, 36494, 44860, 39419, 41255, 32791, 32892, 30708, 33772, 30393,\n",
      "        32615, 33214, 29889,     2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_01 = \"### instruction: 인공지능을 무엇을 할 수 있는지 알려줘.\\n\\n### output:\"\n",
    "inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=2048, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### instruction: 인공지능을 무엇을 할 수 있는지 알려줘.\n",
      "\n",
      "### output: 인공지능(AI)은 다양한 분야에 응용되어 인간의 의사 결정 및 작업을 지원합니다. 다음은 AI를 사용할 수 있는 몇 가지 잠재적 용도입니다:1. 의료: AI는 이미지를 분석하고 학습하여 질병을 진단하고, 의료 기록을 분석하고 예측 데이터를 생성하며, 적절한 치료 계획과 진단을 개발하는 데 사용할 수 있습니다.2. 금융: AI 플랫폼은 거래를 분석하고 미래의 위험을 예측할 수 있으며 잠재적인 사기와 사기 조짐을 식별하여 조치를 취할 수 있습니다. 예를 들어, 잠재적인 불법 거래를 식별하고 잠재적인 사기 패턴을 분석하는 데 사용할 수 있습니다. 또한 AI는 시장 데이터를 분석하고 미래의 수익 및 수익 예측치를 계산하며 개인화된 추천과 투자 조언을 제공합니다.3. 교육: AI는 학생들의 학습 경험을 개선할 수 있으며, 교육 데이터를 분석하고 개별화된 학습 경험을 예측하는 데 사용할 수 있습니다. 또한, AI는 학생들이 특정 문제에 대한 잠재적 솔루션을 발견하도록 가이드하거나 학생들의 학습 결과를 개선하도록 설계된 맞춤형 학습 경험이나 콘텐츠를 제공하는 데 사용할 수 있습니다.4. 공급망 관리: AI는 제조업체의 재고 및 생산 계획을 개선하고 예측 분석 및 예측을 사용하여 효율성과 생산성을 높일 수 있습니다. 예를 들어, 공급망에 추가하여 잠재적인 재고 부족을 예측하고 공급업체의 생산 스케줄 변경을 예상 가능하게 하는 시스템을 구현하는 데 사용할 수 있습니다.5. 마케팅: AI는 소비자의 행동과 선호도를 분석하고 데이터를 사용하여 타겟을 식별하고 개인화된 메시지를 전달할 수 있습니다. 예를 들어, 타겟 고객과 잠재 고객 간의 행동 차이를 분석하여 타겟팅된 광고와 이메일 캠페인을 생성하는 데 사용할 수 있습니다.6. 챗봇 및 가상 보조: AI가 사용되는 챗봇 및 가상 비서는 정보를 얻고, 특정 작업을 수행하고, 개인화된 답변을 제공할 수 있습니다. 예를 들어, 챗봇에서 데이터를 학습하고 특정 질문에 적합한 답변을 제공할 수 있으며, 가상 비서는 사용자가 대화를 계속할 때 사용자에게 개인화된 응답을 제공하도록 설계된 가상 비서를 생성할 수 있습니다.</s>\n",
      "466\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))\n",
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_01 = \"### instruction: 인공지능의 장점에 대해 알려줘.\\n\\n### output:\"\n",
    "inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs, num_beams = 3, early_stopping=True, max_new_tokens=2048, do_sample=True, top_k=50, top_p=0.95, eos_token_id=tokenizer.eos_token_id, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### instruction: 인공지능의 장점에 대해 알려줘.\n",
      "\n",
      "### output: 인공지능(AI)은 여러 가지 장점을 가지고 있습니다. 다음은 몇 가지 주요 장점입니다:\n",
      "\n",
      "1. 개인화: AI는 개인화된 경험을 제공할 수 있습니다. AI는 사용자의 행동, 선호도 및 선호도를 학습하고 이를 기반으로 개인화된 추천, 제안을 제공합니다.\n",
      "\n",
      "2. 효율성: AI는 반복적인 작업을 자동화하여 생산성을 높이고 시간을 절약할 수 있습니다. AI는 대량의 데이터를 빠르게 처리하고 분석하여 의사 결정에 도움을 줄 수 있습니다.\n",
      "\n",
      "3. 정확성: AI는 정확하고 일관된 결정을 내릴 수 있습니다. AI는 방대한 양의 데이터를 분석하고 패턴을 학습하여 정확하고 일관된 결정을 내릴 수 있습니다.\n",
      "\n",
      "4. 적응력: AI는 상황에 맞게 적응할 수 있습니다. AI는 학습하고 적응할 수 있어 시간이 지남에 따라 더 나은 결정을 내릴 수 있습니다.\n",
      "\n",
      "5. 효율성: AI는 반복적인 작업을 자동화하여 생산성을 높이고 시간을 절약할 수 있습니다. AI는 대량의 데이터를 빠르게 처리하고 분석하여 의사 결정에 도움을 줄 수 있습니다.\n",
      "\n",
      "6. 개인화: AI는 개인화된 경험을 제공할 수 있습니다. AI는 사용자의 행동, 선호도 및 선호도를 학습하고 이를 기반으로 개인화된 추천, 제안을 제공합니다.\n",
      "\n",
      "7. 효율성: AI는 반복적인 작업을 자동화하여 생산성을 높이고 시간을 절약할 수 있습니다. AI는 대량의 데이터를 빠르게 처리하고 분석하여 의사 결정에 도움을 줄 수 있습니다.</s>\n",
      "339\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))\n",
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_for_p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
