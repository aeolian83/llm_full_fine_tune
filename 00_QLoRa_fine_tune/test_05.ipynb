{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ko_instruction_01 = load_dataset(\"nlpai-lab/kullm-v2\", cache_dir=\"/mnt/t7/.cache/huggingface/datasets\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 문구를 동등한 문구로 대체하여 문장을 다시 작성합니다.\n",
      "그는 웃으며 즐거워했습니다.\n",
      "그는 호탕하게 웃으며 즐거워했습니다.\n"
     ]
    }
   ],
   "source": [
    "print(ko_instruction_01[10445]['instruction'])\n",
    "print(ko_instruction_01[10445]['input'])\n",
    "print(ko_instruction_01[10445]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/aeolian83/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "login(token= os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'aeolian83/llama_ko_sft_kullm_experi_02_non_q'\n",
    "device_map = {\"\": 0}\n",
    "cache_model_dir=\"/mnt/t7/.cache/huggingface/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b1e2f63ad745bf90e9b1be1ee37ba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config, device_map=device_map, cache_dir=cache_model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=cache_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_01 = \"### instruction: 주어진 문구를 동등한 문구로 대체하여 문장을 다시 작성합니다.\\n\\n### input: 그는 웃으며 즐거워했습니다.\\n\\n### output:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### instruction: 주어진 문구를 동등한 문구로 대체하여 문장을 다시 작성합니다.\n",
      "\n",
      "### input: 그는 웃으며 즐거워했습니다.\n",
      "\n",
      "### output: 그는 웃으며 즐거워했습니다.​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​\n",
      "540\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,   835, 15278, 29901, 32034, 35138, 32038, 34117, 32135, 44845,\n",
      "        30877, 32038, 36507, 33553, 32932, 32038, 32499, 32489, 36258, 32111,\n",
      "        29889,    13,    13,  2277, 29937,  1881, 29901, 32889, 32604, 32586,\n",
      "        42654, 45017, 32510, 29889,    13,    13,  2277, 29937,  1962, 29901,\n",
      "        32889, 32604, 32586, 42654, 45017, 32510, 29889, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166,\n",
      "        30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166, 30166],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_tok = [32303]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'한다'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(pad_tok, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_for_p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
