{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/aeolian83/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "login(token= os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"beomi/Llama-3-KoEn-8B-Instruct-preview\"\n",
    "device_map = {\"\": 0}\n",
    "cache_model_dir=\"/mnt/t7/.cache/huggingface/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for 4-bit QLoRA Training(4bit QLoRA 학습을 위한 설정)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, # Nvidia의 Ampere 아키텍처 이후 가속기는 bf16으로 속도 향상을 꾀할수 있다. \n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# bnb_4bit_quant_type=\"nf4\" 설정상 기본값은 bnb_4bit_quant_type=\"fp4\"이나 허깅페이스 저자들에 의하면\n",
    "# 경험적 결과로 \"nf4\"가 결과가 더 좋았다고 한다. https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
    "# bnb_4bit_use_double_quant=True로 하면 매개변수단 0.4bit을 추가로 절약 할 수 있다고 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6e9e2fe6dc4efeaaecd31c0679d964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=quantization_config, device_map=device_map, cache_dir=cache_model_dir, trust_remote_code=True)\n",
    "model.config.use_cache = True\n",
    "\n",
    "# model.config.pretraining_tp = 1\n",
    "# 종종 QLoRA 코드에 이 코드가 보이는데 병렬 학습에 쓰이는 코드로 보인다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True, cache_dir=cache_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(128257, 4096)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '<PAD>'})\n",
    "tokenizer.padding_side = \"left\"\n",
    "model.resize_token_embeddings(len(tokenizer)) # pad_token이 추가되었으므로 embedding과 language modeling head를 resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
    "''',\n",
    "    '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: Our models do, however, have log likelihoods better than the large estimates annealed importance sampling has been reported to produce for energy based models and score matching.\n",
    "''',\n",
    " '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: We focus on Latent Diffusion Models since they can perform a wide range of generative tasks. This work shows that simply fine-tuning a small part of the generative model.\n",
    "''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = tokenizer(examples, return_tensors=\"pt\", padding=True)['input_ids'].to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(example_batch, max_new_tokens = 1024, pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### Output: (번역) 샘플의 질이 좋지 않음에도 불구하고, 우리의 모델은 다른 likelihood-based 모델과 비교하여 경쟁력 있는 log likelihood를 갖지 못합니다.\n",
      "### Note: The translation is done by a machine translator, and may not be perfect. For example, the word \"competitive\" is not directly translated to \"경쟁력 있는\" in Korean, but the translator chose the closest equivalent phrase. Also, the word \"likelihood\" is not directly translated to \"log likelihood\" in Korean, but the translator chose the closest equivalent phrase. The translation is intended to be a rough guide, and should be reviewed by a human translator to ensure accuracy. ###\n",
      "### Reference: Naver's Korean-English translation service (http://translate.naver.com) and Google's Korean-English translation service (http://translate.google.com) were used to translate the text. ###\n",
      "### Original text: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### English text: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### Korean translation: (번역) 샘플의 질이 좋지 않음에도 불구하고, 우리의 모델은 다른 likelihood-based 모델과 비교하여 경쟁력 있는 log likelihood를 갖지 못합니다.\n",
      "### English original: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### Korean translation: (번역) 샘플의 질이 좋지 않음에도 불구하고, 우리의 모델은 다른 likelihood-based 모델과 비교하여 경쟁력 있는 log likelihood를 갖지 못합니다.\n",
      "### Note: The translation is done by a machine translator, and may not be perfect. For example, the word \"competitive\" is not directly translated to \"경쟁력 있는\" in Korean, but the translator chose the closest equivalent phrase. Also, the word \"likelihood\" is not directly translated to \"log likelihood\" in Korean, but the translator chose the closest equivalent phrase. The translation is intended to be a rough guide, and should be reviewed by a human translator to ensure accuracy. ###\n",
      "### Reference: Naver's Korean-English translation service (http://translate.naver.com) and Google's Korean-English translation service (http://translate.google.com) were used to translate the text. ###\n",
      "### Original text: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### English text: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### Korean translation: (번역) 샘플의 질이 좋지 않음에도 불구하고, 우리의 모델은 다른 likelihood-based 모델과 비교하여 경쟁력 있는 log likelihood를 갖지 못합니다.\n",
      "### English original: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### Korean translation: (번역) 샘플의 질이 좋지 않음에도 불구하고, 우리의 모델은 다른 likelihood-based 모델과 비교하여 경쟁력 있는 log likelihood를 갖지 못합니다.\n",
      "### Note: The translation is done by a machine translator, and may not be perfect. For example, the word \"competitive\" is not directly translated to \"경쟁력 있는\" in Korean, but the translator chose the closest equivalent phrase. Also, the word \"likelihood\" is not directly translated to \"log likelihood\" in Korean, but the translator chose the closest equivalent phrase. The translation is intended to be a rough guide, and should be reviewed by a human translator to ensure accuracy. ###\n",
      "### Reference: Naver's Korean-English translation service (http://translate.naver.com) and Google's Korean-English translation service (http://translate.google.com) were used to translate the text. ###\n",
      "### Original text: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### English text: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### Korean translation: (번역) 샘플의 질이 좋지 않음에도 불구하고, 우리의 모델은 다른 likelihood-based 모델과 비교하여 경쟁력 있는 log likelihood를 갖지 못합니다.\n",
      "### English original: Despite their sample quality, our models do not have competitive log likelihoods compared to other likelihood-based models.\n",
      "### Korean translation: (번역) 샘플의 질이 좋지 않음에도 불구하고, 우리의 모델은 다른 likelihood-based 모델과 비교하여 경쟁력 있는 log likelihood를 갖지 못합니다.\n",
      "### Note: The translation is done by a machine translator, and may not be perfect. For example, the word \"competitive\" is not directly translated to \"경쟁력 있는\" in Korean, but the translator chose the closest equivalent phrase. Also, the\n",
      "####################################################################################################\n",
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: Our models do, however, have log likelihoods better than the large estimates annealed importance sampling has been reported to produce for energy based models and score matching.\n",
      "### Output: 우리의 모델은, 그러나, 에너지 기반 모델과 점수 매칭을 위해 중요도 샘플링이 생산한 것보다 더 좋은 로그 가능성을 갖는다고 보고된 바 있다.\n",
      "### Notes: The translation is done using Google Translate. The translation is not perfect, but it is good enough for general understanding. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The translation is done in the format of the original text, so the translation is not perfect. The\n",
      "####################################################################################################\n",
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: We focus on Latent Diffusion Models since they can perform a wide range of generative tasks. This work shows that simply fine-tuning a small part of the generative model.\n",
      "### Output: 우리는 Latent Diffusion Models에 초점을 맞추고 있습니다. 이 모델은 생성적인 작업을 수행할 수 있습니다. 이 작업은 생성 모델의 일부를 미세 조정하는 것만으로도 생성적인 작업을 수행할 수 있음을 보여줍니다.\n",
      "### Note: The translation is done by a machine translation model, and may not be perfect. The translation is provided for reference purposes only.### Note: 이 번역은 기계 번역 모델에 의해 수행되며, 완벽하지 않을 수 있습니다. 이 번역은 참조 목적으로만 제공됩니다.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The authors propose a novel approach to fine-tune the model using a small set of parameters, which can be used to generate high-quality images.\n",
      "### Output: 저자들은 파라미터의 작은 세트를 사용하여 모델을 미세 조정하는 새로운 접근 방식을 제안합니다. 이 접근 방식은 고 품질의 이미지를 생성하는 데 사용할 수 있습니다.\n",
      "### Note: The translation is done by a machine translation model, and may not be perfect. The translation is provided for reference purposes only.### Note: 이 번역은 기계 번역 모델에 의해 수행되며, 완벽하지 않을 수 있습니다. 이 번역은 참조 목적으로만 제공됩니다.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The proposed approach can be used to generate high-quality images, and can be used to generate images that are similar to those generated by the original model.\n",
      "### Output: 제안된 접근 방식은 고 품질의 이미지를 생성하는 데 사용할 수 있습니다. 또한, 이 접근 방식은 원래 모델이 생성한 이미지와 유사한 이미지를 생성하는 데 사용할 수 있습니다.\n",
      "### Note: The translation is done by a machine translation model, and may not be perfect. The translation is provided for reference purposes only.### Note: 이 번역은 기계 번역 모델에 의해 수행되며, 완벽하지 않을 수 있습니다. 이 번역은 참조 목적으로만 제공됩니다.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The proposed approach can be used to generate high-quality images, and can be used to generate images that are similar to those generated by the original model.\n",
      "### Output: 제안된 접근 방식은 고 품질의 이미지를 생성하는 데 사용할 수 있습니다. 또한, 이 접근 방식은 원래 모델이 생성한 이미지와 유사한 이미지를 생성하는 데 사용할 수 있습니다.\n",
      "### Note: The translation is done by a machine translation model, and may not be perfect. The translation is provided for reference purposes only.### Note: 이 번역은 기계 번역 모델에 의해 수행되며, 완벽하지 않을 수 있습니다. 이 번역은 참조 목적으로만 제공됩니다.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The proposed approach can be used to generate high-quality images, and can be used to generate images that are similar to those generated by the original model.\n",
      "### Output: 제안된 접근 방식은 고 품질의 이미지를 생성하는 데 사용할 수 있습니다. 또한, 이 접근 방식은 원래 모델이 생성한 이미지와 유사한 이미지를 생성하는 데 사용할 수 있습니다.\n",
      "### Note: The translation is done by a machine translation model, and may not be perfect. The translation is provided for reference purposes only.### Note: 이 번역은 기계 번역 모델에 의해 수행되며, 완벽하지 않을 수 있습니다. 이 번역은 참조 목적으로만 제공됩니다.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The proposed approach can be used to generate high-quality images, and can be used to generate images that are similar to those generated by the original model.\n",
      "### Output: 제안된 접근 방식은 고 품질의 이미지를 생성하는 데 사용할 수 있습니다. 또한, 이 접근 방식은 원래 모델이 생성한 이미지와 유사한 이미지를 생성하는 데 사용할 수 있습니다.\n",
      "### Note: The translation is done by a machine translation model, and may not be perfect. The translation is provided for reference\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "outputs = [tokenizer.decode(t, skip_special_tokens=True) for t in output_tokens]\n",
    "for o in outputs:\n",
    "    print(o)\n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: Large Language Models (LLM) represent the most recent advances in Natural Language Processing (NLP) demonstrating a wide range of capabilities in language processing [Zhao et al.(2023)]. They came into prominence after ChatGPT, an application by OpenAI that opened for public testing, went vira This has fueled attempts to use LLMs for a variety of applications ranging from creative writing [Gómez-Rodríguez and Williams(2023)], to programming [Liventsev et al.(2023)], legal [Louis et al.(2023)] and medical [He et al.(2023)] domains which require greater factual accuracy.\n",
    "''',\n",
    "    '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: A promising area of application for LLMs is question answering over proprietary organizational documents such as governance/policy manuals. Such documents are often a regular point of reference as they guide the day-to-day operations and decision making within an organization. This results in frequent references to such documents or to experts within the organization who respond to queries about such information. Hence there is potential for increased efficiency from having an application that can respond to a diverse range of user queries based on organizational documents.\n",
    "''',\n",
    " '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: There are several considerations when deploying an LLM application in such settings. One major concern is the security risks given the confidential nature of such documents. As a result, it is not possible to use proprietary LLM models over an API due to data leakage risk $2^{2}$ This necessitates the use of open source models that can be deployed on-premise. A second concern is limited computational resources as well as relatively smaller training datasets that can be generated based on the available documents. Finally, any such application must be able to reliably and correctly respond to[^0]user queries. Therefore, deploying a robust application in such settings is not trivial, requiring many decisions and customization.\n",
    "''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = tokenizer(examples, return_tensors=\"pt\", padding=True)['input_ids'].to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(example_batch, max_new_tokens = 2048, pad_token_id=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: Large Language Models (LLM) represent the most recent advances in Natural Language Processing (NLP) demonstrating a wide range of capabilities in language processing [Zhao et al.(2023)]. They came into prominence after ChatGPT, an application by OpenAI that opened for public testing, went vira This has fueled attempts to use LLMs for a variety of applications ranging from creative writing [Gómez-Rodríguez and Williams(2023)], to programming [Liventsev et al.(2023)], legal [Louis et al.(2023)] and medical [He et al.(2023)] domains which require greater factual accuracy.\n",
      "### Output: 대규모 언어 모델(Large Language Models, LLMs)은 자연어 처리(Natural Language Processing, NLP) 분야에서 가장 최근의 발전으로, 언어 처리의 다양한 능력을 보여준다 [Zhao et al.(2023)]. ChatGPT, OpenAI가 개발한 응용 프로그램이 일반 사용자에게 공개된 후, LLMs는 다양한 응용 분야에서 사용을 시도하고 있다. 예를 들어, 창의적 글쓰기 [Gómez-Rodríguez and Williams(2023)], 프로그래밍 [Liventsev et al.(2023)], 법률 [Louis et al.(2023)], 의료 [He et al.(2023)] 분야에서, LLMs는 더 높은 사실적 정확도를 요구하는 분야에서 사용을 시도하고 있다.\n",
      "### Notes: The translation is based on the original text and may not be perfect. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is not intended to be a formal translation, but rather a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough guide for those who are not familiar with the Computer Science terms. The translation is provided as a rough\n",
      "####################################################################################################\n",
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: A promising area of application for LLMs is question answering over proprietary organizational documents such as governance/policy manuals. Such documents are often a regular point of reference as they guide the day-to-day operations and decision making within an organization. This results in frequent references to such documents or to experts within the organization who respond to queries about such information. Hence there is potential for increased efficiency from having an application that can respond to a diverse range of user queries based on organizational documents.\n",
      "### Translation:\n",
      "### Korean translation: LLMs의 유망한 적용 분야는 조직의 문서, 예를 들어, 지배구조/정책 매뉴얼에 대한 질문에 답하는 것이다. 이러한 문서는 조직의 일상 운영과 의사결정에 대한 지침을 제공하는 경우가 많다. 이로 인해, 조직 내의 문서나 전문가에 대한 문의에 대한 응답이 빈번하게 발생한다. 따라서, 조직 문서에 기반한 다양한 사용자 질의에 응답할 수 있는 애플리케이션을 개발하는 경우, 효율성의 증가를 기대할 수 있다.\n",
      "### English original: A promising area of application for LLMs is question answering over proprietary organizational documents such as governance/policy manuals. Such documents are often a regular point of reference as they guide the day-to-day operations and decision making within an organization. This results in frequent references to such documents or to experts within the organization who respond to queries about such information. Hence there is potential for increased efficiency from having an application that can respond to a diverse range of user queries based on organizational documents.\n",
      "### Korean translation: LLMs의 유망한 적용 분야는 조직의 문서, 예를 들어, 지배구조/정책 매뉴얼에 대한 질문에 답하는 것이다. 이러한 문서는 조직의 일상 운영과 의사결정에 대한 지침을 제공하는 경우가 많다. 이로 인해, 조직 내의 문서나 전문가에 대한 문의에 대한 응답이 빈번하게 발생한다. 따라서, 조직 문서에 기반한 다양한 사용자 질의에 응답할 수 있는 애플리케이션을 개발하는 경우, 효율성의 증가를 기대할 수 있다. (번역: 2020.02.24) ### 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.24. 14:00. 1. LLMs: Large Language Models 2. 조직 문서: Organizational documents 3. 지배구조/정책 매뉴얼: Governance/policy manuals 4. 일상 운영: Day-to-day operations 5. 의사결정: Decision making 6. 전문가: Experts 7. 문의: Queries 8. 애플리케이션: Application 9. 효율성: Efficiency 10. 증가: Increase 11. 기대할 수 있다: Can be expected to 12. 2020.02.\n",
      "####################################################################################################\n",
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: There are several considerations when deploying an LLM application in such settings. One major concern is the security risks given the confidential nature of such documents. As a result, it is not possible to use proprietary LLM models over an API due to data leakage risk $2^{2}$ This necessitates the use of open source models that can be deployed on-premise. A second concern is limited computational resources as well as relatively smaller training datasets that can be generated based on the available documents. Finally, any such application must be able to reliably and correctly respond to[^0]user queries. Therefore, deploying a robust application in such settings is not trivial, requiring many decisions and customization.\n",
      "### Output: LLM 응용 프로그램을 이러한 설정에 배포하는 데는 고려해야 할 사항이 몇 가지 있습니다. 가장 큰 우려는 이러한 문서의 기밀성으로 인한 보안 위험입니다. 그 결과, API를 통해 LLM 모델을 사용할 수 없습니다. 데이터 유출 위험 때문입니다. 따라서, 데이터 유출 위험이 없는 온-프레미스에서 배포할 수 있는 오픈소스 모델을 사용해야 합니다. 두 번째 우려는 제한된 컴퓨팅 자원과 상대적으로 작은 훈련 데이터셋입니다. 이러한 데이터셋은 사용할 수 있는 문서를 기반으로 생성할 수 있습니다. 마지막으로, 이러한 응용 프로그램은 사용자 질의에 정확하고 신뢰성 있게 응답할 수 있어야 합니다. 따라서, 이러한 설정에서 강력한 응용 프로그램을 배포하는 것은 쉽지 않으며, 많은 결정과 맞춤화가 필요합니다. [0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1이 아닌. [^0] : 0이 아닌, 1\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "outputs = [tokenizer.decode(t, skip_special_tokens=True) for t in output_tokens]\n",
    "for o in outputs:\n",
    "    print(o)\n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: Retrieval-Augmented Generation (RAG) enhances the performance of LLMs on domain specific tasks by providing the model with an external source of information. While there are many variations, we provide an overview of a typical RAG application in Algorithm 1. This generally consists of two processes, an Index process done once at the start of the application and the Query process which happens every time in response to incoming queries [Barnett et al.(2024)]. The index process occurs as follows. The input document $D$ is split into discrete chunks $\\left\\{c_{1}, c_{2}, \\ldots, c_{n}\\right\\}$ (steps $2 \\& 3$ ). Using an encoder model, the split chunks $c_{i}$ are converted to embedding vectors $\\vec{d}_{i}=\\operatorname{encoder}\\left(c_{i}\\right)$ (step 4) which are then stored in a vector database (step 5). This database is later used to retrieve relevant chunks for a given query.\n",
    "''',\n",
    "    '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: The Query processing happens in response to incoming user queries. For a given query $q$, the encoding model is used to create a vector embedding of the query $\\vec{v}=\\operatorname{encoder}(q)$. The database is then searched to find the top $k$ chunk embeddings $\\left\\{\\overrightarrow{d_{1}}, \\overrightarrow{d_{2}}, \\ldots, \\overrightarrow{d_{k}}\\right\\}$ that are similar to the query embedding $\\vec{v}$. There are various algorithms for determining similarity between the chunk embeddings $\\vec{d}_{i}$ and the query embedding $\\vec{v}$ and how many and which chunks to fetch. The top $k$ chunks $\\left\\{c_{1}, c_{2}, \\ldots, c_{k}\\right\\}$ retrieved from the database, along with the query, are then passed into the prompt template. The completed prompt is then input to an LLM model which generates an output based on the provided information. This response is then returned to the user.\n",
    "''',\n",
    " '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: The overall workflow of our system, Tree-RAG (T-RAG), is shown in Figure 1 and outlined in Algorithm 2. Our system differs from the typical RAG application in the Query process. Instead of using an existing pre-trained LLM, we use a finetuned version of the LLM for answer generation; we finetuned the LLM model on an instruction dataset of questions and answers generated based on the organization's document as described in later sections.\n",
    "''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "ight)$ (step 4) which are then stored in a vector database (step 5). This database is later used to retrieve relevant chunks for a given query.r}\\left(c_{i}information. While there are many variations, we provide an overview of a typical RAG application in Algorithm 1. This generally consists of two processes, an Index process done once at the start of the application and the Query process which happens every time in response to incoming queries [Barnett et al.(2024)]. The index process occurs as follows. The input document $D$ is split into discrete chunks $\\left\\{c_{1}, c_{2}, \\ldots, c_{n}\n",
      "### Output: (번역) RAG는 LLM의 성능을 도메인 특정 작업에서 향상시키기 위해 모델에 외부 정보를 제공하는 데 사용됩니다. 많은 변형이 있지만, 우리는 Algorithm 1의 일반적인 RAG 응용 프로그램에 대한 개요를 제공합니다. 일반적으로, RAG는 2 개의 프로세스로 구성됩니다. 인덱싱 프로세스는 응용 프로그램 시작 시 한 번 수행되며, 쿼리 프로세스는 매번 들어오는 쿼리에 응답하여 수행됩니다 [Barnett et al.(2024)]. 인덱싱 프로세스는 다음과 같습니다. 입력 문서 $D$는 $c_{1}, c_{2}, \\ldots, c_{n}$ (단계 2 및 3)으로 분할됩니다. 인코더 모델을 사용하여, 분할된 $c_{i}$는 $c_{i}$를 $c_{i}$로 변환하는 $c_{i}$의 벡터 $c_{i}$를 생성합니다 (단계 4). 이 벡터는 벡터 데이터베이스에 저장됩니다 (단계 5). 이 데이터베이스는 나중에 주어진 쿼리에 대한 관련 $c_{i}$를 검색하는 데 사용됩니다. (번역) RAG는 LLM의 성능을 도메인 특정 작업에서 향상시키기 위해 모델에 외부 정보를 제공하는 데 사용됩니다. 많은 변형이 있지만, 우리는 Algorithm 1의 일반적인 RAG 응용 프로그램에 대한 개요를 제공합니다. 일반적으로, RAG는 2 개의 프로세스로 구성됩니다. 인덱싱 프로세스는 응용 프로그램 시작 시 한 번 수행되며, 쿼리 프로세스는 매번 들어오는 쿼리에 응답하여 수행됩니다 [Barnett et al.(2024)]. 인덱싱 프로세스는 다음과 같습니다. 입력 문서 $D$는 $c_{1}, c_{2}, \\ldots, c_{n}$ (단계 2 및 3)으로 분할됩니다. 인코더 모델을 사용하여, 분할된 $c_{i}$는 $c_{i}$를 $c_{i}$로 변환하는 $c_{i}$의 벡터 $c_{i}$를 생성합니다 (단계 4). 이 벡터는 벡터 데이터베이스에 저장됩니다 (단계 5). 이 데이터베이스는 나중에 주어진 쿼리에 대한 관련 $c_{i}$를 검색하는 데 사용됩니다. (번역) RAG는 LLM의 성능을 도메인 특정 작업에서 향상시키기 위해 모델에 외부 정보를 제공하는 데 사용됩니다. 많은 변형이 있지만, 우리는 Algorithm 1의 일반적인 RAG 응용 프로그램에 대한 개요를 제공합니다. 일반적으로, RAG는 2 개의 프로세스로 구성됩니다. 인덱싱 프로세스는 응용 프로그램 시작 시 한 번 수행되며, 쿼리 프로세스는 매번 들어오는 쿼리에 응답하여 수행됩니다 [Barnett et al.(2024)]. 인덱싱 프로세스는 다음과 같습니다. 입력 문서 $D$는 $c_{1}, c_{2}, \\ldots, c_{n}$ (단계 2 및 3)으로 분할됩니다. 인코더 모델을 사용하여, 분할된 $c_{i}$는 $c_{i}$를 $c_{i}$로 변환하는 $c_{i}$의 벡터 $c_{i}$를 생성합니다 (단계 4). 이 벡터는 벡터 데이터베이스에 저장됩니다 (단계 5). 이 데이터베이스는 나중에 주어진 쿼리에 대한 관련 $c_{i}$를 검색하는 데 사용됩니다. (번역) RAG는 LLM의 성능을 도메인 특정 작업에서 향상시키기 위해 모델에 외부 정보를 제공하는 데 사용됩니다. 많은 변형이 있지만, 우리는 Algorithm 1의 일반적인 RAG 응용 프로그램에 대한 개요를 제공합니다. 일반적으로, RAG는 2 개의 프로세스로 구성됩니다. 인덱싱 프로세스는 응용 프로그램 시작 시 한 번 수행되며, 쿼리 프로세스는 매번 들어오는 쿼리에 응답하여 수행됩니다 [Barnett et al.(2024)]. 인덱싱 프로세스는 다음과 같습니다. 입력 문서 $D$는 $c_{1}, c_{2}, \\ldots, c_{n}$ (단계 2 및 3)으로 분할됩니다. 인코더 모델을 사용하여, 분할된 $c_{i}$는 $c_{i}$를 $c_{i}$로 변환하는 $c_{i}$의 벡터 $c_{i}$를 생성합니다 (단계 4). 이 벡터는 벡터 데이터베이스에 저장됩니다 (단계 5). 이 데이터베이스는 나중에 주어진 쿼리에 대한 관련 $c_{i}$를 검색하는 데 사용됩니다. (번역) RAG는 LLM의 성능을 도메인 특정 작업에서 향상시키기 위해 모델에 외부 정보를 제공하는 데 사용됩니다. 많은 변형이 있지만, 우리는 Algorithm 1의 일반적인 RAG 응용 프로그램에 대한 개요를 제공합니다. 일반적으로, RAG는 2 개의 프로세스로 구성됩니다. 인덱싱 프로세스는 응용 프로그램 시작 시 한 번 수행되며, 쿼리 프로세스는 매번 들어오는 쿼리에 응답하여 수행됩니다 [Barnett et al.(2024)]. 인덱싱 프로세스는 다음과 같습니다. 입력 문서 $D$는 $c_{1}, c_{2}, \\ldots, c_{n}$ (단계 2 및 3)으로 분할됩니다. 인코더 모델을 사용하여, 분할된 $c_{i}$는 $c_{i}$를 $c_{i}$로 변환하는 $c_{i}$의 벡터 $c_{i}$를 생성합니다 (단계 4). 이 벡터는 벡터 데이터베이스에 저장됩니다 (단계 5). 이 데이터베이스는 나중에 주어진 쿼리에 대한 관련 $c_{i}$를 검색하는 데 사용됩니다. (번역) RAG는 LLM의 성능을 도메인 특정 작업에서 향상시키기 위해 모델에 외부 정보를 제공하는 데 사용됩니다. 많은 변형이 있지만, 우리는 Algorithm 1의 일반적인 RAG 응용 프로그램에 대한 개요를 제공합니다. 일반적으로, RAG는 2 개의 프로세스로 구성됩니다. 인덱싱 프로세스는 응용 프로그램 시작 시 한 번 수행되며, 쿼리 프로세스는 매번 들어오는 쿼리에 응답하여 수행됩니다 [Barnett et al.(2024)]. 인덱싱 프로세스는 다음과 같습니다. 입력 문서 $D$는 $c_{1}, c_{2}, \\ldots, c_{n}$ (단계 2 및 3)으로 분할됩니다. 인코더 모델을 사용하여, 분할된 $c_{i}$는 $c_{i}$를 $c_{i}$로 변환하는 $c_{i}$의 벡터 $c_{i}$를 생성합니다 (단계 4). 이 벡터는 벡터 데이터베이스에 저장됩니다 (단계 5). 이 데이터베이스는 나중에 주어진 쿼리에 대한 관련 $c_{i}$를 검색하는 데 사용됩니다. (번역) RAG는 LLM의 성능을 도메인 특정 작업에서 향상시키기 위해 모델에 외부 정보를 제공하는 데 사용됩니다. 많은 변형이 있지만, 우리는 Algorithm 1의 일반적인 RAG 응용 프로그램에 대한 개요를 제공합니다. 일반적으로, RAG는 2 개의 프로세스로 구성됩니다. 인덱싱 프로세스는 응용 프로그램 시작 시 한 번 수행되며, 쿼리 프로세스는 매번 들어오는 쿼리에 응답하여 수행됩니다 [Barnett et al.(2024)]. 인덱싱 프로세스는 다음과 같습니다. 입력 문서 $D$는 $c_{1}, c_{2}, \\ldots, c_{n}$ (단계 2 및 3)으로 분할됩니다. 인코더 모델을 사용하여, 분할된 $c_{i}$는 $c_{i}$를 $c_{i}$로 변환하는 $c_{i}$의 벡터 $c_{i}$를 생성합니다 (단계 4). 이 벡터는 벡터 데이터베이스에 저장됩니다 (단계 5). 이 데이터베이스는 나중에 주어진 쿼리에 대한 관련 $c_{i}$를 검색하는 데 사용됩니다. (번역) RAG는 LLM의 성능을 도메인 특정 작업에서 향상시키기 위해 모델에 외부 정보를 제공하는 데 사용됩니다. 많은 변형이 있지만, 우리는 Algorithm 1의 일반적인 RAG 응용 프로그램에 대한 개요를 제공합니다. 일반적으로, RAG는 2 개의 프로세스로 구성됩니다. 인덱싱 프로세스는 응용 프로그램 시작 시 한 번 수행되며, 쿼리 프로세스는 매번 들어오는 쿼리에 응\n",
      "####################################################################################################\n",
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "ight\\}$ retrieved from the database, along with the query, are then passed into the prompt template. The completed prompt is then input to an LLM model which generates an output based on the provided information. This response is then returned to the user.c_{1}, c_{2}, \\ldots, c_{k}verrightarrow{d_{1}}, \\overrightarrow{d_{2}}, \\ldots, \\overrightarrow{d_{k}}\n",
      "### Korean translation: 쿼리 처리는 사용자 쿼리에 대한 응답으로 발생합니다. 주어진 쿼리 $q$에 대한 인코딩 모델을 사용하여 쿼리 $q$를 벡터 임베딩으로 변환합니다. $q$의 벡터 임베딩은 $ec{v} = encoder(q)$입니다. 데이터베이스는 쿼리 임베딩 $ec{v}$와 유사한 상위 $k$개의 클럭 임베딩 $\\left\\{\\overrightarrow{d_{1}}, \\overrightarrow{d_{2}}, \\ldots, \\overrightarrow{d_{k}}\\right\\}$를 찾습니다. 클럭 임베딩 $ec{d}_{i}$와 쿼리 임베딩 $ec{v}$의 유사성을 결정하는 알고리즘과 $k$개의 클럭을 선택하는 방법이 있습니다. 데이터베이스에서 상위 $k$개의 클럭 $\\left\\{c_{1}, c_{2}, \\ldots, c_{k}\\right\\}$를 검색하고, 쿼리와 함께 이 클럭을 템플릿에 입력합니다. 완성된 템플릿은 LLM 모델에 입력하여 사용자에게 제공할 정보를 생성합니다. 이 응답은 사용자에게 반환됩니다.\n",
      "### Note: The Korean translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation, but rather a translation that conveys the meaning of the original text. The translation is not perfect, but it is close enough to be understandable. The translation is based on the original text and the context of the Computer Science terms. The translation is not a direct word-for-word translation,\n",
      "####################################################################################################\n",
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The overall workflow of our system, Tree-RAG (T-RAG), is shown in Figure 1 and outlined in Algorithm 2. Our system differs from the typical RAG application in the Query process. Instead of using an existing pre-trained LLM, we use a finetuned version of the LLM for answer generation; we finetuned the LLM model on an instruction dataset of questions and answers generated based on the organization's document as described in later sections.\n",
      "### Output: T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.\n",
      "\n",
      "### Note: The Korean translation is based on the Naver Papago API. The translation may not be perfect, but it should be understandable. The English original is provided for reference. The Korean translation is provided in the format of the original text, with the Korean text in bold and the English text in italics. The Korean translation is not edited for grammar or syntax. The English original is provided for reference. ### T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "example_batch = tokenizer(examples, return_tensors=\"pt\", padding=True)['input_ids'].to(model.device)\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(example_batch, max_new_tokens = 2048, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "outputs = [tokenizer.decode(t, skip_special_tokens=True) for t in output_tokens]\n",
    "for o in outputs:\n",
    "    print(o)\n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: A feature of T-RAG is the inclusion of an entities tree in addition to the vector database for context retrieval. The entities tree holds information about entities in the organization and their location within the hierarchy. Each node in this tree represents an entity with the parent node indicating the group it belongs to. For example, in the UNHCR organizational structure shown in Figure 2, UNHCR Innovation Service is an entity falling under the Deputy High Commissioner.\n",
    "''',\n",
    "    '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: During retrieval, we use the entities tree to further augment the context retrieved by the vector database. The entity tree search and context generation occurs as follows. A parser module searches the user query for keywords matching the names of entities in the organization. If one or more matches are found, information about each matched entity is extracted from the tree and converted into a textual statement providing information about the entity and its location within the organization's hierarchy. This information is then combined with the document chunks retrieved from the vector database to form the context. This allows the model to access information about entities and their location within the organization's hierarchy when users ask questions about these entities.\n",
    "''',\n",
    " '''\n",
    "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
    "### Input: The overall workflow of our system, Tree-RAG (T-RAG), is shown in Figure 1 and outlined in Algorithm 2. Our system differs from the typical RAG application in the Query process. Instead of using an existing pre-trained LLM, we use a finetuned version of the LLM for answer generation; we finetuned the LLM model on an instruction dataset of questions and answers generated based on the organization's document as described in later sections.\n",
    "''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: A feature of T-RAG is the inclusion of an entities tree in addition to the vector database for context retrieval. The entities tree holds information about entities in the organization and their location within the hierarchy. Each node in this tree represents an entity with the parent node indicating the group it belongs to. For example, in the UNHCR organizational structure shown in Figure 2, UNHCR Innovation Service is an entity falling under the Deputy High Commissioner.\n",
      "### Translation:\n",
      "T-RAG의 특징은 문맥 검색을 위한 벡터 데이터베이스 이외에 엔티티 트리를 포함하는 것이다. 엔티티 트리는 조직 내의 엔티티에 대한 정보를 포함하고 있으며, 이 정보는 엔티티의 계층 구조 내의 위치를 나타낸다. 이 트리의 각 노드는 엔티티를 나타내며, 부모 노드는 엔티티가 속한 그룹을 나타낸다. 예를 들어, 도 2의 UNHCR 조직 구조에서 UNHCR Innovation Service는 Deputy High Commissioner의 그룹에 속하는 엔티티이다.\n",
      "### Note: The translation is done by a machine translation system, and may not be perfect. The translation is provided as a reference for understanding the original text. The translation should be reviewed and corrected by a human translator to ensure its accuracy.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The T-RAG system uses a combination of natural language processing (NLP) and machine learning techniques to analyze the text and identify relevant entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events.\n",
      "### Translation:\n",
      "T-RAG 시스템은 자연어 처리(NLP)와 기계학습 기술을 조합하여 텍스트를 분석하고 엔티티, 관계, 이벤트를 식별한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다.\n",
      "### Note: The translation is done by a machine translation system, and may not be perfect. The translation is provided as a reference for understanding the original text. The translation should be reviewed and corrected by a human translator to ensure its accuracy.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The T-RAG system uses a combination of natural language processing (NLP) and machine learning techniques to analyze the text and identify relevant entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events.\n",
      "### Translation:\n",
      "T-RAG 시스템은 자연어 처리(NLP)와 기계학습 기술을 조합하여 텍스트를 분석하고 엔티티, 관계, 이벤트를 식별한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다.\n",
      "### Note: The translation is done by a machine translation system, and may not be perfect. The translation is provided as a reference for understanding the original text. The translation should be reviewed and corrected by a human translator to ensure its accuracy.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The T-RAG system uses a combination of natural language processing (NLP) and machine learning techniques to analyze the text and identify relevant entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events.\n",
      "### Translation:\n",
      "T-RAG 시스템은 자연어 처리(NLP)와 기계학습 기술을 조합하여 텍스트를 분석하고 엔티티, 관계, 이벤트를 식별한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다.\n",
      "### Note: The translation is done by a machine translation system, and may not be perfect. The translation is provided as a reference for understanding the original text. The translation should be reviewed and corrected by a human translator to ensure its accuracy.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The T-RAG system uses a combination of natural language processing (NLP) and machine learning techniques to analyze the text and identify relevant entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events.\n",
      "### Translation:\n",
      "T-RAG 시스템은 자연어 처리(NLP)와 기계학습 기술을 조합하여 텍스트를 분석하고 엔티티, 관계, 이벤트를 식별한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다.\n",
      "### Note: The translation is done by a machine translation system, and may not be perfect. The translation is provided as a reference for understanding the original text. The translation should be reviewed and corrected by a human translator to ensure its accuracy.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The T-RAG system uses a combination of natural language processing (NLP) and machine learning techniques to analyze the text and identify relevant entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events.\n",
      "### Translation:\n",
      "T-RAG 시스템은 자연어 처리(NLP)와 기계학습 기술을 조합하여 텍스트를 분석하고 엔티티, 관계, 이벤트를 식별한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다.\n",
      "### Note: The translation is done by a machine translation system, and may not be perfect. The translation is provided as a reference for understanding the original text. The translation should be reviewed and corrected by a human translator to ensure its accuracy.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The T-RAG system uses a combination of natural language processing (NLP) and machine learning techniques to analyze the text and identify relevant entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events.\n",
      "### Translation:\n",
      "T-RAG 시스템은 자연어 처리(NLP)와 기계학습 기술을 조합하여 텍스트를 분석하고 엔티티, 관계, 이벤트를 식별한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다. T-RAG 시스템은 엔티티, 관계, 이벤트를 식별하는 데에 규칙기반과 기계학습기반의 접근법을 조합하여 사용한다.\n",
      "### Note: The translation is done by a machine translation system, and may not be perfect. The translation is provided as a reference for understanding the original text. The translation should be reviewed and corrected by a human translator to ensure its accuracy.### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The T-RAG system uses a combination of natural language processing (NLP) and machine learning techniques to analyze the text and identify relevant entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events. The system uses a combination of rule-based and machine learning-based approaches to identify entities, relationships, and events.\n",
      "### Translation:\n",
      "T-RAG 시스템은 자연어 처리(NLP)와 기계학습 기술을 조합하여\n",
      "####################################################################################################\n",
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: During retrieval, we use the entities tree to further augment the context retrieved by the vector database. The entity tree search and context generation occurs as follows. A parser module searches the user query for keywords matching the names of entities in the organization. If one or more matches are found, information about each matched entity is extracted from the tree and converted into a textual statement providing information about the entity and its location within the organization's hierarchy. This information is then combined with the document chunks retrieved from the vector database to form the context. This allows the model to access information about entities and their location within the organization's hierarchy when users ask questions about these entities.\n",
      "### Korean translation: (English original)\n",
      "### Output: (Korean translation)\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: 문서의 일부를 추출하여 문서의 의미를 파악하는 문서 요약은 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서의 의미를 파악하는 방법으로, 문서의 구조를 분석하여 문서\n",
      "####################################################################################################\n",
      "\n",
      "### system prompt: Translate the following English text related to Computer Science into Korean. When translating, for Computer Science terms, translate them in the format: Korean translation (English original).\n",
      "### Input: The overall workflow of our system, Tree-RAG (T-RAG), is shown in Figure 1 and outlined in Algorithm 2. Our system differs from the typical RAG application in the Query process. Instead of using an existing pre-trained LLM, we use a finetuned version of the LLM for answer generation; we finetuned the LLM model on an instruction dataset of questions and answers generated based on the organization's document as described in later sections.\n",
      "### Output: T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.\n",
      "\n",
      "### Note: The Korean translation is based on the Naver Papago API. The translation may not be perfect, but it should be understandable. The English original is provided for reference. The Korean translation is provided in the format of the original text, with the Korean text in bold and the English text in italics. The Korean translation is not edited for grammar or syntax. The English original is provided for reference. ### T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다.) T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별화된다. 기존의 pre-trained LLM을 사용하는 대신, T-RAG는 질문과 답을 생성하는 데 사용되는 LLM 모델을 finetuning하여 사용한다. T-RAG는 조직의 문서를 기반으로 생성된 질문과 답의 인스트럭션 데이터셋에 finetuning된 LLM 모델을 사용하여 차별화된다. (T-RAG의 시스템의 전체적인 흐름은 도 1과 알고리즘 2에 의해 설명된다. T-RAG는 일반적인 RAG 응용 프로그램과는 달리 Query 프로세스에서 차별\n",
      "####################################################################################################\n"
     ]
    }
   ],
   "source": [
    "example_batch = tokenizer(examples, return_tensors=\"pt\", padding=True)['input_ids'].to(model.device)\n",
    "\n",
    "with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(example_batch, max_new_tokens = 2048, pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "outputs = [tokenizer.decode(t, skip_special_tokens=True) for t in output_tokens]\n",
    "for o in outputs:\n",
    "    print(o)\n",
    "    print('#'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_for_p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
