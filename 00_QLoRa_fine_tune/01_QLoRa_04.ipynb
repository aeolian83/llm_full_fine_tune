{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/blog/finetune-llms/\n",
    "\n",
    "https://colab.research.google.com/drive/1vIjBtePIZwUaHWfjfNHzBjwuXOyU_ugD?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Environment & Huggingface, W&B login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maeolian83\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"]=\"QLoRA_Instruction_finetune_03\"\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/aeolian83/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "login(token= os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset Load\n",
    "\n",
    "- 이 시스템에서는 작업을 외장하드에서 하고 있기 때문에 캐쉬폴더를 별도로 지정(In this system, tasks are being performed on an external hard drive, so a separate cache folder is specified.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_instruction_01 = load_dataset(\"nlpai-lab/kullm-v2\", cache_dir=\"/mnt/t7/.cache/huggingface/datasets\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'instruction', 'input', 'output'],\n",
       "    num_rows: 152630\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_instruction_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'alpaca_{idx}',\n",
       " 'instruction': '다음 문장을 3인칭으로 다시 작성합니다.',\n",
       " 'input': '나는 불안하다',\n",
       " 'output': '불안해합니다.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_instruction_01[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_instruction_01 = ko_instruction_01.shuffle(seed=2160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ko_instruction_01 = ko_instruction_01['train'].train_test_split(test_size=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Load\n",
    "\n",
    "- QLoRA로 finetune을 하기위해 일반 7B 모델을 BitsAndBytes를 통해 양자화(4bit quantization)하여 로드, 훈련속도 향상을 위해 데이터 타입을 fp32가 아니라 fp16으로 로드(차후에는 bf16으로 로드해서 훈련예정)\n",
    "- To finetune with QLoRA, a standard 7B model is quantized (4-bit quantization) through BitsAndBytes for loading, and to improve training speed, the data type is loaded as fp16 instead of fp32 (with plans to load and train with bf16 in the future).\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "quantization_config=BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        llm_int8_threshold=6.0,\n",
    "        llm_int8_has_fp16_weight=False,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "    ),\n",
    "```\n",
    "\n",
    "### *Reference\n",
    "\n",
    "- https://github.com/huggingface/peft/blob/main/examples/fp4_finetuning/finetune_fp4_opt_bnb_peft.py\n",
    "- https://colab.research.google.com/drive/19AFEOrCI6-bc7h9RTso_NndRwXJRaJ25?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig, PeftModel, get_peft_model\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./checkpoint/experi_04\"\n",
    "model_id = \"beomi/llama-2-ko-7b\"\n",
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4bit QLoRA 학습을 위한 설정\n",
    "bnb_4bit_compute_dtype = \"bfloat16\" # 코랩 무료버전에서 실행 시 \"float16\"를 사용하세요\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "use_4bit = True\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de776a436a740f39af9584f839386fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=device_map, cache_dir=\"/mnt/t7/.cache/huggingface/models\")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) PEFT훈련을 위한 CONFIG설정, 이 부분은 Trainable Parameter를 확인하지 않아도 QLoRA를 위해서는 무조건 해야 한다.(\"For PEFT training configuration, this step must be done unconditionally for QLoRA, even without checking for Trainable Parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    inference_mode=False,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=\"/mnt/t7/.cache/huggingface/models\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# # 학습 진행 중 loss가 치솟다가 0.0으로 떨어지는 문제 해결을 위해 사용\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Prompt 설정(Prompt configuration)\n",
    "\n",
    "- Prompt는 아래와 같음(The prompt is as follows.)\n",
    "> \\#\\#\\# System: content  \n",
    "> \\#\\#\\# Human: content  \n",
    "> \\#\\#\\# Assistant: content  \n",
    "\n",
    "- Prompt에 맞춰서 Dataset을 재가공(Reprocessing the Dataset according to the Prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(sample):\n",
    "    system_prompt = f\"### instruction: {sample['instruction']}\"\n",
    "    input = f\"### input: {sample['input']}\" if len(sample[\"input\"]) > 0 else None\n",
    "    output = f\"### output: {sample['output']}\"\n",
    "    # join all the parts together\n",
    "    prompt = \"\\n\\n\".join([i for i in [system_prompt, input, output] if i is not None])\n",
    "    return prompt\n",
    "\n",
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_instruction(sample)}{tokenizer.eos_token}\"\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ko_instruction_01.map(template_dataset, remove_columns=list(ko_instruction_01.features), num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 152630\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### instruction: 인공 신경망의 두 가지 주요 구성 요소는 무엇인가요?\\n\\n### output: 인공 신경망의 두 가지 주요 구성 요소는 뉴런(또는 노드)과 뉴런 간의 상호 연결(또는 시냅스)입니다. 뉴런은 계층으로 구성되어 있으며, 입력 계층은 데이터를 받아들이고, 출력 계층은 결과를 생성하며, 그 사이에 숨겨진 계층은 연산을 수행합니다. 뉴런 간의 상호 연결을 통해 정보의 흐름이 이루어지며, 학습 과정에서 뉴런의 강점 또는 가중치가 조정되어 네트워크의 성능이 향상됩니다.</s>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"text\"][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### instruction: 이 코드 스니펫을 Keras 대신 PyTorch로 다시 생성할 수 있나요?\\n\\n### output: 물론 다음은 파이토치에서 구현된 신경망을 사용하여 지도 학습 접근법을 사용하여 이진 행렬을 완성하는 방법의 예입니다:'''pythonimport numpy as npsklearn.model_selection에서 train_test_split을 가져옵니다.sklearn.metrics에서 정확도_점수 가져오기토치 가져오기torch.nn을 nn으로 가져옵니다.torch.optim을 optim으로 가져옵니다.# 신경망을 사용하여 누락된 값을 대입하는 함수를 만듭니다.def complete_matrix(matrix):    # 행렬을 관측값과 결측값으로 분할합니다.    observed_values = matrix[matrix != 0]    missing_mask = matrix == 0    missing_values = matrix[missing_mask]    # 데이터를 훈련 및 테스트 집합으로 분할    X_train, X_test, y_train, y_test = train_test_split(observed_values, missing_values, test_size=0.2)    # 신경망 정의 및 훈련    model = nn.Sequential(        nn.Linear(1, 32),        nn.ReLU(),        nn.Linear(32, 1),        nn.Sigmoid()    )    criterion = nn.BCELoss()    optimizer = optim.Adam(model.parameters())    X_train = torch.from_numpy(X_train).float()    y_train = torch.from_numpy(y_train).float()    X_test = torch.from_numpy(X_test).float()    for epoch in range(100):        optimizer.zero_grad()        y_pred = model(X_train)        loss = criterion(y_pred.squeeze(), y_train)        loss.backward()        optimizer.step()    # 신경망을 사용하여 결측값을 추정합니다.    imputed_values = model(torch.from_numpy(missing_values).float())    imputed_values = imputed_values.detach().numpy()    # 가장 가까운 정수로 추정된 값을 반올림합니다.    imputed_values = np.round(imputed_values)    # 원래 행렬에 대입된 값을 삽입합니다.    matrix[missing_mask] = imputed_values    # 테스트 세트에서 모델 평가    y_test = torch.from_numpy(y_test).float()    y_test_pred = model(X_test)    test_accuracy = accuracy_score(y_test.numpy(), np.round(y_test_pred.detach().numpy()))    print(f'테스트 정확도: {test_accuracy:.2f}')    행렬 반환matrix = np.array([    [0, 0, 0, 0, -1, -1, -1, 1, 0, 0],    [0, 1, 0, 0, 1, 0, 1, 0, 1, 0],    [-1, -1, 1, 1, 0, -1, -1, 0, 0, 0],    [0, 0, -1, 0, 0, 0, 0, 0, 0, 0],    [0, 0, 0, 0, 1, 0, 0, -1, 1, 0],    [0, 0, 1, 0```</s>\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"text\"][3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### instruction: 30분 이내에 준비할 수 있는 식사를 제안하세요.\\n\\n### output: 30분 이내에 준비할 수 있는 한 끼 식사는 닭고기 볶음입니다. 간단한 레시피를 소개합니다:\\n\\n재료\\n- 얇게 썬 뼈 없는 껍질 없는 닭 가슴살 1파운드\\n- 식물성 기름 2큰술\\n- 다진 마늘 2쪽\\n- 다진 생강 1큰술\\n- 얇게 썬 붉은 피망 1개\\n- 브로콜리 꽃 1 컵\\n- 슈가 스냅 완두콩 1 컵\\n- 얇게 썬 당근 1컵\\n- 간장 1/4 컵\\n- 닭 육수 1/4 컵\\n- 옥수수 전분 1 큰술\\n- 꿀 2작은술\\n- 소금과 후추, 맛보기\\n\\n만드는 방법\\n1. 큰 팬에 기름을 두르고 중간보다 센 불에 올립니다. 마늘과 생강을 넣고 30초간 조리합니다.\\n2. 닭고기 스트립을 넣고 갈색이 나고 완전히 익을 때까지 약 5분간 조리합니다. 팬에서 닭고기를 꺼내 따로 보관합니다.\\n3. 3. 같은 팬에 붉은 피망, 브로콜리, 슈가 스냅 완두콩, 얇게 썬 당근을 추가합니다. 야채가 부드러워질 때까지 6~10분간 저어가며 조리합니다.\\n4. 작은 볼에 간장, 닭 육수, 옥수수 전분, 꿀을 넣고 휘젓습니다. 익힌 야채 위에 소스를 붓고 소스가 걸쭉해질 때까지 약 2분간 저어줍니다.\\n5. 익힌 닭고기를 팬에 다시 넣고 모든 것이 소스에 잘 코팅 될 때까지 저어줍니다. 추가로 2-3 분 더 조리합니다.\\n6. 소금과 후추로 간을하여 맛을 낸다. 밥이나 국수와 함께 제공합니다.\\n\\n그게 다입니다! 30분 이내에 준비할 수 있는 건강하고 맛있는 식사입니다. 맛있게 드세요!</s>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"text\"][3230]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"### instruction: 직원의 이름과 급여를 저장할 수 있는 데이터 구조의 예를 만듭니다.\\n\\n### output: 직원의 이름과 급여를 저장할 수 있는 데이터 구조의 한 예로, 키는 직원의 이름이고 값은 급여인 사전을 들 수 있습니다.\\n\\n```\\nemployee_salaries = {\\n    'John Doe': 50000,\\n    'Jane Smith': 60000,\\n    'Bob Johnson': 55000,\\n    'Emily Davis': 65000\\n}\\n```\\n\\n이 예제에서 `employee_salaries` 사전은 직원 4명의 이름과 급여를 저장합니다. 키는 직원의 이름(예: 'John Doe')이고 값은 급여(예: 50000)입니다. 따라서 이름을 참조하기만 하면 모든 직원의 급여 정보에 쉽게 액세스할 수 있습니다.</s>\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[\"text\"][12312]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = ko_instruction_01['test'].map(template_dataset, remove_columns=list(ko_instruction_01['test'].features), num_proc=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Configure Train arguments & Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aeolian83/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:245: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/aeolian83/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=checkpoint_dir,\n",
    "    save_steps=200,\n",
    "    save_total_limit=3, # 가장 최근 체크포인트 3개만 저장합니다.\n",
    "    logging_steps=30,\n",
    "    report_to=\"wandb\",\n",
    "    learning_rate=1e-5,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=2, # epochs 대신 max_steps을 기준으로 할 수 있습니다.\n",
    "    warmup_ratio=0.02,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\", # paged_adamw_8bit 사용시 메모리를 더 절약할 수 있지만 loss가 0으로 떨어지는 문제가 있습니다.\n",
    "    group_by_length=True,\n",
    "    fp16 = False, # 코랩 무료버전에서 실행 시 \"True\"를 사용하세요\n",
    "    bf16 = True, # 코랩 무료버전에서 실행 시 \"False\"를 사용하세요\n",
    "    lr_scheduler_type=\"constant\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     train_dataset=train_dataset,\n",
    "#     peft_config=peft_config,\n",
    "#     dataset_text_field=\"text\",\n",
    "#     max_seq_length=1024,\n",
    "#     tokenizer=tokenizer,\n",
    "#     args=training_arguments,\n",
    "#     packing=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/t7/dnn/llm_practicing/00_QLoRa_fine_tune/wandb/run-20240424_221741-tptqd8yz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aeolian83/QLoRA_Instruction_finetune_03/runs/tptqd8yz' target=\"_blank\">helpful-wave-5</a></strong> to <a href='https://wandb.ai/aeolian83/QLoRA_Instruction_finetune_03' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aeolian83/QLoRA_Instruction_finetune_03' target=\"_blank\">https://wandb.ai/aeolian83/QLoRA_Instruction_finetune_03</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aeolian83/QLoRA_Instruction_finetune_03/runs/tptqd8yz' target=\"_blank\">https://wandb.ai/aeolian83/QLoRA_Instruction_finetune_03/runs/tptqd8yz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3402e1870fa45d99f435ab23917ee73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/305260 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.467, 'grad_norm': 0.1328125, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 3.2204, 'grad_norm': 0.11279296875, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.6088, 'grad_norm': 0.2470703125, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.9207, 'grad_norm': 0.16015625, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 3.2477, 'grad_norm': 2.34375, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.6076, 'grad_norm': 0.341796875, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 3.2067, 'grad_norm': 0.1748046875, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.6031, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.8153, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.7713, 'grad_norm': 1.6796875, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.2137, 'grad_norm': 0.3359375, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.7726, 'grad_norm': 0.2734375, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.3876, 'grad_norm': 0.87890625, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.5368, 'grad_norm': 0.33984375, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.4081, 'grad_norm': 2.703125, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.05, 'grad_norm': 0.384765625, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.1103, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.2427, 'grad_norm': 0.88671875, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.0087, 'grad_norm': 0.81640625, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.1964, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.0059, 'grad_norm': 0.9765625, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.0732, 'grad_norm': 0.2109375, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 1.994, 'grad_norm': 0.91796875, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 1.9839, 'grad_norm': 0.25, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 2.0685, 'grad_norm': 2.625, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 1.938, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9289, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.018, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9959, 'grad_norm': 1.3515625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.146, 'grad_norm': 4.53125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0522, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2294, 'grad_norm': 0.8671875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9113, 'grad_norm': 3.421875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1401, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0454, 'grad_norm': 4.96875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8458, 'grad_norm': 0.388671875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0878, 'grad_norm': 0.39453125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0141, 'grad_norm': 2.078125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9708, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.163, 'grad_norm': 1.46875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8906, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9089, 'grad_norm': 0.205078125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8949, 'grad_norm': 2.578125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8456, 'grad_norm': 0.345703125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2636, 'grad_norm': 6.8125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0269, 'grad_norm': 0.365234375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9597, 'grad_norm': 0.345703125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9025, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0895, 'grad_norm': 0.349609375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0774, 'grad_norm': 3.296875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9465, 'grad_norm': 2.015625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.975, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8906, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0286, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0255, 'grad_norm': 1.3828125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0493, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9035, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0408, 'grad_norm': 0.921875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0145, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1099, 'grad_norm': 9.6875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8608, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9504, 'grad_norm': 0.2041015625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.1609, 'grad_norm': 1.1484375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9497, 'grad_norm': 0.37109375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8654, 'grad_norm': 9.75, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9414, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9969, 'grad_norm': 0.310546875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9048, 'grad_norm': 5.71875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9521, 'grad_norm': 0.33203125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8895, 'grad_norm': 2.734375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8872, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.871, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.8241, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.0568, 'grad_norm': 0.451171875, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 2.2531, 'grad_norm': 4.78125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.7665, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.01}\n",
      "{'loss': 1.9544, 'grad_norm': 0.26953125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9021, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9428, 'grad_norm': 0.39453125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.149, 'grad_norm': 5.03125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8758, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0775, 'grad_norm': 0.3203125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0331, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8966, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8248, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8813, 'grad_norm': 1.1640625, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.985, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9502, 'grad_norm': 1.0, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8902, 'grad_norm': 0.35546875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9098, 'grad_norm': 1.9453125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9201, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.073, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0496, 'grad_norm': 1.328125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9283, 'grad_norm': 0.373046875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9076, 'grad_norm': 6.71875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8492, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8277, 'grad_norm': 0.3671875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9099, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8923, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0134, 'grad_norm': 2.453125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.883, 'grad_norm': 1.28125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0262, 'grad_norm': 0.279296875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9112, 'grad_norm': 1.2578125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9602, 'grad_norm': 0.376953125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9375, 'grad_norm': 3.4375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.7992, 'grad_norm': 0.4609375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9355, 'grad_norm': 0.373046875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9801, 'grad_norm': 0.458984375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9861, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0393, 'grad_norm': 6.28125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9919, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8713, 'grad_norm': 0.33984375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0256, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9132, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0636, 'grad_norm': 3.0, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9929, 'grad_norm': 1.46875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0303, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9466, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.0494, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 2.011, 'grad_norm': 2.5, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9428, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.8499, 'grad_norm': 0.88671875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9211, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9686, 'grad_norm': 0.404296875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9633, 'grad_norm': 4.875, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9639, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9897, 'grad_norm': 0.423828125, 'learning_rate': 1e-05, 'epoch': 0.02}\n",
      "{'loss': 1.9009, 'grad_norm': 1.828125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9057, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.2582, 'grad_norm': 4.03125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9515, 'grad_norm': 0.404296875, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8899, 'grad_norm': 0.248046875, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9247, 'grad_norm': 0.9609375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8065, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8944, 'grad_norm': 7.25, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8324, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.077, 'grad_norm': 0.345703125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9817, 'grad_norm': 0.859375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9488, 'grad_norm': 0.306640625, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.924, 'grad_norm': 2.78125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8966, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.1121, 'grad_norm': 0.97265625, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8621, 'grad_norm': 1.546875, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9041, 'grad_norm': 0.42578125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9118, 'grad_norm': 4.34375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9577, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.994, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8631, 'grad_norm': 0.8046875, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0105, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8818, 'grad_norm': 5.34375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8097, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9388, 'grad_norm': 0.392578125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8918, 'grad_norm': 1.5078125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9753, 'grad_norm': 0.365234375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0728, 'grad_norm': 6.59375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8518, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.7518, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9187, 'grad_norm': 1.3125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9304, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8926, 'grad_norm': 3.359375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8888, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9566, 'grad_norm': 0.328125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0101, 'grad_norm': 0.953125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8294, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.869, 'grad_norm': 1.5, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8865, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8251, 'grad_norm': 0.392578125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8898, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9823, 'grad_norm': 0.4375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0673, 'grad_norm': 7.4375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9471, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.1099, 'grad_norm': 0.376953125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 2.0212, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.8134, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9197, 'grad_norm': 1.8671875, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.7866, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.7335, 'grad_norm': 0.361328125, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.86, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.03}\n",
      "{'loss': 1.9121, 'grad_norm': 0.3359375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0277, 'grad_norm': 7.21875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8499, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.1443, 'grad_norm': 0.474609375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7999, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.912, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0792, 'grad_norm': 2.15625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0397, 'grad_norm': 1.203125, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7486, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8328, 'grad_norm': 0.7890625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7554, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8885, 'grad_norm': 7.53125, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8123, 'grad_norm': 1.0546875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9656, 'grad_norm': 0.349609375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7922, 'grad_norm': 1.015625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7957, 'grad_norm': 0.29296875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.116, 'grad_norm': 3.140625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8032, 'grad_norm': 0.76171875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8906, 'grad_norm': 0.31640625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0255, 'grad_norm': 0.8359375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8649, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.974, 'grad_norm': 2.953125, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.972, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9581, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8646, 'grad_norm': 1.5, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9176, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9543, 'grad_norm': 9.9375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8516, 'grad_norm': 1.0546875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8759, 'grad_norm': 0.294921875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9298, 'grad_norm': 1.59375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7254, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8963, 'grad_norm': 7.21875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8329, 'grad_norm': 0.94140625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0317, 'grad_norm': 0.466796875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7709, 'grad_norm': 0.82421875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0094, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9985, 'grad_norm': 7.71875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8314, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0455, 'grad_norm': 0.74609375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8381, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.777, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7375, 'grad_norm': 7.9375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9093, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9863, 'grad_norm': 0.337890625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9045, 'grad_norm': 0.9375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9882, 'grad_norm': 0.953125, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9214, 'grad_norm': 6.78125, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.7932, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.8711, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0054, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.04}\n",
      "{'loss': 1.6965, 'grad_norm': 0.373046875, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.02, 'grad_norm': 6.75, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9354, 'grad_norm': 1.203125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.881, 'grad_norm': 0.361328125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.899, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9263, 'grad_norm': 0.349609375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0414, 'grad_norm': 8.125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8297, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9695, 'grad_norm': 0.279296875, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.871, 'grad_norm': 1.28125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.91, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9038, 'grad_norm': 7.96875, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8662, 'grad_norm': 0.95703125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8415, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.7437, 'grad_norm': 1.5, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.93, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8767, 'grad_norm': 8.25, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9033, 'grad_norm': 0.76953125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0603, 'grad_norm': 0.3203125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0242, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8477, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0523, 'grad_norm': 3.09375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8733, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0293, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0343, 'grad_norm': 1.828125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9834, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9223, 'grad_norm': 8.625, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9821, 'grad_norm': 0.74609375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9956, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8349, 'grad_norm': 1.390625, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9665, 'grad_norm': 0.380859375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9139, 'grad_norm': 7.9375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 2.0068, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9403, 'grad_norm': 0.419921875, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9044, 'grad_norm': 1.15625, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9367, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9375, 'grad_norm': 1.9609375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8991, 'grad_norm': 1.75, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.851, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8731, 'grad_norm': 1.28125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8986, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9867, 'grad_norm': 4.71875, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9483, 'grad_norm': 1.0859375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9886, 'grad_norm': 0.275390625, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8454, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8119, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8445, 'grad_norm': 8.75, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.912, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8885, 'grad_norm': 0.8671875, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.9601, 'grad_norm': 1.6484375, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.8569, 'grad_norm': 0.64453125, 'learning_rate': 1e-05, 'epoch': 0.05}\n",
      "{'loss': 1.957, 'grad_norm': 8.5625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9227, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0528, 'grad_norm': 0.36328125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8871, 'grad_norm': 1.1875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8195, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8663, 'grad_norm': 2.484375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9663, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0066, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9662, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9242, 'grad_norm': 0.380859375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9732, 'grad_norm': 3.75, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9452, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8309, 'grad_norm': 0.291015625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0606, 'grad_norm': 0.96484375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8333, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0572, 'grad_norm': 9.0625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8474, 'grad_norm': 1.1484375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0648, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8725, 'grad_norm': 3.25, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8503, 'grad_norm': 0.39453125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9351, 'grad_norm': 1.6484375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8794, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8308, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9265, 'grad_norm': 1.765625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9802, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8799, 'grad_norm': 6.78125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8766, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9778, 'grad_norm': 0.3203125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8996, 'grad_norm': 2.125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0491, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9585, 'grad_norm': 7.0625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8801, 'grad_norm': 2.0625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8881, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0818, 'grad_norm': 2.03125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.853, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0079, 'grad_norm': 8.8125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9064, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8563, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.95, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0459, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 2.0792, 'grad_norm': 7.78125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8252, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.828, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.7978, 'grad_norm': 1.8984375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9634, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9149, 'grad_norm': 3.484375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9255, 'grad_norm': 0.9921875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9565, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.8516, 'grad_norm': 0.9921875, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.9582, 'grad_norm': 0.41015625, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.7804, 'grad_norm': 3.109375, 'learning_rate': 1e-05, 'epoch': 0.06}\n",
      "{'loss': 1.7867, 'grad_norm': 0.470703125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9341, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8753, 'grad_norm': 2.015625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8567, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9412, 'grad_norm': 4.65625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8657, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8954, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8582, 'grad_norm': 1.9296875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0688, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.944, 'grad_norm': 1.8515625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7685, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0058, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9468, 'grad_norm': 1.5546875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8801, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0145, 'grad_norm': 1.7734375, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8509, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7896, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8452, 'grad_norm': 1.9296875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9013, 'grad_norm': 0.474609375, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7627, 'grad_norm': 3.90625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8498, 'grad_norm': 1.28125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8748, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0009, 'grad_norm': 1.640625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7728, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0269, 'grad_norm': 2.671875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7547, 'grad_norm': 0.83984375, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8443, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.954, 'grad_norm': 1.3046875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9954, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9483, 'grad_norm': 4.40625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.889, 'grad_norm': 0.78515625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0985, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7901, 'grad_norm': 1.671875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9466, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9229, 'grad_norm': 2.578125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9062, 'grad_norm': 0.7734375, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.836, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9794, 'grad_norm': 1.828125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8067, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9349, 'grad_norm': 9.625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9521, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8829, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8268, 'grad_norm': 0.85546875, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8254, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9152, 'grad_norm': 4.8125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8204, 'grad_norm': 0.7890625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8153, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.928, 'grad_norm': 0.87890625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.7383, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 2.0621, 'grad_norm': 3.390625, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.9258, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.07}\n",
      "{'loss': 1.8234, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8575, 'grad_norm': 2.046875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8862, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9863, 'grad_norm': 8.1875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0019, 'grad_norm': 0.91015625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9152, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8594, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8684, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9804, 'grad_norm': 1.8984375, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8669, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8424, 'grad_norm': 0.35546875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8224, 'grad_norm': 0.875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.941, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8744, 'grad_norm': 4.1875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8736, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.88, 'grad_norm': 0.40625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9012, 'grad_norm': 2.34375, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8606, 'grad_norm': 0.267578125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.969, 'grad_norm': 3.171875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8229, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1399, 'grad_norm': 0.31640625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8392, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8253, 'grad_norm': 0.369140625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 2.1233, 'grad_norm': 3.921875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8592, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8274, 'grad_norm': 0.255859375, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 2.0757, 'grad_norm': 2.28125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8325, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8789, 'grad_norm': 2.765625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8367, 'grad_norm': 0.7890625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8603, 'grad_norm': 1.109375, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9144, 'grad_norm': 1.171875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7584, 'grad_norm': 0.470703125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8724, 'grad_norm': 1.515625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8934, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8545, 'grad_norm': 0.78515625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8759, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7243, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9684, 'grad_norm': 6.90625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.892, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8858, 'grad_norm': 0.298828125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9269, 'grad_norm': 1.4765625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7922, 'grad_norm': 0.42578125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9299, 'grad_norm': 9.25, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.7312, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8443, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9508, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.981, 'grad_norm': 0.3203125, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.863, 'grad_norm': 2.515625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8424, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.9341, 'grad_norm': 0.466796875, 'learning_rate': 1e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8251, 'grad_norm': 0.81640625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8355, 'grad_norm': 0.419921875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0344, 'grad_norm': 2.84375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8749, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8851, 'grad_norm': 0.380859375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9112, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8149, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9015, 'grad_norm': 5.65625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9036, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9433, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9612, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8917, 'grad_norm': 0.466796875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9862, 'grad_norm': 4.03125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8462, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.938, 'grad_norm': 0.392578125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8745, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8819, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0104, 'grad_norm': 1.78125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8597, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8168, 'grad_norm': 0.35546875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8292, 'grad_norm': 3.8125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0479, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.826, 'grad_norm': 3.65625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8037, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.818, 'grad_norm': 0.283203125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8976, 'grad_norm': 0.91015625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9096, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9334, 'grad_norm': 4.03125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.914, 'grad_norm': 0.4296875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 2.1657, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0844, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.949, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9933, 'grad_norm': 3.765625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.798, 'grad_norm': 1.1875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9663, 'grad_norm': 0.3359375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8763, 'grad_norm': 1.125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9377, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0229, 'grad_norm': 2.375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.847, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9429, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7945, 'grad_norm': 3.171875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.9264, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8264, 'grad_norm': 9.6875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.7903, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8534, 'grad_norm': 0.359375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8388, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8905, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0779, 'grad_norm': 7.8125, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8177, 'grad_norm': 0.77734375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8526, 'grad_norm': 1.375, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 1.8825, 'grad_norm': 0.8046875, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 2.0418, 'grad_norm': 0.39453125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9736, 'grad_norm': 3.046875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.799, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9271, 'grad_norm': 0.416015625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7917, 'grad_norm': 1.9140625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.81, 'grad_norm': 0.44140625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.812, 'grad_norm': 4.8125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7814, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.817, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0194, 'grad_norm': 0.81640625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.993, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8824, 'grad_norm': 7.71875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0467, 'grad_norm': 0.84375, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7325, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8932, 'grad_norm': 1.375, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8644, 'grad_norm': 0.953125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9612, 'grad_norm': 5.65625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8437, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9806, 'grad_norm': 0.328125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8877, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8851, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8357, 'grad_norm': 2.0, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8959, 'grad_norm': 1.2890625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8258, 'grad_norm': 0.384765625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9885, 'grad_norm': 1.4609375, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8098, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9007, 'grad_norm': 3.0625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9974, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8613, 'grad_norm': 0.294921875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8831, 'grad_norm': 1.65625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7815, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.971, 'grad_norm': 3.4375, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8997, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0417, 'grad_norm': 0.416015625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9174, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7697, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9334, 'grad_norm': 9.4375, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7417, 'grad_norm': 1.28125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7731, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.7219, 'grad_norm': 1.3046875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8181, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0788, 'grad_norm': 3.40625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0467, 'grad_norm': 0.81640625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0583, 'grad_norm': 0.94140625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8088, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9082, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9562, 'grad_norm': 3.75, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.844, 'grad_norm': 0.4375, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9623, 'grad_norm': 0.384765625, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 2.0372, 'grad_norm': 1.5234375, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.8855, 'grad_norm': 0.8046875, 'learning_rate': 1e-05, 'epoch': 0.1}\n",
      "{'loss': 1.9774, 'grad_norm': 3.484375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7726, 'grad_norm': 0.7890625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.91, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.872, 'grad_norm': 3.140625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8988, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8525, 'grad_norm': 9.875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8559, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8908, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 2.1245, 'grad_norm': 1.109375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9385, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9392, 'grad_norm': 3.90625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8969, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8988, 'grad_norm': 0.515625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9282, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.878, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 2.0683, 'grad_norm': 4.34375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8328, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8936, 'grad_norm': 0.341796875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8308, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9183, 'grad_norm': 0.3203125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8269, 'grad_norm': 9.4375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9149, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8469, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8816, 'grad_norm': 1.203125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8917, 'grad_norm': 0.365234375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9121, 'grad_norm': 9.9375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.882, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9669, 'grad_norm': 0.435546875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9039, 'grad_norm': 2.765625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9682, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7967, 'grad_norm': 4.34375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8003, 'grad_norm': 0.96484375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8317, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9351, 'grad_norm': 1.28125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8316, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9702, 'grad_norm': 3.328125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8285, 'grad_norm': 0.62109375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.7662, 'grad_norm': 1.265625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.773, 'grad_norm': 1.671875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8258, 'grad_norm': 0.9140625, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9214, 'grad_norm': 3.796875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8865, 'grad_norm': 0.388671875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.881, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9782, 'grad_norm': 0.9296875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8682, 'grad_norm': 0.470703125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9109, 'grad_norm': 8.375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9529, 'grad_norm': 2.359375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.937, 'grad_norm': 0.458984375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8376, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.8815, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.6367, 'grad_norm': 5.46875, 'learning_rate': 1e-05, 'epoch': 0.11}\n",
      "{'loss': 1.9417, 'grad_norm': 0.48828125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0003, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9144, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8514, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.736, 'grad_norm': 2.359375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7945, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9843, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8137, 'grad_norm': 0.7890625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9013, 'grad_norm': 1.859375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7856, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 2.1111, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0059, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7812, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9524, 'grad_norm': 5.0, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8585, 'grad_norm': 0.64453125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7796, 'grad_norm': 0.314453125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0232, 'grad_norm': 0.82421875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8607, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8896, 'grad_norm': 3.5625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0155, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9461, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9259, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7085, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9259, 'grad_norm': 9.3125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9387, 'grad_norm': 1.390625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7994, 'grad_norm': 0.369140625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7321, 'grad_norm': 1.625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8577, 'grad_norm': 0.482421875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.81, 'grad_norm': 9.5625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7257, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7387, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.782, 'grad_norm': 2.4375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8858, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8812, 'grad_norm': 10.1875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7701, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.904, 'grad_norm': 0.443359375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8639, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8198, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9722, 'grad_norm': 3.65625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.7946, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8047, 'grad_norm': 0.419921875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8719, 'grad_norm': 1.546875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 2.016, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9627, 'grad_norm': 3.890625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.8337, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0061, 'grad_norm': 0.341796875, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9119, 'grad_norm': 1.9140625, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.68, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 2.0524, 'grad_norm': 3.9375, 'learning_rate': 1e-05, 'epoch': 0.12}\n",
      "{'loss': 1.9139, 'grad_norm': 0.515625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9289, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8015, 'grad_norm': 1.8125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8459, 'grad_norm': 0.78515625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9559, 'grad_norm': 3.875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7418, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7857, 'grad_norm': 0.283203125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8106, 'grad_norm': 1.109375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9735, 'grad_norm': 0.388671875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9275, 'grad_norm': 5.09375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7328, 'grad_norm': 0.7109375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8002, 'grad_norm': 0.62109375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9366, 'grad_norm': 1.671875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9891, 'grad_norm': 0.357421875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.924, 'grad_norm': 3.453125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8433, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.838, 'grad_norm': 0.349609375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9071, 'grad_norm': 1.8125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8484, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.776, 'grad_norm': 9.5625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8665, 'grad_norm': 0.92578125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9573, 'grad_norm': 0.244140625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9079, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9763, 'grad_norm': 0.451171875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9228, 'grad_norm': 2.328125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 2.011, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8667, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8814, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9512, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0248, 'grad_norm': 5.25, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.6394, 'grad_norm': 1.1796875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.916, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9698, 'grad_norm': 0.93359375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7948, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9866, 'grad_norm': 4.1875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7461, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0117, 'grad_norm': 10.0, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8589, 'grad_norm': 1.46875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8462, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7809, 'grad_norm': 3.203125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8927, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8102, 'grad_norm': 0.306640625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0277, 'grad_norm': 2.375, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0037, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9201, 'grad_norm': 8.625, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.826, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 2.0291, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.7341, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8368, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.8254, 'grad_norm': 10.3125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9367, 'grad_norm': 0.64453125, 'learning_rate': 1e-05, 'epoch': 0.13}\n",
      "{'loss': 1.9855, 'grad_norm': 0.359375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.964, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7927, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9205, 'grad_norm': 2.34375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8646, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 2.1617, 'grad_norm': 0.404296875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7544, 'grad_norm': 2.171875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8743, 'grad_norm': 0.3515625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.963, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8988, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.991, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8628, 'grad_norm': 1.0546875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9337, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9834, 'grad_norm': 3.390625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8392, 'grad_norm': 0.98828125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9439, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8934, 'grad_norm': 2.296875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8885, 'grad_norm': 0.458984375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8041, 'grad_norm': 3.859375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8234, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.829, 'grad_norm': 0.41796875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9242, 'grad_norm': 0.90234375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8755, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9603, 'grad_norm': 7.9375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7928, 'grad_norm': 0.7578125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8963, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8977, 'grad_norm': 1.1171875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9321, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8625, 'grad_norm': 2.40625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.795, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9136, 'grad_norm': 0.29296875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8118, 'grad_norm': 1.890625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.6119, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8922, 'grad_norm': 2.890625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.951, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9742, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9252, 'grad_norm': 0.8828125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7552, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9049, 'grad_norm': 1.484375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8004, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7514, 'grad_norm': 0.380859375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7733, 'grad_norm': 1.125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9032, 'grad_norm': 0.9296875, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8475, 'grad_norm': 1.6640625, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8355, 'grad_norm': 1.78125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8733, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.9838, 'grad_norm': 1.734375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.7751, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8681, 'grad_norm': 2.234375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8974, 'grad_norm': 0.4609375, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8595, 'grad_norm': 0.3828125, 'learning_rate': 1e-05, 'epoch': 0.14}\n",
      "{'loss': 1.8939, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.726, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9377, 'grad_norm': 6.96875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8495, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9798, 'grad_norm': 0.28515625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7581, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7623, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.864, 'grad_norm': 1.734375, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7673, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 2.0814, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8081, 'grad_norm': 2.765625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7977, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9826, 'grad_norm': 2.296875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9065, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8645, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8182, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9003, 'grad_norm': 0.3828125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9438, 'grad_norm': 4.40625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.889, 'grad_norm': 0.9140625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9572, 'grad_norm': 0.416015625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8623, 'grad_norm': 2.640625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.86, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9542, 'grad_norm': 2.171875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8478, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.716, 'grad_norm': 0.390625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9363, 'grad_norm': 1.1640625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8687, 'grad_norm': 0.4296875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8967, 'grad_norm': 5.46875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9453, 'grad_norm': 2.328125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9825, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9079, 'grad_norm': 0.95703125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8896, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9505, 'grad_norm': 7.6875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7686, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7871, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8354, 'grad_norm': 0.96875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.913, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 2.0578, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9459, 'grad_norm': 0.7109375, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 2.1055, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9574, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7957, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 2.0546, 'grad_norm': 3.828125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8626, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8724, 'grad_norm': 1.390625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8084, 'grad_norm': 5.53125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8032, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8957, 'grad_norm': 9.5, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.726, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.9582, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.8903, 'grad_norm': 1.8046875, 'learning_rate': 1e-05, 'epoch': 0.15}\n",
      "{'loss': 1.7607, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8389, 'grad_norm': 7.9375, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9096, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9828, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.92, 'grad_norm': 2.015625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8341, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8589, 'grad_norm': 7.0, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.791, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 2.0222, 'grad_norm': 0.357421875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9241, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8269, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.76, 'grad_norm': 2.296875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9964, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8022, 'grad_norm': 0.451171875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8676, 'grad_norm': 1.8046875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9864, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8903, 'grad_norm': 5.21875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8366, 'grad_norm': 0.92578125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 2.0078, 'grad_norm': 0.490234375, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9642, 'grad_norm': 1.1953125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.7403, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.886, 'grad_norm': 3.1875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8938, 'grad_norm': 1.6875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8589, 'grad_norm': 0.310546875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9502, 'grad_norm': 1.4453125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8745, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.863, 'grad_norm': 2.78125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 2.0088, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.7861, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8685, 'grad_norm': 1.1796875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8154, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.954, 'grad_norm': 5.46875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8943, 'grad_norm': 1.4296875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.841, 'grad_norm': 0.34375, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.883, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8331, 'grad_norm': 0.6953125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.7494, 'grad_norm': 3.15625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8433, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9166, 'grad_norm': 0.392578125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9695, 'grad_norm': 3.546875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8022, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8835, 'grad_norm': 3.0625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.894, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9891, 'grad_norm': 0.474609375, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 2.0253, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.7834, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9355, 'grad_norm': 3.90625, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8051, 'grad_norm': 2.796875, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.7798, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9022, 'grad_norm': 1.3125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.8936, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.16}\n",
      "{'loss': 1.9816, 'grad_norm': 4.71875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.976, 'grad_norm': 1.5859375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9919, 'grad_norm': 0.3828125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7618, 'grad_norm': 1.3046875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9413, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7985, 'grad_norm': 9.8125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8365, 'grad_norm': 0.39453125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 2.0529, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9466, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7988, 'grad_norm': 0.36328125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9172, 'grad_norm': 7.3125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9053, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7382, 'grad_norm': 0.31640625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 2.0027, 'grad_norm': 1.1015625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8284, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9422, 'grad_norm': 1.921875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7217, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9659, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9481, 'grad_norm': 1.3515625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7839, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8976, 'grad_norm': 6.9375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.6784, 'grad_norm': 1.7734375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 2.0041, 'grad_norm': 0.4296875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8705, 'grad_norm': 1.546875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8476, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8468, 'grad_norm': 1.8671875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8007, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 2.1099, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9264, 'grad_norm': 1.671875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9851, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8816, 'grad_norm': 10.9375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9762, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9037, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 2.0073, 'grad_norm': 0.921875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9282, 'grad_norm': 0.462890625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8828, 'grad_norm': 3.0, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8049, 'grad_norm': 1.1875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8386, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9349, 'grad_norm': 1.2421875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9442, 'grad_norm': 0.88671875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8301, 'grad_norm': 1.875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8912, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9397, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7702, 'grad_norm': 1.34375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7984, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9499, 'grad_norm': 2.671875, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.7316, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8742, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9332, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8435, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.9265, 'grad_norm': 5.125, 'learning_rate': 1e-05, 'epoch': 0.17}\n",
      "{'loss': 1.8721, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.929, 'grad_norm': 0.40625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8969, 'grad_norm': 2.453125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8189, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9776, 'grad_norm': 4.125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.7805, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8596, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8742, 'grad_norm': 1.75, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9004, 'grad_norm': 0.46484375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 2.0068, 'grad_norm': 4.375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8461, 'grad_norm': 0.92578125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8757, 'grad_norm': 0.357421875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9407, 'grad_norm': 2.21875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 2.0345, 'grad_norm': 0.390625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.7867, 'grad_norm': 10.125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8596, 'grad_norm': 1.0859375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8945, 'grad_norm': 0.369140625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8453, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.7485, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 2.0771, 'grad_norm': 4.15625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8002, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8422, 'grad_norm': 1.203125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.834, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.761, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9534, 'grad_norm': 4.25, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.874, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.7282, 'grad_norm': 0.46484375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9077, 'grad_norm': 1.640625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.754, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8262, 'grad_norm': 13.5625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8822, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9259, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8858, 'grad_norm': 1.296875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 2.0188, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9645, 'grad_norm': 10.625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.7914, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9638, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.835, 'grad_norm': 0.87890625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.7119, 'grad_norm': 0.4609375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9376, 'grad_norm': 3.984375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 2.0266, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9308, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.7628, 'grad_norm': 1.0546875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8161, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9095, 'grad_norm': 5.09375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8338, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8787, 'grad_norm': 0.310546875, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.9677, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8136, 'grad_norm': 0.390625, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8035, 'grad_norm': 10.4375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.813, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.18}\n",
      "{'loss': 1.8165, 'grad_norm': 0.37109375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7074, 'grad_norm': 1.4453125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7366, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 2.0141, 'grad_norm': 3.125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7804, 'grad_norm': 0.91796875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8613, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9448, 'grad_norm': 2.0625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7245, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8065, 'grad_norm': 6.09375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8384, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8741, 'grad_norm': 1.1640625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9034, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8081, 'grad_norm': 0.33984375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7853, 'grad_norm': 10.1875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9343, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9733, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 2.0213, 'grad_norm': 2.765625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8569, 'grad_norm': 0.404296875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9412, 'grad_norm': 2.515625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8927, 'grad_norm': 0.74609375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9184, 'grad_norm': 0.416015625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8949, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8808, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8936, 'grad_norm': 8.875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8633, 'grad_norm': 0.84375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9379, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8716, 'grad_norm': 2.125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7832, 'grad_norm': 0.85546875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9625, 'grad_norm': 2.453125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7271, 'grad_norm': 1.328125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8955, 'grad_norm': 0.35546875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8663, 'grad_norm': 1.15625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.6783, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9105, 'grad_norm': 4.84375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8239, 'grad_norm': 0.7109375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9156, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9117, 'grad_norm': 2.53125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9057, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8869, 'grad_norm': 1.6796875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8485, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9857, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 2.0526, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.6736, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9391, 'grad_norm': 2.859375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.862, 'grad_norm': 0.96484375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7557, 'grad_norm': 0.29296875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7192, 'grad_norm': 2.578125, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8653, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.8854, 'grad_norm': 2.171875, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 2.0054, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.9821, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.19}\n",
      "{'loss': 1.7744, 'grad_norm': 0.94921875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8038, 'grad_norm': 0.490234375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9221, 'grad_norm': 9.375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8997, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.816, 'grad_norm': 0.404296875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 2.0056, 'grad_norm': 1.9453125, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6994, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9769, 'grad_norm': 2.625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8508, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8972, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9891, 'grad_norm': 1.4375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7615, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8903, 'grad_norm': 4.15625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8359, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8281, 'grad_norm': 0.333984375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9201, 'grad_norm': 2.140625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8711, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8914, 'grad_norm': 2.21875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8414, 'grad_norm': 0.8046875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9783, 'grad_norm': 0.330078125, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9879, 'grad_norm': 1.9296875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9152, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7884, 'grad_norm': 2.578125, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.806, 'grad_norm': 0.9765625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8839, 'grad_norm': 0.328125, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8598, 'grad_norm': 1.15625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7867, 'grad_norm': 1.8515625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7648, 'grad_norm': 2.421875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7414, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9379, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9536, 'grad_norm': 1.4140625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.853, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8344, 'grad_norm': 2.484375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8462, 'grad_norm': 0.80859375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9162, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9907, 'grad_norm': 1.4609375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8743, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.959, 'grad_norm': 1.8046875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7801, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.934, 'grad_norm': 0.33984375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9452, 'grad_norm': 1.7265625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8032, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8151, 'grad_norm': 9.6875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9205, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.9431, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8552, 'grad_norm': 1.2734375, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8096, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.8923, 'grad_norm': 11.0625, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.6767, 'grad_norm': 1.1796875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 1.7967, 'grad_norm': 0.41796875, 'learning_rate': 1e-05, 'epoch': 0.2}\n",
      "{'loss': 2.1374, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8546, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9003, 'grad_norm': 5.03125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8745, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7966, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8457, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7374, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 2.1089, 'grad_norm': 9.8125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8264, 'grad_norm': 2.0625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 2.1552, 'grad_norm': 0.302734375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8082, 'grad_norm': 3.4375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8676, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9307, 'grad_norm': 8.5, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8631, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9044, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.864, 'grad_norm': 1.2265625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.899, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9577, 'grad_norm': 3.90625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7774, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8606, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8132, 'grad_norm': 4.15625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.6985, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8581, 'grad_norm': 2.296875, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8845, 'grad_norm': 0.91796875, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 2.0025, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9634, 'grad_norm': 1.8828125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8196, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 2.0287, 'grad_norm': 1.703125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7175, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7826, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8989, 'grad_norm': 2.171875, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8139, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9645, 'grad_norm': 3.34375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7744, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 2.0047, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8236, 'grad_norm': 0.91015625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7848, 'grad_norm': 0.4921875, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9836, 'grad_norm': 12.375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.908, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8875, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.782, 'grad_norm': 2.984375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.909, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8717, 'grad_norm': 3.703125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8057, 'grad_norm': 0.921875, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8345, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9116, 'grad_norm': 1.890625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8546, 'grad_norm': 0.392578125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8549, 'grad_norm': 2.40625, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.7851, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.8393, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 2.0071, 'grad_norm': 2.578125, 'learning_rate': 1e-05, 'epoch': 0.21}\n",
      "{'loss': 1.9486, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9112, 'grad_norm': 7.0, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7928, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8869, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9438, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.853, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 2.0666, 'grad_norm': 4.3125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9496, 'grad_norm': 0.64453125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9343, 'grad_norm': 0.28125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8544, 'grad_norm': 1.328125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7424, 'grad_norm': 0.306640625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9748, 'grad_norm': 7.21875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.86, 'grad_norm': 1.390625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8172, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8457, 'grad_norm': 2.71875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6481, 'grad_norm': 0.48828125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8607, 'grad_norm': 3.8125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8448, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9312, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9586, 'grad_norm': 1.390625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7125, 'grad_norm': 0.64453125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9242, 'grad_norm': 3.078125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8326, 'grad_norm': 0.95703125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9805, 'grad_norm': 0.3046875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.912, 'grad_norm': 1.6484375, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8822, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9315, 'grad_norm': 2.34375, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8704, 'grad_norm': 0.9921875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8706, 'grad_norm': 0.33203125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7646, 'grad_norm': 0.9140625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8868, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 2.049, 'grad_norm': 3.1875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8284, 'grad_norm': 0.83203125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8123, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8773, 'grad_norm': 2.0625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.879, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9169, 'grad_norm': 4.375, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9248, 'grad_norm': 0.9140625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7741, 'grad_norm': 0.337890625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.6687, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.9342, 'grad_norm': 0.8125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.944, 'grad_norm': 4.71875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8823, 'grad_norm': 0.75, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.871, 'grad_norm': 0.3359375, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.825, 'grad_norm': 2.828125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.816, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8453, 'grad_norm': 3.125, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8235, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7691, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8441, 'grad_norm': 2.25, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.7907, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.22}\n",
      "{'loss': 1.8118, 'grad_norm': 2.828125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7819, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.792, 'grad_norm': 0.36328125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9684, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9291, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9508, 'grad_norm': 1.4765625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7676, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 2.0151, 'grad_norm': 1.171875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9419, 'grad_norm': 2.140625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9765, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.905, 'grad_norm': 7.84375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7913, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.682, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8326, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7531, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9223, 'grad_norm': 3.265625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8528, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8046, 'grad_norm': 0.3359375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8515, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8312, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8789, 'grad_norm': 11.125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7563, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.6226, 'grad_norm': 0.376953125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8278, 'grad_norm': 1.015625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9638, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9496, 'grad_norm': 2.59375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8251, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9763, 'grad_norm': 0.384765625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8737, 'grad_norm': 1.9609375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7795, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8507, 'grad_norm': 1.5625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8912, 'grad_norm': 1.0546875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8561, 'grad_norm': 0.3671875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8234, 'grad_norm': 2.171875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9137, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8211, 'grad_norm': 2.75, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8129, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8654, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 2.0145, 'grad_norm': 1.7421875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9182, 'grad_norm': 0.44140625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8022, 'grad_norm': 3.828125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9366, 'grad_norm': 0.8828125, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7735, 'grad_norm': 0.369140625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.725, 'grad_norm': 1.9921875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8837, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7978, 'grad_norm': 4.5, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9324, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8001, 'grad_norm': 0.27734375, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.8351, 'grad_norm': 2.40625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.7597, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9735, 'grad_norm': 10.75, 'learning_rate': 1e-05, 'epoch': 0.23}\n",
      "{'loss': 1.9255, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.795, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8607, 'grad_norm': 2.5, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7778, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.79, 'grad_norm': 5.71875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9983, 'grad_norm': 0.99609375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9235, 'grad_norm': 0.37109375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.872, 'grad_norm': 1.640625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 2.0088, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9633, 'grad_norm': 4.46875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8481, 'grad_norm': 0.93359375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8338, 'grad_norm': 0.34375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8741, 'grad_norm': 3.34375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9805, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8583, 'grad_norm': 2.875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7945, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8717, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7604, 'grad_norm': 0.9453125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9937, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9424, 'grad_norm': 10.5625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9708, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9952, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 2.1172, 'grad_norm': 1.1484375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8618, 'grad_norm': 0.89453125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 2.0178, 'grad_norm': 2.734375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9136, 'grad_norm': 0.84375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8848, 'grad_norm': 0.283203125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.89, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8702, 'grad_norm': 0.4921875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9397, 'grad_norm': 3.640625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 2.009, 'grad_norm': 1.015625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7201, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9257, 'grad_norm': 2.015625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9683, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9747, 'grad_norm': 3.8125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7721, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7792, 'grad_norm': 0.3515625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9229, 'grad_norm': 1.203125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.8103, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 2.0335, 'grad_norm': 5.1875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7047, 'grad_norm': 0.890625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 2.0677, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9375, 'grad_norm': 0.81640625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7987, 'grad_norm': 0.3984375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9122, 'grad_norm': 5.28125, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9013, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9066, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.7682, 'grad_norm': 1.4765625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.972, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9953, 'grad_norm': 7.65625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.751, 'grad_norm': 0.462890625, 'learning_rate': 1e-05, 'epoch': 0.24}\n",
      "{'loss': 1.9444, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7928, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7642, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 2.0006, 'grad_norm': 3.0625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9335, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8899, 'grad_norm': 0.3671875, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9174, 'grad_norm': 1.6796875, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8267, 'grad_norm': 0.376953125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8368, 'grad_norm': 3.84375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8271, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9331, 'grad_norm': 0.330078125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.963, 'grad_norm': 1.25, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9088, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9917, 'grad_norm': 3.015625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8662, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8472, 'grad_norm': 0.36328125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8968, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.784, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8429, 'grad_norm': 1.84375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9799, 'grad_norm': 0.859375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8625, 'grad_norm': 0.44140625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9628, 'grad_norm': 1.609375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6776, 'grad_norm': 0.498046875, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9509, 'grad_norm': 7.15625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7339, 'grad_norm': 0.83203125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 2.0076, 'grad_norm': 0.296875, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8202, 'grad_norm': 2.171875, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8181, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8373, 'grad_norm': 2.0, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8761, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7751, 'grad_norm': 0.31640625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9364, 'grad_norm': 0.77734375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8487, 'grad_norm': 0.42578125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8316, 'grad_norm': 2.625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8496, 'grad_norm': 0.8359375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8677, 'grad_norm': 0.3828125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8099, 'grad_norm': 0.97265625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9961, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7262, 'grad_norm': 3.828125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8955, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.6769, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.765, 'grad_norm': 1.390625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7709, 'grad_norm': 0.3984375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9325, 'grad_norm': 11.0, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8966, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7286, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.7564, 'grad_norm': 1.34375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.9251, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8546, 'grad_norm': 2.3125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.8039, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.82, 'grad_norm': 0.42578125, 'learning_rate': 1e-05, 'epoch': 0.25}\n",
      "{'loss': 1.919, 'grad_norm': 1.1171875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8517, 'grad_norm': 0.458984375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8074, 'grad_norm': 3.046875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8761, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7781, 'grad_norm': 0.388671875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8737, 'grad_norm': 1.84375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9101, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9333, 'grad_norm': 3.90625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8045, 'grad_norm': 0.98046875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9696, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8804, 'grad_norm': 1.6171875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9133, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9941, 'grad_norm': 5.96875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7192, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9644, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.797, 'grad_norm': 1.265625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8343, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8719, 'grad_norm': 11.1875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7888, 'grad_norm': 0.9375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9284, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9928, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9744, 'grad_norm': 0.33984375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7712, 'grad_norm': 11.625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 2.0758, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7787, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9895, 'grad_norm': 2.3125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.903, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9846, 'grad_norm': 3.625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8103, 'grad_norm': 1.0234375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8919, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8407, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8016, 'grad_norm': 0.98828125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 2.0372, 'grad_norm': 3.3125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8647, 'grad_norm': 1.0234375, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9025, 'grad_norm': 0.390625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.926, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.929, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8992, 'grad_norm': 2.8125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8434, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 2.0246, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8083, 'grad_norm': 1.75, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7789, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.9379, 'grad_norm': 3.5625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.763, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8192, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7986, 'grad_norm': 1.4765625, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8144, 'grad_norm': 0.330078125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8532, 'grad_norm': 2.6875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8303, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8072, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.8376, 'grad_norm': 1.9921875, 'learning_rate': 1e-05, 'epoch': 0.26}\n",
      "{'loss': 1.7652, 'grad_norm': 0.498046875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.925, 'grad_norm': 4.5625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8409, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8781, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8636, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 2.1017, 'grad_norm': 0.451171875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9076, 'grad_norm': 10.3125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.791, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8753, 'grad_norm': 0.365234375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9227, 'grad_norm': 2.40625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8996, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7966, 'grad_norm': 10.8125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8192, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9732, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8749, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7577, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9422, 'grad_norm': 5.34375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8312, 'grad_norm': 0.82421875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 2.0007, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7855, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9085, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8727, 'grad_norm': 4.0, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7852, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9688, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8984, 'grad_norm': 1.8671875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9542, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9146, 'grad_norm': 2.90625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7573, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 2.0271, 'grad_norm': 0.328125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8898, 'grad_norm': 0.96875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.6456, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9313, 'grad_norm': 7.0, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7548, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8208, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.798, 'grad_norm': 1.0078125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9092, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9438, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9664, 'grad_norm': 1.6328125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8669, 'grad_norm': 0.41015625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8328, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8629, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8919, 'grad_norm': 2.59375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8151, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9331, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7234, 'grad_norm': 2.046875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8539, 'grad_norm': 0.490234375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.7909, 'grad_norm': 2.828125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8732, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9293, 'grad_norm': 0.310546875, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9748, 'grad_norm': 1.0859375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.8232, 'grad_norm': 0.984375, 'learning_rate': 1e-05, 'epoch': 0.27}\n",
      "{'loss': 1.9211, 'grad_norm': 7.3125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6884, 'grad_norm': 1.5625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6033, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8016, 'grad_norm': 1.4921875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7998, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8217, 'grad_norm': 11.125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6685, 'grad_norm': 0.7734375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9115, 'grad_norm': 0.376953125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8533, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9126, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.797, 'grad_norm': 6.125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9356, 'grad_norm': 1.40625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.875, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8709, 'grad_norm': 1.6171875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.6903, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9707, 'grad_norm': 6.34375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7949, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9611, 'grad_norm': 0.41796875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7932, 'grad_norm': 1.796875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8702, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7607, 'grad_norm': 5.78125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8379, 'grad_norm': 0.88671875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9082, 'grad_norm': 0.4296875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8903, 'grad_norm': 1.0078125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8894, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7799, 'grad_norm': 6.09375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8525, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9156, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.901, 'grad_norm': 1.8671875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9293, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8016, 'grad_norm': 10.875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8063, 'grad_norm': 0.94140625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.923, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8667, 'grad_norm': 1.4609375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8686, 'grad_norm': 0.328125, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9186, 'grad_norm': 7.1875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9971, 'grad_norm': 0.77734375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9705, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9928, 'grad_norm': 1.296875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8676, 'grad_norm': 0.984375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8171, 'grad_norm': 2.546875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8132, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 2.0491, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8939, 'grad_norm': 2.875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8802, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.7939, 'grad_norm': 3.0625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.786, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9593, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.9763, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8555, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.28}\n",
      "{'loss': 1.8741, 'grad_norm': 11.875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7992, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9239, 'grad_norm': 0.392578125, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9322, 'grad_norm': 1.609375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7216, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9385, 'grad_norm': 2.796875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0089, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8225, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9795, 'grad_norm': 1.9765625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9471, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8421, 'grad_norm': 4.375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8406, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8756, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7664, 'grad_norm': 0.91796875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6913, 'grad_norm': 0.875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0127, 'grad_norm': 11.75, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8898, 'grad_norm': 0.80859375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6963, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8197, 'grad_norm': 1.7734375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8568, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0257, 'grad_norm': 4.59375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7892, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8147, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0556, 'grad_norm': 1.21875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7921, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8293, 'grad_norm': 3.296875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8244, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0454, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8051, 'grad_norm': 2.546875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7262, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9319, 'grad_norm': 2.234375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8134, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7187, 'grad_norm': 0.451171875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8742, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9035, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 2.0143, 'grad_norm': 8.3125, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6835, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.6528, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8133, 'grad_norm': 1.7421875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7539, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9206, 'grad_norm': 8.625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8094, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7329, 'grad_norm': 0.388671875, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8694, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.7755, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9845, 'grad_norm': 3.234375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9149, 'grad_norm': 0.8515625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8131, 'grad_norm': 0.2734375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8481, 'grad_norm': 1.109375, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8577, 'grad_norm': 0.81640625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.9904, 'grad_norm': 4.40625, 'learning_rate': 1e-05, 'epoch': 0.29}\n",
      "{'loss': 1.8211, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8212, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8412, 'grad_norm': 1.890625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8553, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8558, 'grad_norm': 4.4375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7946, 'grad_norm': 0.99609375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9147, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8866, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7976, 'grad_norm': 0.84375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 2.0629, 'grad_norm': 5.125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.817, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8202, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8218, 'grad_norm': 2.984375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9671, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8442, 'grad_norm': 3.9375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8901, 'grad_norm': 0.8046875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8803, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9314, 'grad_norm': 1.296875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8912, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8698, 'grad_norm': 11.6875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8504, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 2.001, 'grad_norm': 0.361328125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8263, 'grad_norm': 1.328125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8345, 'grad_norm': 0.4921875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9529, 'grad_norm': 2.625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.843, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8946, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 2.0239, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8534, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8877, 'grad_norm': 2.328125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.866, 'grad_norm': 1.0078125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7868, 'grad_norm': 0.404296875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8015, 'grad_norm': 1.25, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 2.0142, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9732, 'grad_norm': 2.84375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7557, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8811, 'grad_norm': 0.306640625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.839, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8825, 'grad_norm': 0.443359375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8339, 'grad_norm': 7.0, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7506, 'grad_norm': 1.1953125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8623, 'grad_norm': 0.41796875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8472, 'grad_norm': 1.2890625, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7976, 'grad_norm': 0.376953125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8682, 'grad_norm': 2.21875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.9368, 'grad_norm': 2.125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8284, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8968, 'grad_norm': 0.89453125, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7753, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.8908, 'grad_norm': 10.9375, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 1.7649, 'grad_norm': 0.875, 'learning_rate': 1e-05, 'epoch': 0.3}\n",
      "{'loss': 2.0981, 'grad_norm': 0.376953125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8852, 'grad_norm': 2.140625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7742, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6918, 'grad_norm': 1.9765625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8774, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8294, 'grad_norm': 0.328125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8924, 'grad_norm': 0.875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8075, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.866, 'grad_norm': 2.25, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8968, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.909, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8998, 'grad_norm': 1.7890625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.6202, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8424, 'grad_norm': 3.0, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9321, 'grad_norm': 0.94140625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 2.0876, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8337, 'grad_norm': 1.3125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8148, 'grad_norm': 0.44140625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9389, 'grad_norm': 3.671875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8409, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8741, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7791, 'grad_norm': 1.7890625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8647, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8905, 'grad_norm': 3.609375, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9461, 'grad_norm': 2.421875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8255, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7638, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 2.0145, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8568, 'grad_norm': 5.90625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8775, 'grad_norm': 0.82421875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8494, 'grad_norm': 0.3046875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9172, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8515, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9057, 'grad_norm': 2.625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8716, 'grad_norm': 1.125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9288, 'grad_norm': 5.75, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.948, 'grad_norm': 1.1640625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9512, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7659, 'grad_norm': 11.3125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.725, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9196, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7113, 'grad_norm': 3.515625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9098, 'grad_norm': 0.42578125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8292, 'grad_norm': 3.921875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9405, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.9347, 'grad_norm': 0.46484375, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7202, 'grad_norm': 1.2578125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8389, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8866, 'grad_norm': 5.15625, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.7812, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.825, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.31}\n",
      "{'loss': 1.8373, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9045, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9658, 'grad_norm': 1.8125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7159, 'grad_norm': 0.99609375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9272, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9101, 'grad_norm': 1.4609375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9406, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9997, 'grad_norm': 3.59375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8917, 'grad_norm': 0.84375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7494, 'grad_norm': 0.337890625, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9859, 'grad_norm': 1.3203125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.5996, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8502, 'grad_norm': 2.53125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7726, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8509, 'grad_norm': 0.361328125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8145, 'grad_norm': 1.2265625, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9542, 'grad_norm': 0.8125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9385, 'grad_norm': 4.6875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6912, 'grad_norm': 0.93359375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7051, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8571, 'grad_norm': 1.6015625, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.6897, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8741, 'grad_norm': 5.4375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8841, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8639, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9762, 'grad_norm': 1.25, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8843, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8486, 'grad_norm': 4.125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8105, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8049, 'grad_norm': 0.443359375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.958, 'grad_norm': 3.734375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7244, 'grad_norm': 0.4609375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8754, 'grad_norm': 3.015625, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7784, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9031, 'grad_norm': 0.3828125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8525, 'grad_norm': 2.546875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7903, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.959, 'grad_norm': 4.8125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7654, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8931, 'grad_norm': 0.326171875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8017, 'grad_norm': 1.40625, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8314, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8983, 'grad_norm': 11.3125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9493, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9612, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.704, 'grad_norm': 1.6171875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8941, 'grad_norm': 0.466796875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9038, 'grad_norm': 11.6875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9039, 'grad_norm': 1.3046875, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.8491, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.7803, 'grad_norm': 1.7734375, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 1.9373, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8594, 'grad_norm': 12.25, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8184, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8756, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9458, 'grad_norm': 3.140625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8068, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9623, 'grad_norm': 3.296875, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7177, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8186, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9878, 'grad_norm': 2.9375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.798, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8632, 'grad_norm': 11.5625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8572, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8684, 'grad_norm': 0.44140625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.864, 'grad_norm': 1.4140625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8751, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 2.0092, 'grad_norm': 5.125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7847, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8458, 'grad_norm': 0.2275390625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 2.0005, 'grad_norm': 2.03125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7106, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7717, 'grad_norm': 2.890625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7688, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9729, 'grad_norm': 0.341796875, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9262, 'grad_norm': 2.0625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7557, 'grad_norm': 0.423828125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8724, 'grad_norm': 2.09375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9726, 'grad_norm': 0.64453125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.805, 'grad_norm': 0.33984375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9819, 'grad_norm': 2.59375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9039, 'grad_norm': 0.93359375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8675, 'grad_norm': 4.03125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.88, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9631, 'grad_norm': 0.380859375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8937, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7556, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8105, 'grad_norm': 4.4375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8762, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 2.0514, 'grad_norm': 0.4609375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8682, 'grad_norm': 1.515625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8548, 'grad_norm': 0.3984375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8371, 'grad_norm': 3.015625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8159, 'grad_norm': 0.515625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8883, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9654, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7886, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.7893, 'grad_norm': 3.734375, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.8471, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.869, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.834, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9696, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.33}\n",
      "{'loss': 1.9101, 'grad_norm': 12.375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9904, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8925, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9745, 'grad_norm': 1.84375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9213, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8026, 'grad_norm': 2.609375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8315, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8624, 'grad_norm': 0.31640625, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8178, 'grad_norm': 1.703125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6827, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.983, 'grad_norm': 11.9375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8562, 'grad_norm': 0.9140625, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6885, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.854, 'grad_norm': 1.109375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6981, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8446, 'grad_norm': 12.0, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6764, 'grad_norm': 1.390625, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8186, 'grad_norm': 1.8203125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8522, 'grad_norm': 2.015625, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8204, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9324, 'grad_norm': 4.28125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.7862, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9588, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9038, 'grad_norm': 1.9453125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8571, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9606, 'grad_norm': 2.34375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.7797, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8443, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 2.0166, 'grad_norm': 1.0546875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.797, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.953, 'grad_norm': 5.0625, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6214, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9621, 'grad_norm': 0.416015625, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9934, 'grad_norm': 1.1171875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 2.006, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8841, 'grad_norm': 5.9375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8827, 'grad_norm': 0.8359375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.6896, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9248, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9205, 'grad_norm': 0.328125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9032, 'grad_norm': 1.9453125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9143, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9003, 'grad_norm': 0.94921875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8397, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8068, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9167, 'grad_norm': 4.875, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.934, 'grad_norm': 0.98828125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.7337, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 2.0329, 'grad_norm': 2.484375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.7086, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.8306, 'grad_norm': 2.09375, 'learning_rate': 1e-05, 'epoch': 0.34}\n",
      "{'loss': 1.9876, 'grad_norm': 0.98046875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8672, 'grad_norm': 0.7109375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9827, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9462, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8397, 'grad_norm': 5.09375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7178, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7813, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8897, 'grad_norm': 1.8828125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.851, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 2.0307, 'grad_norm': 6.65625, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8997, 'grad_norm': 0.76953125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9239, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8405, 'grad_norm': 1.484375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7147, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9239, 'grad_norm': 5.5625, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8786, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8899, 'grad_norm': 0.359375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8217, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9574, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 2.0499, 'grad_norm': 2.375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8716, 'grad_norm': 0.98828125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7593, 'grad_norm': 1.734375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8646, 'grad_norm': 1.859375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7604, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7585, 'grad_norm': 2.15625, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9664, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.746, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8873, 'grad_norm': 1.2421875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.831, 'grad_norm': 0.7109375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9456, 'grad_norm': 5.21875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8344, 'grad_norm': 1.671875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7958, 'grad_norm': 0.310546875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9323, 'grad_norm': 2.03125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.941, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8999, 'grad_norm': 2.765625, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.89, 'grad_norm': 2.015625, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.6819, 'grad_norm': 1.0234375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9695, 'grad_norm': 1.5, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8678, 'grad_norm': 0.6953125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7756, 'grad_norm': 2.546875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9662, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8614, 'grad_norm': 0.294921875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9349, 'grad_norm': 1.7109375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8365, 'grad_norm': 0.498046875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9143, 'grad_norm': 1.6015625, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8148, 'grad_norm': 0.80859375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9252, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.9361, 'grad_norm': 1.875, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.7286, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8116, 'grad_norm': 5.125, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8078, 'grad_norm': 1.9375, 'learning_rate': 1e-05, 'epoch': 0.35}\n",
      "{'loss': 1.8305, 'grad_norm': 0.330078125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7703, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 2.0287, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9478, 'grad_norm': 2.3125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.835, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7806, 'grad_norm': 0.333984375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8077, 'grad_norm': 0.95703125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7534, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8704, 'grad_norm': 11.625, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.727, 'grad_norm': 0.8984375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9373, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9165, 'grad_norm': 2.03125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.6424, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.842, 'grad_norm': 3.828125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9371, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8513, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8662, 'grad_norm': 1.609375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.863, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.934, 'grad_norm': 3.828125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.6531, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 2.0223, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8772, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9329, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7618, 'grad_norm': 2.46875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.792, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8906, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9554, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7636, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8656, 'grad_norm': 7.8125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7401, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.754, 'grad_norm': 0.359375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8789, 'grad_norm': 2.234375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9244, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8699, 'grad_norm': 2.828125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7284, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9798, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8185, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9341, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9264, 'grad_norm': 3.015625, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8688, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9369, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.744, 'grad_norm': 2.625, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9981, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.9125, 'grad_norm': 3.203125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8433, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8836, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8413, 'grad_norm': 1.6484375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.6772, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.8738, 'grad_norm': 11.25, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.7572, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.36}\n",
      "{'loss': 1.89, 'grad_norm': 0.2890625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9164, 'grad_norm': 1.015625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.922, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9139, 'grad_norm': 2.890625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8636, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9364, 'grad_norm': 0.515625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8696, 'grad_norm': 0.8671875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8613, 'grad_norm': 0.4609375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8787, 'grad_norm': 5.59375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8594, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.829, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8447, 'grad_norm': 2.125, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7189, 'grad_norm': 0.482421875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8678, 'grad_norm': 3.640625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.847, 'grad_norm': 1.0078125, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.836, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.93, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7987, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8192, 'grad_norm': 3.84375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8482, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.815, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9121, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8769, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9102, 'grad_norm': 3.90625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7338, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9588, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9358, 'grad_norm': 1.75, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7978, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8367, 'grad_norm': 11.6875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9019, 'grad_norm': 0.81640625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9212, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7849, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7967, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9816, 'grad_norm': 4.3125, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.75, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8685, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8825, 'grad_norm': 1.9375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9051, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8766, 'grad_norm': 4.09375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8951, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7365, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9208, 'grad_norm': 1.46875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.7988, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9372, 'grad_norm': 3.109375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9302, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9602, 'grad_norm': 0.4609375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8715, 'grad_norm': 1.34375, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8775, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8613, 'grad_norm': 2.6875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8918, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.9778, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.37}\n",
      "{'loss': 1.8523, 'grad_norm': 4.34375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 2.0978, 'grad_norm': 0.380859375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8583, 'grad_norm': 11.8125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8843, 'grad_norm': 1.34375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.809, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7935, 'grad_norm': 1.9921875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9212, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9643, 'grad_norm': 7.34375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8631, 'grad_norm': 0.83984375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9209, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8313, 'grad_norm': 2.90625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7927, 'grad_norm': 0.82421875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7328, 'grad_norm': 3.125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7573, 'grad_norm': 0.984375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9603, 'grad_norm': 0.3828125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8743, 'grad_norm': 1.8828125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8562, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9404, 'grad_norm': 3.953125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8685, 'grad_norm': 0.875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8866, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8, 'grad_norm': 1.109375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7816, 'grad_norm': 0.83984375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8577, 'grad_norm': 12.3125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.794, 'grad_norm': 0.9375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8777, 'grad_norm': 0.330078125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8314, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7887, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.765, 'grad_norm': 3.15625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 2.0607, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9368, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.843, 'grad_norm': 1.46875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9522, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 2.0168, 'grad_norm': 3.515625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8387, 'grad_norm': 0.93359375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8655, 'grad_norm': 0.361328125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8722, 'grad_norm': 2.53125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.7805, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8082, 'grad_norm': 4.3125, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8826, 'grad_norm': 0.8359375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 2.0631, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9944, 'grad_norm': 1.3515625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9715, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8501, 'grad_norm': 5.40625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8082, 'grad_norm': 1.1015625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9491, 'grad_norm': 0.341796875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9992, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9871, 'grad_norm': 0.9921875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8437, 'grad_norm': 4.09375, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8889, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.8646, 'grad_norm': 0.3671875, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.9318, 'grad_norm': 1.7890625, 'learning_rate': 1e-05, 'epoch': 0.38}\n",
      "{'loss': 1.94, 'grad_norm': 0.458984375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9105, 'grad_norm': 2.21875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7145, 'grad_norm': 1.1171875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 2.0094, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8468, 'grad_norm': 1.3125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7664, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8346, 'grad_norm': 4.59375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7584, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7985, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8859, 'grad_norm': 1.296875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8528, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8663, 'grad_norm': 2.828125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7942, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9745, 'grad_norm': 0.4921875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7345, 'grad_norm': 1.9609375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9259, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.844, 'grad_norm': 2.015625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8789, 'grad_norm': 1.4453125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9951, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8742, 'grad_norm': 1.1171875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7352, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8285, 'grad_norm': 3.203125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7954, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9109, 'grad_norm': 1.9296875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8896, 'grad_norm': 1.828125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7717, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9703, 'grad_norm': 11.0625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8113, 'grad_norm': 0.76953125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8733, 'grad_norm': 0.365234375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8436, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8608, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8168, 'grad_norm': 8.75, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7766, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8532, 'grad_norm': 0.373046875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9655, 'grad_norm': 1.296875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8474, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8552, 'grad_norm': 3.8125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7654, 'grad_norm': 0.953125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.684, 'grad_norm': 0.3984375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8871, 'grad_norm': 1.6875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 2.0567, 'grad_norm': 0.7578125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9055, 'grad_norm': 3.59375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8484, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7773, 'grad_norm': 0.376953125, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.9526, 'grad_norm': 1.59375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8918, 'grad_norm': 0.41015625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.8855, 'grad_norm': 1.7734375, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7852, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 2.1505, 'grad_norm': 0.40625, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.7767, 'grad_norm': 1.6796875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.789, 'grad_norm': 1.421875, 'learning_rate': 1e-05, 'epoch': 0.39}\n",
      "{'loss': 1.981, 'grad_norm': 3.859375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.7602, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9013, 'grad_norm': 0.330078125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9002, 'grad_norm': 1.765625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8238, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9777, 'grad_norm': 3.078125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8589, 'grad_norm': 0.90234375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 2.0009, 'grad_norm': 0.33203125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9196, 'grad_norm': 1.6796875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9861, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8959, 'grad_norm': 12.75, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.7119, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8182, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9095, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8031, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9905, 'grad_norm': 7.59375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9101, 'grad_norm': 0.8828125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.7675, 'grad_norm': 0.36328125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8574, 'grad_norm': 1.4375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9211, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8318, 'grad_norm': 12.75, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.7282, 'grad_norm': 1.1640625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.7787, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8873, 'grad_norm': 0.921875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8128, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.987, 'grad_norm': 8.75, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9382, 'grad_norm': 0.7890625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8073, 'grad_norm': 0.8671875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8442, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.873, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8912, 'grad_norm': 5.28125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8162, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8062, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8064, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8768, 'grad_norm': 0.92578125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8362, 'grad_norm': 11.625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8066, 'grad_norm': 0.8984375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9623, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8629, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9017, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8061, 'grad_norm': 12.125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9025, 'grad_norm': 0.9296875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9243, 'grad_norm': 0.36328125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.782, 'grad_norm': 2.09375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.7409, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8387, 'grad_norm': 12.1875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9297, 'grad_norm': 0.77734375, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.916, 'grad_norm': 0.337890625, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.8306, 'grad_norm': 0.76171875, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.961, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.9446, 'grad_norm': 6.75, 'learning_rate': 1e-05, 'epoch': 0.4}\n",
      "{'loss': 1.889, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.7992, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.925, 'grad_norm': 1.890625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9784, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9564, 'grad_norm': 2.75, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8711, 'grad_norm': 1.109375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8931, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8396, 'grad_norm': 1.9921875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.7889, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 2.0201, 'grad_norm': 10.8125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9125, 'grad_norm': 0.462890625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8831, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8418, 'grad_norm': 1.5234375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.6716, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 2.0433, 'grad_norm': 3.828125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.769, 'grad_norm': 1.265625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8917, 'grad_norm': 0.384765625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8714, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9184, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9747, 'grad_norm': 4.25, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8203, 'grad_norm': 0.859375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9022, 'grad_norm': 0.3125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8147, 'grad_norm': 0.9765625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 2.0149, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8355, 'grad_norm': 3.0, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8196, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8171, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 2.0045, 'grad_norm': 1.9296875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8194, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 2.0122, 'grad_norm': 8.75, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8539, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8642, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9028, 'grad_norm': 2.265625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8488, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8374, 'grad_norm': 5.65625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.7645, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.7406, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8371, 'grad_norm': 1.2890625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.716, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9334, 'grad_norm': 3.953125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9857, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.9233, 'grad_norm': 0.33203125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8306, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.7306, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.933, 'grad_norm': 4.625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.861, 'grad_norm': 0.890625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8849, 'grad_norm': 2.703125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 2.0116, 'grad_norm': 1.6875, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8726, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.7513, 'grad_norm': 2.78125, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.8898, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.41}\n",
      "{'loss': 1.859, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8813, 'grad_norm': 1.1875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.82, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9239, 'grad_norm': 3.28125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8478, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7267, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.852, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7626, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9623, 'grad_norm': 12.5625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9022, 'grad_norm': 1.1875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7604, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8076, 'grad_norm': 1.96875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9305, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7762, 'grad_norm': 9.3125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.724, 'grad_norm': 0.77734375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8896, 'grad_norm': 0.380859375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9187, 'grad_norm': 1.7421875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7999, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9638, 'grad_norm': 6.09375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9114, 'grad_norm': 0.953125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9678, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9612, 'grad_norm': 1.6171875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.6707, 'grad_norm': 0.83203125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9978, 'grad_norm': 3.046875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7671, 'grad_norm': 0.94921875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8515, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9463, 'grad_norm': 1.859375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8252, 'grad_norm': 0.474609375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 2.0193, 'grad_norm': 3.78125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8836, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.888, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.871, 'grad_norm': 0.984375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7316, 'grad_norm': 1.9765625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9067, 'grad_norm': 3.609375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8278, 'grad_norm': 2.421875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9168, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8761, 'grad_norm': 1.2421875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8788, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9107, 'grad_norm': 2.59375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8932, 'grad_norm': 0.9765625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9975, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8188, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.905, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8786, 'grad_norm': 3.96875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9138, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9917, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9996, 'grad_norm': 1.6640625, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9313, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.949, 'grad_norm': 12.5, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.8787, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.9604, 'grad_norm': 0.9453125, 'learning_rate': 1e-05, 'epoch': 0.42}\n",
      "{'loss': 1.7181, 'grad_norm': 1.265625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7695, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8119, 'grad_norm': 3.484375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8684, 'grad_norm': 1.1015625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9028, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8438, 'grad_norm': 2.078125, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.927, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8322, 'grad_norm': 4.5, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9145, 'grad_norm': 0.78515625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.6844, 'grad_norm': 0.37109375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7708, 'grad_norm': 1.40625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7886, 'grad_norm': 1.0, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7893, 'grad_norm': 4.96875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8005, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 2.0808, 'grad_norm': 0.4609375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8736, 'grad_norm': 1.375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.711, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9107, 'grad_norm': 4.0, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9361, 'grad_norm': 0.9375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8196, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8329, 'grad_norm': 1.84375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8512, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9783, 'grad_norm': 4.4375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.82, 'grad_norm': 0.94921875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8415, 'grad_norm': 0.890625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8812, 'grad_norm': 4.5625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9137, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7718, 'grad_norm': 3.25, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8721, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9351, 'grad_norm': 0.498046875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8823, 'grad_norm': 1.9765625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7894, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.908, 'grad_norm': 3.75, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7256, 'grad_norm': 2.984375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7952, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.814, 'grad_norm': 0.99609375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7367, 'grad_norm': 0.435546875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8174, 'grad_norm': 3.171875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9403, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9138, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7719, 'grad_norm': 1.7890625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7513, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7463, 'grad_norm': 7.15625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7565, 'grad_norm': 1.296875, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9771, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8842, 'grad_norm': 1.203125, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9097, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8634, 'grad_norm': 3.90625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.7288, 'grad_norm': 0.84375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.9184, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 2.0509, 'grad_norm': 1.4609375, 'learning_rate': 1e-05, 'epoch': 0.43}\n",
      "{'loss': 1.8524, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8755, 'grad_norm': 11.25, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8839, 'grad_norm': 1.1640625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9116, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9036, 'grad_norm': 0.96875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9543, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9563, 'grad_norm': 3.234375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8621, 'grad_norm': 0.85546875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8407, 'grad_norm': 0.3359375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9258, 'grad_norm': 2.34375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8876, 'grad_norm': 0.89453125, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 2.0166, 'grad_norm': 9.5, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8862, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8252, 'grad_norm': 0.416015625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.7619, 'grad_norm': 1.6875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8924, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8262, 'grad_norm': 11.625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9886, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9223, 'grad_norm': 1.9765625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.774, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9269, 'grad_norm': 7.0, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8704, 'grad_norm': 0.8359375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8867, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.772, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8272, 'grad_norm': 0.443359375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8566, 'grad_norm': 5.65625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.7719, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8975, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8812, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9905, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8873, 'grad_norm': 2.140625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.7726, 'grad_norm': 1.2578125, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8697, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.7974, 'grad_norm': 0.92578125, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 2.0272, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.7774, 'grad_norm': 3.828125, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9043, 'grad_norm': 1.2734375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8336, 'grad_norm': 0.388671875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.7143, 'grad_norm': 2.46875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8708, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.777, 'grad_norm': 11.5, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.849, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9037, 'grad_norm': 0.34375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9465, 'grad_norm': 1.4765625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.721, 'grad_norm': 0.46484375, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8886, 'grad_norm': 4.15625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.875, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.7348, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8431, 'grad_norm': 2.140625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.8613, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.44}\n",
      "{'loss': 1.9522, 'grad_norm': 4.1875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.908, 'grad_norm': 0.8828125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.827, 'grad_norm': 0.96484375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.9632, 'grad_norm': 1.3125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8053, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8269, 'grad_norm': 4.59375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.9036, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8147, 'grad_norm': 0.33984375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.9894, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7772, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8518, 'grad_norm': 11.5, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8085, 'grad_norm': 0.82421875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7123, 'grad_norm': 0.39453125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.957, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8166, 'grad_norm': 0.890625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8528, 'grad_norm': 3.5625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.9039, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7656, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8519, 'grad_norm': 3.125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7183, 'grad_norm': 0.87890625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8091, 'grad_norm': 3.515625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8637, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0032, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8327, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8107, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8125, 'grad_norm': 5.0625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8216, 'grad_norm': 0.921875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.865, 'grad_norm': 0.3671875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.9121, 'grad_norm': 1.2265625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8237, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0335, 'grad_norm': 6.8125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8409, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7668, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8927, 'grad_norm': 1.7421875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8812, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8149, 'grad_norm': 4.71875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.828, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.951, 'grad_norm': 0.384765625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8841, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.9297, 'grad_norm': 0.92578125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8862, 'grad_norm': 2.28125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7517, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7819, 'grad_norm': 0.435546875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.7825, 'grad_norm': 0.875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8407, 'grad_norm': 0.4375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 2.0103, 'grad_norm': 4.25, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8464, 'grad_norm': 0.76171875, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8023, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8824, 'grad_norm': 1.4375, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.8046, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.45}\n",
      "{'loss': 1.9089, 'grad_norm': 7.46875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9497, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8866, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7965, 'grad_norm': 2.296875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8605, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8741, 'grad_norm': 2.234375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8908, 'grad_norm': 1.4453125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8628, 'grad_norm': 0.388671875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7804, 'grad_norm': 1.0234375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8364, 'grad_norm': 0.8671875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9225, 'grad_norm': 7.90625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.77, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8058, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8823, 'grad_norm': 3.53125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.84, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9071, 'grad_norm': 11.75, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8353, 'grad_norm': 1.203125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.87, 'grad_norm': 0.443359375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9506, 'grad_norm': 1.84375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8723, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7344, 'grad_norm': 3.0, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.856, 'grad_norm': 0.7734375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8196, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.846, 'grad_norm': 1.4375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7757, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8769, 'grad_norm': 6.375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.781, 'grad_norm': 0.9375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9609, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9813, 'grad_norm': 1.2734375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8208, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9095, 'grad_norm': 12.625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8888, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8031, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8742, 'grad_norm': 0.9609375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8488, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8711, 'grad_norm': 1.546875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8149, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9335, 'grad_norm': 0.345703125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.852, 'grad_norm': 1.9375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7074, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9994, 'grad_norm': 2.171875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7372, 'grad_norm': 1.5625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.948, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9205, 'grad_norm': 2.25, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.7846, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.999, 'grad_norm': 2.5625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.869, 'grad_norm': 0.8984375, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8929, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9808, 'grad_norm': 0.98046875, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9036, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.9677, 'grad_norm': 2.8125, 'learning_rate': 1e-05, 'epoch': 0.46}\n",
      "{'loss': 1.8591, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 2.0807, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8171, 'grad_norm': 2.46875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9535, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8862, 'grad_norm': 2.609375, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7731, 'grad_norm': 0.91796875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8817, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.878, 'grad_norm': 2.78125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8489, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8116, 'grad_norm': 13.5625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7362, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8872, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8217, 'grad_norm': 1.796875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9145, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.6905, 'grad_norm': 13.6875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8504, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9529, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9528, 'grad_norm': 0.96875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7901, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8531, 'grad_norm': 2.703125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8528, 'grad_norm': 1.3125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8291, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8899, 'grad_norm': 2.046875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.6759, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8304, 'grad_norm': 3.921875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9378, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9015, 'grad_norm': 0.423828125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9642, 'grad_norm': 0.953125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8846, 'grad_norm': 0.419921875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9948, 'grad_norm': 5.59375, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7409, 'grad_norm': 0.82421875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 2.0987, 'grad_norm': 0.392578125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8805, 'grad_norm': 1.34375, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8143, 'grad_norm': 0.419921875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9116, 'grad_norm': 3.875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8698, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8532, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9038, 'grad_norm': 3.75, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7769, 'grad_norm': 0.5546875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9069, 'grad_norm': 3.65625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.803, 'grad_norm': 0.96875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8811, 'grad_norm': 0.259765625, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9016, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8561, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8198, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.6922, 'grad_norm': 0.76171875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9003, 'grad_norm': 0.35546875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.8075, 'grad_norm': 1.84375, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7533, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9112, 'grad_norm': 2.671875, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.7695, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.47}\n",
      "{'loss': 1.9454, 'grad_norm': 0.474609375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.908, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.83, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8537, 'grad_norm': 4.4375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8342, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9058, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8344, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9092, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8167, 'grad_norm': 11.8125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7336, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9836, 'grad_norm': 1.609375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8871, 'grad_norm': 2.03125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7367, 'grad_norm': 0.451171875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9477, 'grad_norm': 3.546875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8129, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8396, 'grad_norm': 0.390625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7423, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9991, 'grad_norm': 0.466796875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 2.0201, 'grad_norm': 2.84375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.6424, 'grad_norm': 0.76171875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8854, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8542, 'grad_norm': 1.4765625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8534, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7972, 'grad_norm': 4.90625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7769, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8272, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9041, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7555, 'grad_norm': 0.98828125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7731, 'grad_norm': 3.484375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8047, 'grad_norm': 0.76171875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8693, 'grad_norm': 0.498046875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7573, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8047, 'grad_norm': 1.1640625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9587, 'grad_norm': 7.5, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8407, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8925, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 2.0551, 'grad_norm': 1.625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8075, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8966, 'grad_norm': 12.1875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9324, 'grad_norm': 0.93359375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9173, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9647, 'grad_norm': 1.3828125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7892, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9237, 'grad_norm': 2.15625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7412, 'grad_norm': 0.7109375, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7945, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8045, 'grad_norm': 1.203125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8146, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.9136, 'grad_norm': 5.5625, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.7689, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8301, 'grad_norm': 0.38671875, 'learning_rate': 1e-05, 'epoch': 0.48}\n",
      "{'loss': 1.8622, 'grad_norm': 1.25, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8205, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8955, 'grad_norm': 2.78125, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.6475, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 2.0436, 'grad_norm': 0.490234375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.861, 'grad_norm': 1.796875, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7203, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8311, 'grad_norm': 13.0, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9052, 'grad_norm': 0.9140625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8596, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7484, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.893, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8104, 'grad_norm': 12.625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8251, 'grad_norm': 0.80859375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8044, 'grad_norm': 0.515625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8664, 'grad_norm': 0.91015625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8321, 'grad_norm': 0.765625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8948, 'grad_norm': 3.515625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8221, 'grad_norm': 0.84375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7647, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8199, 'grad_norm': 1.1640625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9874, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 2.0161, 'grad_norm': 6.0625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7811, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8638, 'grad_norm': 0.3515625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9268, 'grad_norm': 2.0, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9409, 'grad_norm': 0.984375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8466, 'grad_norm': 3.5625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9449, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7402, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9636, 'grad_norm': 2.125, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8455, 'grad_norm': 0.48828125, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8821, 'grad_norm': 5.21875, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8284, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9167, 'grad_norm': 0.34375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9534, 'grad_norm': 1.984375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7913, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 2.0738, 'grad_norm': 11.875, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8125, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8543, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9101, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.915, 'grad_norm': 0.443359375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.989, 'grad_norm': 3.125, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7918, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.9281, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8656, 'grad_norm': 1.4375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.8616, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7786, 'grad_norm': 8.375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7413, 'grad_norm': 0.93359375, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7985, 'grad_norm': 0.44140625, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7885, 'grad_norm': 1.3671875, 'learning_rate': 1e-05, 'epoch': 0.49}\n",
      "{'loss': 1.7735, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9142, 'grad_norm': 3.8125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9132, 'grad_norm': 0.90234375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7521, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7208, 'grad_norm': 1.390625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8205, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 2.1006, 'grad_norm': 3.390625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7859, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8275, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8808, 'grad_norm': 1.7734375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8757, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7803, 'grad_norm': 4.65625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.78, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7003, 'grad_norm': 0.48046875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9665, 'grad_norm': 3.375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8026, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7544, 'grad_norm': 8.5, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8193, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9035, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9822, 'grad_norm': 1.1171875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8114, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 2.0383, 'grad_norm': 3.390625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8883, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7931, 'grad_norm': 0.416015625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7886, 'grad_norm': 1.2578125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7183, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9579, 'grad_norm': 8.125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7546, 'grad_norm': 1.15625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9056, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7987, 'grad_norm': 1.0078125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9221, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9738, 'grad_norm': 6.25, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7636, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8628, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8493, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7562, 'grad_norm': 0.8515625, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8923, 'grad_norm': 3.125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.788, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9718, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7846, 'grad_norm': 1.6484375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.76, 'grad_norm': 0.48828125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7819, 'grad_norm': 4.59375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9009, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8131, 'grad_norm': 0.357421875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9005, 'grad_norm': 1.75, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.9667, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7948, 'grad_norm': 2.78125, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8085, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7189, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.8328, 'grad_norm': 0.7734375, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.7237, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.5}\n",
      "{'loss': 1.955, 'grad_norm': 2.984375, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8181, 'grad_norm': 0.64453125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9952, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9326, 'grad_norm': 1.40625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.974, 'grad_norm': 1.40625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8864, 'grad_norm': 3.90625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9174, 'grad_norm': 1.265625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 2.0071, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.98, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.98, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8144, 'grad_norm': 3.265625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8177, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9312, 'grad_norm': 0.361328125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8829, 'grad_norm': 0.83203125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7614, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7134, 'grad_norm': 12.125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.887, 'grad_norm': 1.515625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9729, 'grad_norm': 0.37109375, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8713, 'grad_norm': 1.609375, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8172, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9463, 'grad_norm': 2.9375, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8136, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9601, 'grad_norm': 0.37890625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7699, 'grad_norm': 1.7421875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8784, 'grad_norm': 0.46484375, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.882, 'grad_norm': 2.890625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8877, 'grad_norm': 0.88671875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9557, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9899, 'grad_norm': 1.6171875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8304, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9042, 'grad_norm': 2.96875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7545, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.902, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9609, 'grad_norm': 1.9296875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7622, 'grad_norm': 0.48828125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8496, 'grad_norm': 12.25, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8431, 'grad_norm': 1.1796875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9122, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7544, 'grad_norm': 1.734375, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7871, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.796, 'grad_norm': 5.28125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7992, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8047, 'grad_norm': 0.4921875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.9367, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7978, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 2.0034, 'grad_norm': 4.90625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8359, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8047, 'grad_norm': 0.34765625, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.7771, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8939, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8957, 'grad_norm': 12.6875, 'learning_rate': 1e-05, 'epoch': 0.51}\n",
      "{'loss': 1.8806, 'grad_norm': 0.88671875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7827, 'grad_norm': 0.35546875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8141, 'grad_norm': 1.0234375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9379, 'grad_norm': 0.39453125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7962, 'grad_norm': 2.609375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7592, 'grad_norm': 1.3203125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9742, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9056, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8624, 'grad_norm': 0.77734375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.967, 'grad_norm': 9.125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7243, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8121, 'grad_norm': 0.482421875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9435, 'grad_norm': 1.265625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8295, 'grad_norm': 0.404296875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8072, 'grad_norm': 5.53125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9429, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.845, 'grad_norm': 0.470703125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8896, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8447, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7382, 'grad_norm': 12.5625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7758, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8568, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9885, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9465, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9205, 'grad_norm': 2.6875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8886, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8013, 'grad_norm': 0.4296875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8218, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8872, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7414, 'grad_norm': 8.0, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7025, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7722, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9241, 'grad_norm': 1.375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9033, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9656, 'grad_norm': 2.71875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7377, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.846, 'grad_norm': 0.47265625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.835, 'grad_norm': 1.90625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.734, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.915, 'grad_norm': 3.875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.7197, 'grad_norm': 1.109375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9851, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8408, 'grad_norm': 1.875, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8343, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9006, 'grad_norm': 4.90625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.872, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8333, 'grad_norm': 0.369140625, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9338, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8367, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.8065, 'grad_norm': 4.375, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.855, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.52}\n",
      "{'loss': 1.9256, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.9246, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.863, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8943, 'grad_norm': 2.90625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8639, 'grad_norm': 0.81640625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.6627, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7767, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.93, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8977, 'grad_norm': 4.1875, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.6862, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.9219, 'grad_norm': 0.3515625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8355, 'grad_norm': 1.7578125, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.6526, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8751, 'grad_norm': 13.4375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8029, 'grad_norm': 0.8515625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8664, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8859, 'grad_norm': 2.0, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8193, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 2.133, 'grad_norm': 4.71875, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7962, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8859, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8572, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.9133, 'grad_norm': 0.890625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7361, 'grad_norm': 12.25, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8556, 'grad_norm': 0.8515625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8701, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7738, 'grad_norm': 2.171875, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7416, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.718, 'grad_norm': 6.0, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7566, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7578, 'grad_norm': 0.4375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8798, 'grad_norm': 1.671875, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 2.1106, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 2.0016, 'grad_norm': 2.375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.844, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7812, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8766, 'grad_norm': 1.21875, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7574, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 2.0211, 'grad_norm': 3.015625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.847, 'grad_norm': 0.7734375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8907, 'grad_norm': 0.3984375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.9163, 'grad_norm': 0.9375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8448, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.789, 'grad_norm': 12.5, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8736, 'grad_norm': 1.0078125, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7344, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8408, 'grad_norm': 1.890625, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.8062, 'grad_norm': 0.423828125, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.7106, 'grad_norm': 2.5, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 1.915, 'grad_norm': 0.96484375, 'learning_rate': 1e-05, 'epoch': 0.53}\n",
      "{'loss': 2.0257, 'grad_norm': 0.421875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8989, 'grad_norm': 1.0859375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8602, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8033, 'grad_norm': 4.46875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8632, 'grad_norm': 0.80859375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7957, 'grad_norm': 0.8515625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8966, 'grad_norm': 1.1875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9531, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.874, 'grad_norm': 3.8125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8267, 'grad_norm': 0.90234375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9156, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8451, 'grad_norm': 2.03125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7796, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 2.0626, 'grad_norm': 7.78125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.86, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9917, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7689, 'grad_norm': 1.625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8654, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9487, 'grad_norm': 2.515625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9004, 'grad_norm': 0.8203125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8339, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8688, 'grad_norm': 1.796875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8546, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8767, 'grad_norm': 3.984375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8552, 'grad_norm': 1.515625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8809, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7469, 'grad_norm': 3.28125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9766, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8384, 'grad_norm': 6.0625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8048, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9799, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7837, 'grad_norm': 1.5546875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7486, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8504, 'grad_norm': 4.34375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 2.0125, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7962, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7776, 'grad_norm': 1.5, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8194, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8404, 'grad_norm': 3.109375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9576, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8923, 'grad_norm': 0.39453125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9534, 'grad_norm': 1.4296875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8728, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7801, 'grad_norm': 4.6875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8217, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8307, 'grad_norm': 0.82421875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.7971, 'grad_norm': 1.125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9188, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.8068, 'grad_norm': 3.34375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.974, 'grad_norm': 0.91796875, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 2.0075, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.54}\n",
      "{'loss': 1.9261, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8894, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.7458, 'grad_norm': 13.1875, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.815, 'grad_norm': 0.9609375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8534, 'grad_norm': 0.466796875, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 2.0174, 'grad_norm': 1.8671875, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6402, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.7692, 'grad_norm': 5.5, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8708, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 2.0738, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9287, 'grad_norm': 3.078125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8446, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8793, 'grad_norm': 3.703125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8058, 'grad_norm': 0.62109375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8154, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9986, 'grad_norm': 2.078125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9052, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9474, 'grad_norm': 3.40625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9181, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9024, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.7834, 'grad_norm': 1.9453125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6666, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9668, 'grad_norm': 4.125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8923, 'grad_norm': 1.484375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8693, 'grad_norm': 0.33203125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9134, 'grad_norm': 1.3515625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.6954, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8483, 'grad_norm': 3.421875, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.81, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8453, 'grad_norm': 0.5, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9049, 'grad_norm': 1.7578125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.7766, 'grad_norm': 0.361328125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.861, 'grad_norm': 3.09375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8021, 'grad_norm': 1.421875, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8814, 'grad_norm': 0.326171875, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 2.014, 'grad_norm': 2.34375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8227, 'grad_norm': 0.78515625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.759, 'grad_norm': 3.140625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.7844, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8624, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8774, 'grad_norm': 1.375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8024, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9632, 'grad_norm': 6.125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8445, 'grad_norm': 1.3515625, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8592, 'grad_norm': 0.7578125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8249, 'grad_norm': 1.4453125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.7115, 'grad_norm': 0.490234375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.7715, 'grad_norm': 13.4375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.86, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9967, 'grad_norm': 3.8125, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.9198, 'grad_norm': 1.0234375, 'learning_rate': 1e-05, 'epoch': 0.55}\n",
      "{'loss': 1.8344, 'grad_norm': 0.4296875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8446, 'grad_norm': 13.6875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8532, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7822, 'grad_norm': 0.24609375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7802, 'grad_norm': 2.21875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7224, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8562, 'grad_norm': 3.9375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8634, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7821, 'grad_norm': 0.373046875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8006, 'grad_norm': 1.703125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7771, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8118, 'grad_norm': 4.0, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7521, 'grad_norm': 0.859375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9225, 'grad_norm': 0.4375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6955, 'grad_norm': 0.78515625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8456, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8569, 'grad_norm': 6.90625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.85, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7366, 'grad_norm': 0.6015625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8084, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8644, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7791, 'grad_norm': 2.15625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6538, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9074, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7422, 'grad_norm': 1.3671875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8694, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7226, 'grad_norm': 4.84375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7561, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8015, 'grad_norm': 0.3203125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9605, 'grad_norm': 1.28125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9048, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8087, 'grad_norm': 3.53125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8802, 'grad_norm': 0.9453125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7827, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9478, 'grad_norm': 1.4765625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7112, 'grad_norm': 2.625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6491, 'grad_norm': 13.75, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7174, 'grad_norm': 0.96875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9472, 'grad_norm': 0.423828125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9061, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.981, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8353, 'grad_norm': 6.0625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9456, 'grad_norm': 0.88671875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9783, 'grad_norm': 0.41015625, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8934, 'grad_norm': 1.8125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7617, 'grad_norm': 0.4375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.836, 'grad_norm': 2.75, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.8424, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7948, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.9714, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.6997, 'grad_norm': 0.5859375, 'learning_rate': 1e-05, 'epoch': 0.56}\n",
      "{'loss': 1.7777, 'grad_norm': 3.4375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8022, 'grad_norm': 1.328125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7941, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7755, 'grad_norm': 1.90625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9703, 'grad_norm': 3.3125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 2.0381, 'grad_norm': 2.140625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8283, 'grad_norm': 1.1015625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7544, 'grad_norm': 0.4296875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 2.0229, 'grad_norm': 1.6328125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.58, 'grad_norm': 0.80859375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 2.0398, 'grad_norm': 2.515625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8789, 'grad_norm': 1.28125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8601, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 2.014, 'grad_norm': 1.8828125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8381, 'grad_norm': 1.515625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7294, 'grad_norm': 7.5, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9969, 'grad_norm': 1.75, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.827, 'grad_norm': 0.94140625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8993, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9102, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8954, 'grad_norm': 8.6875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8103, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9427, 'grad_norm': 0.423828125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8599, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8171, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7483, 'grad_norm': 3.359375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8255, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9933, 'grad_norm': 0.3125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.86, 'grad_norm': 2.75, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.718, 'grad_norm': 0.859375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8627, 'grad_norm': 12.75, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7425, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9388, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7101, 'grad_norm': 1.9140625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9278, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.843, 'grad_norm': 3.6875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7367, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8189, 'grad_norm': 0.33984375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8206, 'grad_norm': 1.8046875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9003, 'grad_norm': 0.75, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.9147, 'grad_norm': 2.546875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8296, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8307, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8577, 'grad_norm': 1.5625, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8638, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7904, 'grad_norm': 6.46875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7094, 'grad_norm': 0.8671875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8945, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8016, 'grad_norm': 1.5546875, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7906, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.8984, 'grad_norm': 4.84375, 'learning_rate': 1e-05, 'epoch': 0.57}\n",
      "{'loss': 1.7369, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8151, 'grad_norm': 0.470703125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8367, 'grad_norm': 1.2265625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8454, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7855, 'grad_norm': 2.84375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7819, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9307, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7346, 'grad_norm': 2.828125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8319, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.861, 'grad_norm': 12.0625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8837, 'grad_norm': 0.96484375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9777, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8075, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7311, 'grad_norm': 0.7890625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9808, 'grad_norm': 4.21875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8064, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.844, 'grad_norm': 0.4296875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8832, 'grad_norm': 1.40625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7836, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8368, 'grad_norm': 12.125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7112, 'grad_norm': 0.8046875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7811, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9852, 'grad_norm': 0.921875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7738, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9222, 'grad_norm': 13.0, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7307, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.6998, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8226, 'grad_norm': 1.921875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9673, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.964, 'grad_norm': 3.84375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7211, 'grad_norm': 1.125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8642, 'grad_norm': 0.384765625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8936, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.838, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.822, 'grad_norm': 2.75, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7786, 'grad_norm': 1.234375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8623, 'grad_norm': 0.41796875, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8809, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8725, 'grad_norm': 1.1953125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 2.0249, 'grad_norm': 6.40625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9815, 'grad_norm': 0.9765625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8011, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8659, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.7662, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8818, 'grad_norm': 5.25, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8237, 'grad_norm': 0.9765625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.658, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8642, 'grad_norm': 3.953125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.8452, 'grad_norm': 0.92578125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9823, 'grad_norm': 4.0625, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9165, 'grad_norm': 0.78125, 'learning_rate': 1e-05, 'epoch': 0.58}\n",
      "{'loss': 1.9595, 'grad_norm': 0.330078125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8593, 'grad_norm': 1.4296875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.848, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9369, 'grad_norm': 7.03125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9405, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8893, 'grad_norm': 0.482421875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7555, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7788, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.816, 'grad_norm': 13.5625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.784, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.989, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7417, 'grad_norm': 1.3125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9036, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.893, 'grad_norm': 5.34375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9378, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.968, 'grad_norm': 0.373046875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9546, 'grad_norm': 1.0234375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7498, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 2.063, 'grad_norm': 2.40625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8502, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8279, 'grad_norm': 0.435546875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8548, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7511, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8849, 'grad_norm': 3.984375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9497, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8414, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8773, 'grad_norm': 1.484375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8071, 'grad_norm': 0.6953125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8537, 'grad_norm': 5.28125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8403, 'grad_norm': 1.4765625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8575, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8577, 'grad_norm': 2.609375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7356, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.6555, 'grad_norm': 4.625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.825, 'grad_norm': 1.2265625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7042, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9205, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 2.0198, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8979, 'grad_norm': 3.1875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8083, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8425, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8928, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7426, 'grad_norm': 0.458984375, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7551, 'grad_norm': 2.3125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7769, 'grad_norm': 0.92578125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8461, 'grad_norm': 0.9296875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8842, 'grad_norm': 1.6640625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.6774, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9964, 'grad_norm': 7.875, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.7299, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.8702, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.59}\n",
      "{'loss': 1.9104, 'grad_norm': 1.7109375, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8499, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9844, 'grad_norm': 5.21875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8984, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8058, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7843, 'grad_norm': 1.0390625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7422, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9093, 'grad_norm': 3.578125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7274, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9925, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8557, 'grad_norm': 1.953125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8825, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8829, 'grad_norm': 5.125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8844, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8721, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9932, 'grad_norm': 2.0625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8061, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7586, 'grad_norm': 3.875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8812, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8592, 'grad_norm': 0.515625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 2.0205, 'grad_norm': 1.53125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7116, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.963, 'grad_norm': 2.328125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.87, 'grad_norm': 0.86328125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9621, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9113, 'grad_norm': 2.5, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7763, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8833, 'grad_norm': 12.625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8267, 'grad_norm': 0.7890625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7875, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8112, 'grad_norm': 1.515625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8441, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8603, 'grad_norm': 5.03125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9086, 'grad_norm': 1.1015625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8976, 'grad_norm': 0.77734375, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7668, 'grad_norm': 2.515625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8869, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8753, 'grad_norm': 3.921875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7341, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8442, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8689, 'grad_norm': 1.65625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8824, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.6993, 'grad_norm': 7.34375, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7127, 'grad_norm': 0.98046875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 2.002, 'grad_norm': 0.427734375, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9674, 'grad_norm': 1.953125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8484, 'grad_norm': 0.58203125, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9886, 'grad_norm': 3.671875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.7545, 'grad_norm': 0.921875, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8667, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.9413, 'grad_norm': 0.9765625, 'learning_rate': 1e-05, 'epoch': 0.6}\n",
      "{'loss': 1.8447, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8944, 'grad_norm': 13.375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7835, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8136, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8627, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8691, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8314, 'grad_norm': 2.84375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8665, 'grad_norm': 1.546875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7374, 'grad_norm': 0.40234375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7831, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8908, 'grad_norm': 0.42578125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7532, 'grad_norm': 4.21875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9006, 'grad_norm': 0.7578125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.805, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9597, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7887, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9134, 'grad_norm': 3.71875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9197, 'grad_norm': 0.578125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9099, 'grad_norm': 0.62890625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7678, 'grad_norm': 1.625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7973, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8481, 'grad_norm': 11.3125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9325, 'grad_norm': 0.80859375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8535, 'grad_norm': 0.462890625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8605, 'grad_norm': 3.0625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7977, 'grad_norm': 0.498046875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9658, 'grad_norm': 5.59375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8353, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7664, 'grad_norm': 0.353515625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9097, 'grad_norm': 1.734375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8453, 'grad_norm': 1.4609375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8757, 'grad_norm': 6.3125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8876, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8962, 'grad_norm': 0.486328125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9241, 'grad_norm': 2.125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9379, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8788, 'grad_norm': 2.234375, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8481, 'grad_norm': 1.3828125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 2.055, 'grad_norm': 0.419921875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8052, 'grad_norm': 1.3671875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7663, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8832, 'grad_norm': 3.640625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9937, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8731, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.781, 'grad_norm': 2.421875, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8897, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.7865, 'grad_norm': 2.953125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8386, 'grad_norm': 0.70703125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9244, 'grad_norm': 0.4453125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.9195, 'grad_norm': 1.8125, 'learning_rate': 1e-05, 'epoch': 0.61}\n",
      "{'loss': 1.8633, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8371, 'grad_norm': 3.671875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9869, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8624, 'grad_norm': 0.466796875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.764, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7589, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7579, 'grad_norm': 2.59375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7754, 'grad_norm': 1.6640625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 2.0248, 'grad_norm': 0.455078125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8823, 'grad_norm': 2.359375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8274, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9927, 'grad_norm': 12.375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 2.016, 'grad_norm': 0.91796875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9819, 'grad_norm': 0.32421875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8384, 'grad_norm': 2.546875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9558, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9142, 'grad_norm': 4.0625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9532, 'grad_norm': 1.2890625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.854, 'grad_norm': 0.462890625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7732, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9129, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7121, 'grad_norm': 1.4921875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7795, 'grad_norm': 0.71484375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8493, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7555, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 2.002, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7861, 'grad_norm': 3.9375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7712, 'grad_norm': 0.59375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 2.0232, 'grad_norm': 0.361328125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9565, 'grad_norm': 1.4296875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8705, 'grad_norm': 0.703125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 2.0248, 'grad_norm': 5.59375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7504, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7836, 'grad_norm': 0.75, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9663, 'grad_norm': 1.7421875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7274, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.852, 'grad_norm': 6.4375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8988, 'grad_norm': 0.73828125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 2.0294, 'grad_norm': 0.494140625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8944, 'grad_norm': 1.6484375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7246, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8958, 'grad_norm': 5.65625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7462, 'grad_norm': 0.59765625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7912, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7963, 'grad_norm': 2.203125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.84, 'grad_norm': 0.447265625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 2.0296, 'grad_norm': 3.578125, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.7669, 'grad_norm': 0.91015625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8256, 'grad_norm': 0.341796875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 2.071, 'grad_norm': 1.6015625, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.8868, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.62}\n",
      "{'loss': 1.9819, 'grad_norm': 4.6875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8428, 'grad_norm': 0.75, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8967, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.6415, 'grad_norm': 1.765625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8458, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8787, 'grad_norm': 5.21875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8166, 'grad_norm': 0.94921875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9453, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8469, 'grad_norm': 1.296875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7806, 'grad_norm': 0.91015625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 2.0217, 'grad_norm': 4.375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8354, 'grad_norm': 1.5703125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.6588, 'grad_norm': 0.384765625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7666, 'grad_norm': 2.71875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9551, 'grad_norm': 0.7109375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8579, 'grad_norm': 3.109375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9191, 'grad_norm': 1.2734375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8628, 'grad_norm': 0.390625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9379, 'grad_norm': 1.875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7156, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.847, 'grad_norm': 2.828125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8123, 'grad_norm': 1.0703125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9416, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7906, 'grad_norm': 1.5390625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8316, 'grad_norm': 0.74609375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 2.0213, 'grad_norm': 7.25, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8363, 'grad_norm': 1.0, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7683, 'grad_norm': 0.68359375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9263, 'grad_norm': 1.5078125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7432, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9606, 'grad_norm': 5.34375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9147, 'grad_norm': 1.1796875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9455, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8734, 'grad_norm': 1.125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8822, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8926, 'grad_norm': 5.3125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8292, 'grad_norm': 0.6328125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8013, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9649, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.83, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7671, 'grad_norm': 3.96875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8118, 'grad_norm': 1.265625, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.8773, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9235, 'grad_norm': 1.53125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9503, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9348, 'grad_norm': 4.25, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7988, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7442, 'grad_norm': 0.63671875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 2.0775, 'grad_norm': 0.93359375, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9329, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.9137, 'grad_norm': 6.03125, 'learning_rate': 1e-05, 'epoch': 0.63}\n",
      "{'loss': 1.7502, 'grad_norm': 0.7734375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8175, 'grad_norm': 0.365234375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.7909, 'grad_norm': 1.3828125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.832, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9062, 'grad_norm': 3.5, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8607, 'grad_norm': 1.125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.7179, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8313, 'grad_norm': 1.484375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.7154, 'grad_norm': 0.4921875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9387, 'grad_norm': 4.96875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8688, 'grad_norm': 0.90625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9346, 'grad_norm': 0.337890625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8752, 'grad_norm': 1.796875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.7338, 'grad_norm': 0.4765625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9937, 'grad_norm': 3.03125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9348, 'grad_norm': 1.2421875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.6936, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 2.0015, 'grad_norm': 2.359375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8057, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8188, 'grad_norm': 11.125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8739, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8886, 'grad_norm': 0.42578125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9117, 'grad_norm': 1.3046875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8032, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9036, 'grad_norm': 4.125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8421, 'grad_norm': 0.7265625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8467, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8367, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8846, 'grad_norm': 0.458984375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9401, 'grad_norm': 2.8125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.7493, 'grad_norm': 1.1015625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8622, 'grad_norm': 0.46875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8763, 'grad_norm': 1.2421875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9578, 'grad_norm': 0.69140625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8849, 'grad_norm': 2.40625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8442, 'grad_norm': 0.8125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 2.0483, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9186, 'grad_norm': 0.73046875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9593, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 2.0393, 'grad_norm': 6.03125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8446, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9945, 'grad_norm': 0.29296875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9311, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8216, 'grad_norm': 0.7109375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 2.0177, 'grad_norm': 4.28125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8612, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.874, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 2.0006, 'grad_norm': 3.046875, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8734, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.8079, 'grad_norm': 2.40625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9041, 'grad_norm': 1.140625, 'learning_rate': 1e-05, 'epoch': 0.64}\n",
      "{'loss': 1.9198, 'grad_norm': 0.4140625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8602, 'grad_norm': 3.34375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7483, 'grad_norm': 0.6953125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.9054, 'grad_norm': 9.0625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7921, 'grad_norm': 0.74609375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7078, 'grad_norm': 0.439453125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8241, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8757, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8919, 'grad_norm': 1.9765625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8213, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7547, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8268, 'grad_norm': 1.515625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8284, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8926, 'grad_norm': 3.6875, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8064, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7698, 'grad_norm': 1.453125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8383, 'grad_norm': 1.6328125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 2.0129, 'grad_norm': 0.65625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7968, 'grad_norm': 11.8125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8684, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8235, 'grad_norm': 0.412109375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7589, 'grad_norm': 0.80859375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8767, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8255, 'grad_norm': 6.34375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7538, 'grad_norm': 1.09375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8059, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7626, 'grad_norm': 2.3125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.807, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.9706, 'grad_norm': 7.0625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8285, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8455, 'grad_norm': 0.51953125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7492, 'grad_norm': 1.0234375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7196, 'grad_norm': 0.796875, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.9385, 'grad_norm': 11.875, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8686, 'grad_norm': 0.76171875, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.6781, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.9127, 'grad_norm': 1.734375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7504, 'grad_norm': 0.53125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7056, 'grad_norm': 5.8125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.786, 'grad_norm': 0.8125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8052, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.9667, 'grad_norm': 0.96484375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.6602, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 2.0737, 'grad_norm': 4.90625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8184, 'grad_norm': 1.21875, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 2.0217, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8046, 'grad_norm': 2.59375, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8715, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7574, 'grad_norm': 6.125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.9231, 'grad_norm': 0.5703125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.8175, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.65}\n",
      "{'loss': 1.7957, 'grad_norm': 1.0, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.6906, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7946, 'grad_norm': 2.546875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8329, 'grad_norm': 0.921875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.839, 'grad_norm': 0.76171875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7879, 'grad_norm': 1.4375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8171, 'grad_norm': 0.50390625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 2.0291, 'grad_norm': 5.15625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8574, 'grad_norm': 1.25, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8672, 'grad_norm': 0.462890625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8879, 'grad_norm': 0.95703125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8799, 'grad_norm': 0.66796875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8582, 'grad_norm': 7.15625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.9128, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8323, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8718, 'grad_norm': 1.7734375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8248, 'grad_norm': 0.54296875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.966, 'grad_norm': 1.421875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.9222, 'grad_norm': 1.3359375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8894, 'grad_norm': 0.75390625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 2.0032, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7201, 'grad_norm': 0.52734375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8897, 'grad_norm': 2.40625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8216, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.6981, 'grad_norm': 0.44921875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7608, 'grad_norm': 1.5234375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7438, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8906, 'grad_norm': 4.28125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8047, 'grad_norm': 0.83203125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8333, 'grad_norm': 0.423828125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8656, 'grad_norm': 1.703125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8766, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8958, 'grad_norm': 3.8125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8861, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.6998, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8669, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7795, 'grad_norm': 0.6953125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8272, 'grad_norm': 4.15625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.578, 'grad_norm': 0.90234375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.5617, 'grad_norm': 0.400390625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.9677, 'grad_norm': 1.6953125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8068, 'grad_norm': 0.5625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8464, 'grad_norm': 12.1875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.8316, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.9918, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.9407, 'grad_norm': 0.80078125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7347, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.9201, 'grad_norm': 2.765625, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7903, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.9326, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.798, 'grad_norm': 1.1953125, 'learning_rate': 1e-05, 'epoch': 0.66}\n",
      "{'loss': 1.7726, 'grad_norm': 0.6953125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9422, 'grad_norm': 7.1875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8083, 'grad_norm': 0.69921875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.7699, 'grad_norm': 0.326171875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8436, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.7561, 'grad_norm': 0.7734375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8433, 'grad_norm': 1.8984375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.829, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8545, 'grad_norm': 0.43359375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.7503, 'grad_norm': 1.3984375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.804, 'grad_norm': 0.58984375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9588, 'grad_norm': 11.0, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8733, 'grad_norm': 0.8359375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 2.145, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8783, 'grad_norm': 1.6640625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.846, 'grad_norm': 0.95703125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8829, 'grad_norm': 4.84375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.6891, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.934, 'grad_norm': 0.296875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.846, 'grad_norm': 3.125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8062, 'grad_norm': 0.44140625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9161, 'grad_norm': 8.8125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8837, 'grad_norm': 1.15625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9855, 'grad_norm': 0.57421875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8618, 'grad_norm': 2.296875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.7993, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9958, 'grad_norm': 15.125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.6685, 'grad_norm': 0.828125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8704, 'grad_norm': 0.62109375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.849, 'grad_norm': 1.6796875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8988, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.807, 'grad_norm': 12.75, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.7213, 'grad_norm': 0.8515625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9533, 'grad_norm': 1.46875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9209, 'grad_norm': 1.328125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8613, 'grad_norm': 0.546875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 2.0113, 'grad_norm': 2.921875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.6448, 'grad_norm': 0.66015625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.749, 'grad_norm': 0.474609375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9323, 'grad_norm': 1.515625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8384, 'grad_norm': 0.53515625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.7896, 'grad_norm': 2.15625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8206, 'grad_norm': 0.8984375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9578, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8345, 'grad_norm': 1.3671875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.7014, 'grad_norm': 0.5390625, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.7757, 'grad_norm': 14.8125, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.9871, 'grad_norm': 0.96484375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8452, 'grad_norm': 0.404296875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8144, 'grad_norm': 1.375, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8019, 'grad_norm': 0.51171875, 'learning_rate': 1e-05, 'epoch': 0.67}\n",
      "{'loss': 1.8245, 'grad_norm': 3.921875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7465, 'grad_norm': 0.90625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.854, 'grad_norm': 0.6484375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8782, 'grad_norm': 1.6015625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.6952, 'grad_norm': 0.8046875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9063, 'grad_norm': 2.65625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9158, 'grad_norm': 1.03125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 2.1356, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7081, 'grad_norm': 1.546875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8096, 'grad_norm': 0.609375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9586, 'grad_norm': 11.1875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8556, 'grad_norm': 0.8671875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7971, 'grad_norm': 0.408203125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8343, 'grad_norm': 2.140625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8482, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.869, 'grad_norm': 2.96875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8927, 'grad_norm': 0.55859375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9045, 'grad_norm': 0.390625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9385, 'grad_norm': 1.703125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.6979, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9442, 'grad_norm': 2.34375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.81, 'grad_norm': 0.84765625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9664, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8328, 'grad_norm': 1.1328125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7395, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.881, 'grad_norm': 8.5625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8498, 'grad_norm': 0.91015625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8873, 'grad_norm': 0.5078125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8417, 'grad_norm': 1.1015625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.6518, 'grad_norm': 0.734375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 2.011, 'grad_norm': 3.3125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8675, 'grad_norm': 0.60546875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.994, 'grad_norm': 0.4921875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8352, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7723, 'grad_norm': 0.5234375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8024, 'grad_norm': 5.9375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.6784, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7917, 'grad_norm': 0.431640625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.6981, 'grad_norm': 1.3515625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8816, 'grad_norm': 0.7734375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9692, 'grad_norm': 2.515625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.7232, 'grad_norm': 0.67578125, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8458, 'grad_norm': 0.396484375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8256, 'grad_norm': 1.90625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8797, 'grad_norm': 0.56640625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8159, 'grad_norm': 3.5625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8534, 'grad_norm': 0.671875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9493, 'grad_norm': 0.478515625, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9262, 'grad_norm': 0.9609375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.9321, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8769, 'grad_norm': 3.234375, 'learning_rate': 1e-05, 'epoch': 0.68}\n",
      "{'loss': 1.8985, 'grad_norm': 0.89453125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7589, 'grad_norm': 0.6171875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8055, 'grad_norm': 3.40625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7894, 'grad_norm': 0.79296875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7005, 'grad_norm': 11.625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7786, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8599, 'grad_norm': 0.453125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8754, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 2.0671, 'grad_norm': 0.61328125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.793, 'grad_norm': 4.25, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7101, 'grad_norm': 0.6875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.888, 'grad_norm': 0.45703125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9832, 'grad_norm': 1.40625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8075, 'grad_norm': 0.484375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9489, 'grad_norm': 3.953125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7715, 'grad_norm': 0.72265625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9652, 'grad_norm': 0.49609375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 2.0023, 'grad_norm': 1.8359375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.76, 'grad_norm': 0.423828125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.6889, 'grad_norm': 3.734375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7409, 'grad_norm': 0.87109375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8082, 'grad_norm': 0.4375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8147, 'grad_norm': 2.0, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9338, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9563, 'grad_norm': 2.5, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8926, 'grad_norm': 1.2578125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9019, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.918, 'grad_norm': 1.953125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8726, 'grad_norm': 0.65234375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 2.1145, 'grad_norm': 5.65625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7856, 'grad_norm': 0.515625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9746, 'grad_norm': 0.4921875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9441, 'grad_norm': 1.8671875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8143, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9481, 'grad_norm': 6.25, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8393, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8041, 'grad_norm': 0.640625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9443, 'grad_norm': 1.7734375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9117, 'grad_norm': 0.416015625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9694, 'grad_norm': 2.875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8367, 'grad_norm': 1.046875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9229, 'grad_norm': 0.369140625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.698, 'grad_norm': 0.9921875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7399, 'grad_norm': 1.0, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8854, 'grad_norm': 3.46875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8319, 'grad_norm': 0.71875, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8395, 'grad_norm': 0.3828125, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9399, 'grad_norm': 1.0625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.7934, 'grad_norm': 0.515625, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.9541, 'grad_norm': 4.09375, 'learning_rate': 1e-05, 'epoch': 0.69}\n",
      "{'loss': 1.8587, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9175, 'grad_norm': 0.375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.755, 'grad_norm': 0.8984375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8143, 'grad_norm': 0.625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9245, 'grad_norm': 3.296875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8192, 'grad_norm': 1.21875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8165, 'grad_norm': 0.369140625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.7885, 'grad_norm': 1.890625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8113, 'grad_norm': 1.4453125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 2.0823, 'grad_norm': 9.5625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8242, 'grad_norm': 0.8125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8363, 'grad_norm': 0.373046875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8529, 'grad_norm': 3.609375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.6942, 'grad_norm': 0.6640625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9766, 'grad_norm': 4.34375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.7782, 'grad_norm': 0.94921875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9019, 'grad_norm': 0.42578125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9249, 'grad_norm': 1.4453125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.84, 'grad_norm': 0.41015625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8635, 'grad_norm': 2.71875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.7014, 'grad_norm': 1.2109375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9416, 'grad_norm': 1.8671875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8448, 'grad_norm': 1.8671875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8425, 'grad_norm': 0.474609375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8342, 'grad_norm': 11.9375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8266, 'grad_norm': 0.8359375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8386, 'grad_norm': 0.470703125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9423, 'grad_norm': 1.7890625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9067, 'grad_norm': 2.046875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.925, 'grad_norm': 2.9375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9682, 'grad_norm': 1.078125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.7442, 'grad_norm': 0.6796875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8455, 'grad_norm': 1.359375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.7283, 'grad_norm': 0.55078125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8534, 'grad_norm': 2.96875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.7669, 'grad_norm': 0.890625, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8112, 'grad_norm': 0.482421875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.9042, 'grad_norm': 1.6796875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8877, 'grad_norm': 0.64453125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.857, 'grad_norm': 3.03125, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8353, 'grad_norm': 0.7421875, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8064, 'grad_norm': 0.2021484375, 'learning_rate': 1e-05, 'epoch': 0.7}\n",
      "{'loss': 1.8039, 'grad_norm': 1.578125, 'learning_rate': 1e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:360\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 360\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/transformers/trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/transformers/trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1967\u001b[0m ):\n\u001b[1;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/transformers/trainer.py:2911\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2909\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/accelerate/accelerator.py:2001\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2001\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 허깅페이스에서 훈련 도중 러닝레이트가 수정 안되는 경우가 많다 한다. \n",
    "- 스케쥴러 변경을 시도해 보기로 한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./results/experi_04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aeolian83/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/peft/utils/other.py:588: UserWarning: Unable to fetch remote file due to the following error (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 3c877566-c0c7-4b66-a1ec-258126076aba)') - silently ignoring the lookup for the file config.json in beomi/llama-2-ko-7b.\n",
      "  warnings.warn(\n",
      "/home/aeolian83/anaconda3/envs/llm_for_p311/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in beomi/llama-2-ko-7b - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_for_p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
