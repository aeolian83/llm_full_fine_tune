{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/aeolian83/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "login(token= os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'aeolian83/llama_ko_sft_kullm_experi_06'\n",
    "device_map = {\"\": 0}\n",
    "cache_model_dir=\"/mnt/t7/.cache/huggingface/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b994cd1d65b84c91b24b81212eaceb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"./lora_merged_model/sft_09\", quantization_config=quantization_config, device_map=device_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=cache_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_01 = \"### instruction: AI에 대해 알려줘.\\n\\n### output:\"\n",
    "inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=500, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### instruction: AI에 대해 알려줘.\n",
      "\n",
      "### output: 인공 지능(AI)은 기계 학습, 자연어 처리 및 컴퓨터 시각과 같은 전문 분야의 연구와 기술 개발을 이끄는 컴퓨터 과학 분야의 연구 분야입니다. AI는 인간이 생각하는 방식과 유사한 기계의 행동을 개발하려는 기계 지능 시스템의 개발을 촉진하는 데 집중되어 있습니다. 기계의 지능을 구현한 시도는 이미 수십 년의 역사를 갖고 있으며 2019년 현재 컴퓨터 비전에서 자연스러움과 인간적인 행동을 위한 머신 러닝 방법을 찾는 등 다양한 발전을 이뤘습니다. 인공 지능을 구현하려는 시도에는 음성 및 언어 처리, 자연어 이해, 기계 시각 등 다양한 분야의 복잡성과 어려움이 포함됩니다. 궁극적으로 AI 분야의 연구자들은 이러한 기능이 인간의 뇌와 동일한 방식으로 동작하는 기계를 만들고 인간의 지적 행동을 복제하기를 희망합니다. 이러한 목표를 달성하는 데는 여전히 많은 어려움이 있어 계속해서 발전 중입니다.</s>\n",
      "194\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))\n",
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,   835, 15278, 29901,   319, 29902, 31054, 32550, 32947, 45189,\n",
      "        29889,    13,    13,  2277, 29937,  1962, 29901, 36328, 36649, 29898,\n",
      "        23869, 29897, 31354, 41478, 38191, 29892, 34162, 31129, 33948, 32356,\n",
      "        43006, 36566, 31906, 32280, 32690, 41146, 32934, 44834, 32825, 41183,\n",
      "        40389, 43006, 33635, 41146, 32934, 33416, 32214, 29889,   319, 29902,\n",
      "        31081, 34234, 34979, 37016, 31906, 37572, 30877, 32013, 40854, 39265,\n",
      "        32785, 35641, 41478, 36649, 33990, 30708, 41183, 33592, 31536, 32022,\n",
      "        32392, 33420, 33584, 32777, 29889, 32013, 40854, 36649, 31286, 38400,\n",
      "        30877, 32026, 33567, 32622, 35103, 35500, 30708, 38519, 34332, 34705,\n",
      "        29871, 29906, 29900, 29896, 29929, 31571, 32702, 43006, 32072, 34648,\n",
      "        34162, 34746, 45102, 31906, 32333, 32203, 39265, 32427, 32466, 31262,\n",
      "        32431, 45433, 39017, 38454, 32055, 32894, 39545, 32001, 45880, 32043,\n",
      "        29889, 36328, 36649, 31286, 38400, 35641, 35436, 32221, 38596, 32356,\n",
      "        44492, 33948, 29892, 34162, 31129, 32819, 29892, 41478, 36566, 32055,\n",
      "        32894, 41146, 40856, 34446, 42847, 33037, 33214, 29889, 33184, 45058,\n",
      "        32196,   319, 29902, 41146, 32934, 33928, 37236, 34431, 30393, 39609,\n",
      "        33263, 44834, 43884, 36813, 32135, 44896, 32022, 32013, 33642, 34688,\n",
      "        39609, 33641, 39265, 32592, 31306, 42784, 33978, 32111, 29889, 37236,\n",
      "        42134, 35246, 32022, 32392, 31081, 35109, 32504, 42847, 32791, 39708,\n",
      "        33772, 39364, 29889,     2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_01 = \"### instruction: 인공지능을 무엇을 할 수 있는지 알려줘.\\n\\n### output:\"\n",
    "inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs, max_new_tokens=1024, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### instruction: 인공지능을 무엇을 할 수 있는지 알려줘.\n",
      "\n",
      "### output: 인공지능(AI)은 다양한 컴퓨터 과학의 분야에 응용 프로그램으로 사용될 수 있습니다. 아래는 AI 애플리케이션의 몇 가지 예입니다:\n",
      "\n",
      "1. 컴퓨터 비전: 이미지 분석, 이미지 분류 등 이미지 처리와 관련된 작업을 수행합니다.\n",
      "2. 언어 처리: 자연어 처리, 질의응답 시스템, 번역 등 인간의 말에 대한 컴퓨터의 처리 프로세스를 연구합니다.\n",
      "3. 머신 러닝: 과거의 데이터를 분석하여 미래를 예측하고 일반화하는 데 사용할 수 있는 알고리즘과 도구를 개발하는 작업입니다.\n",
      "4. 패턴 인식: 인간의 인식 능력인 시각, 청각, 촉각의 영역을 자동화하기 위해 컴퓨터에게 패턴 인식 능력을 가르치거나 개발하는 데 사용됩니다.\n",
      "5. 음성 인식: 사람이 사용하는 언어를 처리하여 컴퓨터가 이해할 수 있는 언어로 변환하는 데 사용됩니다.\n",
      "6. 자연어 처리: 검색 엔진, 번역기, 기계적 작업에 사용되는 언어 처리 프로세스를 개발하는 데 사용됩니다.\n",
      "7. 음성 인식: 컴퓨터가 사람의 음성을 인식하고 이해하여 사람의 명령을 시행하는 데 사용됩니다.\n",
      "8. 추천 시스템: 개인화된 추천을 제공하기 위해 사용자의 과거 온라인 행동을 분석하여 개인 맞춤 서비스를 생성하는 데 사용됩니다.\n",
      "9. 게임 개발: 보드 게임, 전략 게임 등 컴퓨터 게임을 개발하고 게임 플레이 규칙을 개발하는 데 사용됩니다.\n",
      "10. 시뮬레이션: 공학적, 물리적, 수학적 모델을 사용하여 복잡한 시스템을 모델링하고 테스트하는 데 사용합니다.\n",
      "11. 로봇공학: 이동하고 작업하는 장치를 설계하고 학습시키는 데 사용됩니다.\n",
      "12. 빅데이터 분석: 대규모 데이터 세트를 분석하여 중요한 패턴 또는 추세를 식별하고 예측하는 데 사용할 수 있습니다.\n",
      "13. 의료용: 의학 연구, 영상 검사, 예측, 치료 계획과 같은 의료 분야에서 사용되어 질병을 진단하고 치료하는 데 도움이 되도록 합니다.\n",
      "14. 금융: 시장 및 경제 동향에 대한 예측, 위험 관리, 의사결정을 지원하는 데 사용됩니다.\n",
      "15. 물류 및 공급망 관리: 재고 관리, 차량 흐름, 배송 시간을 최적화하는 것을 포함하여 공급망 운영 및 최적화를 지원하는 데 사용됩니다.\n",
      "16. 보안: 위협 및 침입 탐지, 시스템 복구를 위한 모델을 개발하는 등 보안 시스템에 있어 중요한 역할을 맡는 데 사용됩니다.\n",
      "17. 교육: 컴퓨터가 교수, 학습 및 학습을 돕고 시험문제를 풀거나 교수법을 개선하는 데 사용됩니다.\n",
      "18. AI 로봇: 자동화, 작업, 청소, 인간과의 상호작용과 같은 특정 작업을 수행하고 인간과 협력하는 작업을 하는 로봇을 만드는 데 사용됩니다.\n",
      "19. AI 시스템: AI 시스템을 개발하여 특정 목적이나 문제에 맞는 작업을 수행하도록 교육하고 훈련합니다.\n",
      "\n",
      "이것은 컴퓨터 과학에서 가장 인기있는 AI 애플리케이션의 일부에 불과합니다. 각 AI 애플리케이션은 다른 유형의 AI 기능과 도구를 필요로 할 수 있으며, 이러한 도구는 전문 개발자의 기술과 노력을 필요로 합니다.</s>\n",
      "677\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))\n",
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_01 = \"### instruction: 인공지능의 장점에 대해 알려줘.\\n\\n### output:\"\n",
    "inputs = tokenizer(text_01, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(**inputs, num_beams = 3, early_stopping=True, max_new_tokens=1024, do_sample=True, top_k=50, top_p=0.95, eos_token_id=tokenizer.eos_token_id, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> ### instruction: 인공지능의 장점에 대해 알려줘.\n",
      "\n",
      "### output: 인공지능은 다양한 산업 분야에서 혁신과 효율성을 촉진하는 데 중요한 역할을 하고 있습니다. 다음은 몇 가지 인공지능의 주요 장점입니다:\n",
      "\n",
      "1. 자동화: 인공지능은 반복적이고 정형화된 작업을 자동화하여 생산성을 높이고 오류 가능성을 줄일 수 있습니다.\n",
      "\n",
      "2. 의사결정 지원: 인공지능은 방대한 양의 데이터를 분석하고 패턴을 식별하여 의사결정을 지원하는 데 사용할 수 있습니다.\n",
      "\n",
      "3. 개인화: 인공지능은 사용자의 행동, 선호도, 선호도를 학습하여 개인화된 경험을 제공할 수 있습니다.\n",
      "\n",
      "4. 의사소통: 인공지능은 자연어 처리, 음성 인식 및 텍스트 분석과 같은 기술을 사용하여 인간과 소통할 수 있습니다.\n",
      "\n",
      "5. 학습: 인공지능은 머신러닝, 딥러닝과 같은 기술을 사용하여 스스로 학습하고 개선할 수 있습니다.\n",
      "\n",
      "전반적으로 인공지능은 다양한 산업 분야에서 혁신과 효율성을 촉진하는 데 중요한 역할을 하고 있습니다.</s>\n",
      "221\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=False))\n",
    "print(len(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_for_p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
